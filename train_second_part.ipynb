{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Guess the age 2022-2023\n",
        "Group 9:\n",
        "*   Antonello Avella\n",
        "*   Eugenio Carpentieri\n",
        "*   Valerio Costantino\n",
        "*   Claudio De Pisapia\n",
        "\n"
      ],
      "metadata": {
        "id": "Z6u8jjSkUJ2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init"
      ],
      "metadata": {
        "id": "4eZbMa0BUGik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khnG5-fNNZNb",
        "outputId": "46fff0db-68c5-4794-f1ed-e8879ed0cb74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (1.7.3)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (2.2.3)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (0.90)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1.1-cp38-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->catboost) (2022.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1.1\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-python scipy tensorflow scikit-learn lightgbm xgboost catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN7SP5uIJRCo",
        "outputId": "deedb309-b932-44f5-9f27-cb82f4678e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEHhKOgMGs4v"
      },
      "source": [
        "## Metrics and loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4mBKqxKubz6l"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Concatenate, Flatten, Dropout\n",
        "\n",
        "from keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import keras\n",
        "#TO USE RandomForest uncomment the following line\n",
        "#from cuml import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "from keras.layers.pooling.global_average_pooling1d import GlobalAveragePooling1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RotPrSoed7iw"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def AAR_metric(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    mae_fun = tf.keras.losses.MeanAbsoluteError()\n",
        "    mae = mae_fun(y_true, y_pred)\n",
        "    print(mae)\n",
        "\n",
        "    condition = tf.less_equal(y_true, 0.1)\n",
        "    indices = tf.where(condition) \n",
        "    mae_1 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_1 = tf.square(mae_1-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.2)\n",
        "    condition2 = tf.greater(y_true, 0.1)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_2 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_2 = tf.square(mae_2-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.3)\n",
        "    condition2 = tf.greater(y_true, 0.2)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_3 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_3 = tf.square(mae_3-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.4)\n",
        "    condition2 = tf.greater(y_true, 0.3)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_4 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_4 = tf.square(mae_4-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.5)\n",
        "    condition2 = tf.greater(y_true, 0.4)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_5 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_5 = tf.square(mae_5-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.6)\n",
        "    condition2 = tf.greater(y_true, 0.5)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_6 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_6 = tf.square(mae_6-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.7)\n",
        "    condition2 = tf.greater(y_true, 0.6)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_7 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_7 = tf.square(mae_7-mae)\n",
        "\n",
        "    condition = tf.greater(y_true, 0.7)\n",
        "    indices = tf.where(condition)\n",
        "    mae_8 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_8 = tf.square(mae_8-mae)\n",
        "\n",
        "    mae_temp = tf.stack([mae_1, mae_2, mae_3, mae_4, mae_5, mae_6, mae_7, mae_8], axis=0)\n",
        "    print(\"MAE's of all age groups: \", mae_temp)\n",
        "    indices = tf.where(tf.logical_not(tf.math.is_nan(mae_temp)))\n",
        "    mae_total = tf.gather(mae_temp, indices)\n",
        "    mmae = tf.reduce_mean(mae_total)\n",
        "    mae_diff_temp = tf.stack([mae_diff_1, mae_diff_2, mae_diff_3, mae_diff_4, mae_diff_5, mae_diff_6, mae_diff_7, mae_diff_8])\n",
        "    variance_temp = tf.gather(mae_diff_temp, indices)\n",
        "    variance = tf.sqrt(tf.reduce_mean(variance_temp))\n",
        "    print(mmae)\n",
        "    print(variance)\n",
        "    #𝐴𝐴𝑅 = max(0; 5 − 𝑚𝑀𝐴𝐸) + max(0; 5 − 𝜎)\n",
        "    AAR = tf.math.maximum(tf.zeros((1,)),tf.constant(5, dtype=tf.float32)-mmae*100)+tf.math.maximum(tf.zeros((1,)),tf.constant(5, dtype=tf.float32)-variance*100)\n",
        "\n",
        "    return AAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AiaN-S_n6J7D"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def AAR_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    mae_fun = tf.keras.losses.MeanAbsoluteError()\n",
        "    mae = mae_fun(y_true, y_pred)\n",
        "    \n",
        "\n",
        "    condition = tf.less_equal(y_true, 0.1)\n",
        "    indices = tf.where(condition)\n",
        "    mae_1 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_1 = tf.square(mae_1-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.2)\n",
        "    condition2 = tf.greater(y_true, 0.1)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_2 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_2 = tf.square(mae_2-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.3)\n",
        "    condition2 = tf.greater(y_true, 0.2)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_3 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_3 = tf.square(mae_3-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.4)\n",
        "    condition2 = tf.greater(y_true, 0.3)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_4 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_4 = tf.square(mae_4-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.5)\n",
        "    condition2 = tf.greater(y_true, 0.4)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_5 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_5 = tf.square(mae_5-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.6)\n",
        "    condition2 = tf.greater(y_true, 0.5)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_6 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_6 = tf.square(mae_6-mae)\n",
        "\n",
        "    condition1 = tf.less_equal(y_true, 0.7)\n",
        "    condition2 = tf.greater(y_true, 0.6)\n",
        "    condition = tf.logical_and(condition1, condition2)\n",
        "    indices = tf.where(condition)\n",
        "    mae_7 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_7 = tf.square(mae_7-mae)\n",
        "\n",
        "    condition = tf.greater(y_true, 0.7)\n",
        "    indices = tf.where(condition)\n",
        "    mae_8 = mae_fun(tf.gather(y_true, indices), tf.gather(y_pred, indices))\n",
        "    mae_diff_8 = tf.square(mae_8-mae)\n",
        "\n",
        "    mae_temp = tf.stack([mae_1, mae_2, mae_3, mae_4, mae_5, mae_6, mae_7, mae_8], axis=0)\n",
        "    indices = tf.where(tf.logical_not(tf.math.is_nan(mae_temp)))\n",
        "    mae_total = tf.gather(mae_temp, indices)\n",
        "    mmae = tf.reduce_mean(mae_total)\n",
        "    mae_diff_temp = tf.stack([mae_diff_1, mae_diff_2, mae_diff_3, mae_diff_4, mae_diff_5, mae_diff_6, mae_diff_7, mae_diff_8])\n",
        "    variance_temp = tf.gather(mae_diff_temp, indices)\n",
        "    variance = tf.sqrt(tf.reduce_mean(variance_temp))\n",
        "\n",
        "    AAR_loss = 0.5*mmae + 0.5*variance\n",
        "\n",
        "    return AAR_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m1W47MCSf-wU"
      },
      "outputs": [],
      "source": [
        "#RUN THIS\n",
        "tf.config.run_functions_eagerly(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backbone load"
      ],
      "metadata": {
        "id": "QtE9ecpST1ah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpMe-X3cQNZq",
        "outputId": "d3698690-2534-4770-bfca-2a644027db66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Final_output\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 299, 299, 3)]     0         \n",
            "                                                                 \n",
            " xception (Functional)       (None, 10, 10, 2048)      20861480  \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 2048)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21,123,881\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,123,881\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "final_model = keras.models.load_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/xception09_final', compile=False)\n",
        "final_model.trainable = False\n",
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features load"
      ],
      "metadata": {
        "id": "eTzVvUcST6ff"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yp9eTKv-aVfn"
      },
      "outputs": [],
      "source": [
        "x_train = np.load('/content/drive/MyDrive/xception_x_train.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/xception_y_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U7recMBQTeRo"
      },
      "outputs": [],
      "source": [
        "x_val = np.load('/content/drive/MyDrive/xception_x_val.npy')\n",
        "y_val = np.load('/content/drive/MyDrive/xception_y_val.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmKUApXZZcVQ"
      },
      "source": [
        "## Plotting histograms of training and validation set distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "k2k-B7t-syTR",
        "outputId": "26c6f728-a18b-4e07-e57d-8c90c61894d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "_ = plt.hist(y_val*100, bins='auto')\n",
        "plt.title(\"Val Histogram\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "O2TLRTJPstTn",
        "outputId": "c964fce7-097c-4b2a-95da-4d95244b83a9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW+0lEQVR4nO3dfZBldX3n8fcnjCgPyoDMsjhDMmOcYCEVFadgXC3XgAsDMQ5/EGuIiaM77mytaNR1SyHZDYmGLU0sEcvIZiKj6FI87GiEIIoTxLLMysMgRBkeQi8PMhNgWoYBCT4NfPeP++t4bbpnpvt2973d/X5V3epzfud37v3ee0/fzz2/c+69qSokSfPbr/S7AElS/xkGkiTDQJJkGEiSMAwkSRgGkiQMA81xSb6aZO00Xv/WJK+fruuXZkr8nIEGTZInu2YPBH4KPN3m/3NVXTJDddwPvKOq/r6r7W2t7bUTuJ6lwH3Ac6pq99RWKU2NBf0uQBqtqg4emR7rBblr2QJfXH0cNDUcJtKskeT1SbYl+WCSh4HPJjk0ydVJhpM81qaXdK3zzSTvaNNvS/LtJB9rfe9LcmqPNd2f5A1t+vgkW5I8keSRJB9v3b7V/u5K8mSSVyf5lST/PckDSXYk+XySQ7qu961t2aNJ/seo2/nTJJuS/O8kTwBva7f9nSS7kjyU5FNJ9u+6vkryziT3JPlRkg8n+fUk/7fVe0V3f80/hoFmm38LHAb8GrCezjb82Tb/q8CPgU/tYf0TgLuBw4G/AC5Kkimq7QLggqp6AfDrwBWt/XXt78KqOriqvgO8rV1+C3gxcPBI3UmOAT4NvAU4EjgEWDzqtlYDm4CFwCV0htHe1+7Xq4GTgHeOWucU4FXASuADwAbg94GjgGOBM3u475rlDAPNNs8A51bVT6vqx1X1aFV9saqeqqofAecB/34P6z9QVX9TVU8DF9N5sT1iD/2/3N5t70qyi86L9Hh+DrwkyeFV9WRV3bCHvm8BPl5V91bVk8A5wJokC4AzgL+rqm9X1c+APwFGH9z7TlV9uaqeaY/DLVV1Q1Xtrqr7gb8e43H4i6p6oqq2ArcDX2+3/zjwVeCVe6hXc5xhoNlmuKp+MjKT5MAkf92GVJ6gMySzMMl+46z/8MhEVT3VJg8epy/A6VW1cOTCs99td1sH/AZwV5Kbk7xxD31fBDzQNf8AnWN4R7RlD46q89FR6z/YPZPkN9oQ2cPtcfifdPYSuj3SNf3jMeb39DhojjMMNNuMfof8fuBo4IQ2PDMyJDNVQz/7rKruqaozgX8DfBTYlOQgnl0zwD/TGdoa8avAbjov0A8B3cc9DgBeOPrmRs1fCNwFLG+Pwx/Rh8dAs5dhoNnu+XTe1e5Kchhwbr8KSfL7SRZV1TPArtb8DDDc/r64q/ulwPuSLEtyMJ138pe3s4I2Ab+T5N+1g7p/yt5f2J8PPAE8meSlwH+Zqvul+cEw0Gz3CeAA4IfADcDX+ljLKmBr+5zEBcCaNp7/FJ1jGf/Qjj2sBDYCX6AzrHUf8BPg3QBtTP/dwGV09hKeBHbQ+bzFeP4b8HvAj4C/AS6f+runucwPnUkDru057KIzBHRfv+vR3OSegTSAkvxOOzh+EPAx4PvA/f2tSnOZYSANptV0DjL/M7CczpCTu/GaNg4TSZLcM5AkzeIvqjv88MNr6dKl/S5DkmaVW2655YdVtWh0+6wNg6VLl7Jly5Z+lyFJs0qSB8Zqd5hIkmQYSJIMA0kShoEkCcNAkoRhIEnCMJAksQ9hkGRj+8Hu27va/jLJXUm+l+RvkyzsWnZOkqEkdyc5pat9VWsbSnJ2V/uyJDe29sv9UW5Jmnn7smfwOTrf095tM3BsVf0m8E90fr915Ie81wAva+t8Osl+7ScI/wo4FTgGOLP1hc4vQp1fVS8BHqPz04GSpBm01zCoqm8BO0e1fb39IhN0flBk5Cf6VgOXtR8rvw8YAo5vl6H249s/o/OjHauTBDiRzi87QecHyk/v8T5pllp69ldYevZX+l3GlJqL90lz01QcM/iPwFfb9GJ++Ye6t7W28dpfCOzqCpaR9jElWZ9kS5Itw8PDU1C6ptJEX/imu/946+3pevbWdyLXJc0mPX03UZI/pvMj3pdMTTl7VlUbgA0AK1as8Lu3Z9jIi979H/ntMef31r/X25vs8l5uY6Km+vqkmTLpMEjyNuCNwEldP7qxHTiqq9uS1sY47Y8CC5MsaHsH3f2lCfGFWJq8SQ0TJVkFfAB4U/ux7xFXAWuSPDfJMjq/0HQTcDOwvJ05tD+dg8xXtRC5Hjijrb8WuHJyd0WDziEVaXDty6mllwLfAY5Osi3JOuBTwPOBzUluS/K/AKpqK3AFcAfwNeCsqnq6vet/F3AtcCdwResL8EHgvyYZonMM4aIpvYeSpL3a6zBRVZ05RvO4L9hVdR5w3hjt1wDXjNF+L52zjSRJfeInkCVJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CaUX4lhwaVYSBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDKS+8nMHGhSGgSTJMJAkGQaSJAwDSRKGgSQJw0AaKJ5dpH4xDCRJhoEkyTCQJLEPYZBkY5IdSW7vajssyeYk97S/h7b2JPlkkqEk30tyXNc6a1v/e5Ks7Wp/VZLvt3U+mSRTfSclSXu2L3sGnwNWjWo7G7iuqpYD17V5gFOB5e2yHrgQOuEBnAucABwPnDsSIK3Pf+pab/RtSZKm2V7DoKq+Bewc1bwauLhNXwyc3tX++eq4AViY5EjgFGBzVe2sqseAzcCqtuwFVXVDVRXw+a7rkiTNkMkeMziiqh5q0w8DR7TpxcCDXf22tbY9tW8bo31MSdYn2ZJky/Dw8CRL10R4qqM0P/R8ALm9o68pqGVfbmtDVa2oqhWLFi2aiZuU+sow1kyZbBg80oZ4aH93tPbtwFFd/Za0tj21LxmjXZI0gyYbBlcBI2cErQWu7Gp/azuraCXweBtOuhY4Ocmh7cDxycC1bdkTSVa2s4je2nVdkqQZsmBvHZJcCrweODzJNjpnBX0EuCLJOuAB4M2t+zXAacAQ8BTwdoCq2pnkw8DNrd+HqmrkoPQ76ZyxdADw1XaRJM2gvYZBVZ05zqKTxuhbwFnjXM9GYOMY7VuAY/dWhyRp+vgJZEmSYSBJMgykWcVTTTVdDANJkmEgSTIMJEkYBpIkDANJEoaBJAnDQJKEYSDNan7uQFPFMJAkGQbSXOKegibLMJAkGQbSXOTegSbKMJAkGQaSJMNAkoRhIM15nmGkfWEYSJIMA2m+cU9BYzEMJEmGgTTfuacgMAwkSRgGkiR6DIMk70uyNcntSS5N8rwky5LcmGQoyeVJ9m99n9vmh9rypV3Xc05rvzvJKb3dJUnSRE06DJIsBv4QWFFVxwL7AWuAjwLnV9VLgMeAdW2VdcBjrf381o8kx7T1XgasAj6dZL/J1iVJmrheh4kWAAckWQAcCDwEnAhsassvBk5v06vbPG35SUnS2i+rqp9W1X3AEHB8j3VJmiQPKM9Pkw6DqtoOfAz4AZ0QeBy4BdhVVbtbt23A4ja9GHiwrbu79X9hd/sY6/ySJOuTbEmyZXh4eLKlS5JG6WWY6FA67+qXAS8CDqIzzDNtqmpDVa2oqhWLFi2azpuSpHmll2GiNwD3VdVwVf0c+BLwGmBhGzYCWAJsb9PbgaMA2vJDgEe728dYR5I0A3oJgx8AK5Mc2Mb+TwLuAK4Hzmh91gJXtumr2jxt+Teqqlr7mna20TJgOXBTD3VJkiZowd67jK2qbkyyCfgusBu4FdgAfAW4LMmft7aL2ioXAV9IMgTspHMGEVW1NckVdIJkN3BWVT092bokSRM36TAAqKpzgXNHNd/LGGcDVdVPgN8d53rOA87rpRZJ0uT5CWRJkmEgSTIMJEkYBpL2wk8kzw+GgSTJMJAkGQYaxSEBaX4yDCRJhoEkyTCQJGEYSJIwDCRNkCcZzE2GgSTJMJAkGQaSJAwDSRKGgSQJw0CShGEgqUeeajo3GAaSJMNAkmQYSJIwDCRJGAaSJAwDSRI9hkGShUk2JbkryZ1JXp3ksCSbk9zT/h7a+ibJJ5MMJflekuO6rmdt639PkrW93ilJ0sT0umdwAfC1qnop8HLgTuBs4LqqWg5c1+YBTgWWt8t64EKAJIcB5wInAMcD544EiCRpZkw6DJIcArwOuAigqn5WVbuA1cDFrdvFwOltejXw+eq4AViY5EjgFGBzVe2sqseAzcCqydYlSZq4XvYMlgHDwGeT3JrkM0kOAo6oqodan4eBI9r0YuDBrvW3tbbx2p8lyfokW5JsGR4e7qF0SVK3XsJgAXAccGFVvRL4F34xJARAVRVQPdzGL6mqDVW1oqpWLFq0aKquVtIU8uspZqdewmAbsK2qbmzzm+iEwyNt+If2d0dbvh04qmv9Ja1tvHZJ0gyZdBhU1cPAg0mObk0nAXcAVwEjZwStBa5s01cBb21nFa0EHm/DSdcCJyc5tB04Prm1SZJmyIIe1383cEmS/YF7gbfTCZgrkqwDHgDe3PpeA5wGDAFPtb5U1c4kHwZubv0+VFU7e6xLkjQBPYVBVd0GrBhj0Ulj9C3grHGuZyOwsZdaJEmT5yeQJUmGgSTJMJAkYRhImmZ+7mB2MAwkSYaBJMkwkCRhGEiSMAwkSRgG855nekgCw0CShGEgScIwkCRhGEiSMAwkzTBPWhhMhoEkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJPWZn0geDD2HQZL9ktya5Oo2vyzJjUmGklyeZP/W/tw2P9SWL+26jnNa+91JTum1JknSxEzFnsF7gDu75j8KnF9VLwEeA9a19nXAY639/NaPJMcAa4CXAauATyfZbwrqkiTto57CIMkS4LeBz7T5ACcCm1qXi4HT2/TqNk9bflLrvxq4rKp+WlX3AUPA8b3UJUmamF73DD4BfAB4ps2/ENhVVbvb/DZgcZteDDwI0JY/3vr/a/sY6/ySJOuTbEmyZXh4uMfSJUkjJh0GSd4I7KiqW6awnj2qqg1VtaKqVixatGimblaS5rwFPaz7GuBNSU4Dnge8ALgAWJhkQXv3vwTY3vpvB44CtiVZABwCPNrVPqJ7HUnSDJj0nkFVnVNVS6pqKZ0DwN+oqrcA1wNntG5rgSvb9FVtnrb8G1VVrX1NO9toGbAcuGmydUmSJq6XPYPxfBC4LMmfA7cCF7X2i4AvJBkCdtIJEKpqa5IrgDuA3cBZVfX0NNQlSRrHlIRBVX0T+Gabvpcxzgaqqp8AvzvO+ucB501FLZKkifMTyPOMn/bUoHMb7Q/DQJJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSBpwfu5gZhgGkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJA0i/hp5OljGEiSDANJEizodwGaGe5aS9oT9wwkSYaBJMkwkCTRQxgkOSrJ9UnuSLI1yXta+2FJNie5p/09tLUnySeTDCX5XpLjuq5rbet/T5K1vd8tSdJE9LJnsBt4f1UdA6wEzkpyDHA2cF1VLQeua/MApwLL22U9cCF0wgM4FzgBOB44dyRAJGlP/NzB1Jl0GFTVQ1X13Tb9I+BOYDGwGri4dbsYOL1NrwY+Xx03AAuTHAmcAmyuqp1V9RiwGVg12bokSRM3JccMkiwFXgncCBxRVQ+1RQ8DR7TpxcCDXatta23jtUuSZkjPYZDkYOCLwHur6onuZVVVQPV6G123tT7JliRbhoeHp+pqJWne6ykMkjyHThBcUlVfas2PtOEf2t8drX07cFTX6kta23jtz1JVG6pqRVWtWLRoUS+lS5K69HI2UYCLgDur6uNdi64CRs4IWgtc2dX+1nZW0Urg8TacdC1wcpJD24Hjk1ubJO0TDyT3rpevo3gN8AfA95Pc1tr+CPgIcEWSdcADwJvbsmuA04Ah4Cng7QBVtTPJh4GbW78PVdXOHuqSJE3QpMOgqr4NZJzFJ43Rv4CzxrmujcDGydYiSeqNn0CWJBkGkiTDYM7ygJqkiTAMJM05vhmaOMNAkmQYSJIMA0nzgMNGe2cYSJIMA0mSYSBJwjCQJGEYzBkeIJPUC8NA0rzjm6dnMwwkSYaBJMkwkCSHjTAMZi03XklTyTCQJBkGkiTDQJKeZT4OwxoGs8R83DglzRzDQJJkGEjS3syHPXPDYAJGbxDzYQOR9Gxz8X/fMJhCU7lxzMWNTdLgMgymiS/m0vwxF/7fByYMkqxKcneSoSRn97ueqTYXNhZJ+2Y2/r8PRBgk2Q/4K+BU4BjgzCTH9Leq6X1CZ+PGImlyZsPxxoEIA+B4YKiq7q2qnwGXAaun+0YH6QkaxI1D0swYhNehVNWM3+izikjOAFZV1Tva/B8AJ1TVu0b1Ww+sb7NHA3fv400cDvxwisqdStY1MdY1MdY1MfOlrl+rqkWjGxdM4Q1Mu6raAGyY6HpJtlTVimkoqSfWNTHWNTHWNTHzva5BGSbaDhzVNb+ktUmSZsCghMHNwPIky5LsD6wBrupzTZI0bwzEMFFV7U7yLuBaYD9gY1VtncKbmPDQ0gyxromxromxromZ13UNxAFkSVJ/DcowkSSpjwwDSdLcD4NB+ZqLJBuT7Ehye1fbYUk2J7mn/T20D3UdleT6JHck2ZrkPYNQW5LnJbkpyT+2uv6stS9LcmN7Pi9vJxzMqCT7Jbk1ydWDUlOr4/4k309yW5ItrW0QtrGFSTYluSvJnUle3e+6khzdHqeRyxNJ3tvvulpt72vb/O1JLm3/C9O+jc3pMBiwr7n4HLBqVNvZwHVVtRy4rs3PtN3A+6vqGGAlcFZ7jPpd20+BE6vq5cArgFVJVgIfBc6vqpcAjwHrZrgugPcAd3bND0JNI36rql7RdV56v59HgAuAr1XVS4GX03ns+lpXVd3dHqdXAK8CngL+tt91JVkM/CGwoqqOpXNCzRpmYhurqjl7AV4NXNs1fw5wTh/rWQrc3jV/N3Bkmz4SuHsAHrMrgf8wSLUBBwLfBU6g80nMBWM9vzNUyxI6LxInAlcD6XdNXbXdDxw+qq2vzyNwCHAf7WSVQalrVC0nA/8wCHUBi4EHgcPonO15NXDKTGxjc3rPgF88sCO2tbZBcURVPdSmHwaO6GcxSZYCrwRuZABqa8MxtwE7gM3A/wN2VdXu1qUfz+cngA8Az7T5Fw5ATSMK+HqSW9pXt0D/n8dlwDDw2Ta09pkkBw1AXd3WAJe26b7WVVXbgY8BPwAeAh4HbmEGtrG5HgazRnUiv2/n+SY5GPgi8N6qeqJ7Wb9qq6qnq7Mbv4TOlxm+dKZr6JbkjcCOqrqln3XswWur6jg6w6JnJXld98I+PY8LgOOAC6vqlcC/MGropZ/bfht7fxPwf0Yv60dd7RjFajoh+iLgIJ49vDwt5noYDPrXXDyS5EiA9ndHP4pI8hw6QXBJVX1pkGoDqKpdwPV0do8XJhn5sORMP5+vAd6U5H4636x7Ip3x8H7W9K/au0qqaged8e/j6f/zuA3YVlU3tvlNdMKh33WNOBX4blU90ub7XdcbgPuqariqfg58ic52N+3b2FwPg0H/mourgLVtei2d8foZlSTARcCdVfXxQaktyaIkC9v0AXSOY9xJJxTO6EddVXVOVS2pqqV0tqVvVNVb+lnTiCQHJXn+yDSdcfDb6fPzWFUPAw8mObo1nQTc0e+6upzJL4aIoP91/QBYmeTA9r858nhN/zbWr4M2M3hA5jTgn+iMN/9xH+u4lM4Y4M/pvFtaR2e8+TrgHuDvgcP6UNdr6ewKfw+4rV1O63dtwG8Ct7a6bgf+pLW/GLgJGKKza//cPj2frweuHpSaWg3/2C5bR7b1fj+PrYZXAFvac/ll4NABqesg4FHgkK62Qajrz4C72nb/BeC5M7GN+XUUkqQ5P0wkSdoHhoEkyTCQJBkGkiQMA0kShoEkCcNAkgT8f+zQR7+atWzmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "_ = plt.hist(y_train*100, bins='auto')\n",
        "plt.title(\"Train Histogram\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-mUoOZFGBKC"
      },
      "source": [
        "## Test of our base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rmhc4MPGIyw",
        "outputId": "7123512e-ad0e-4551-ee4c-6dba7ff312e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2048)]            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 262,401\n",
            "Trainable params: 262,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_final = keras.Model(inputs=final_model.layers[3].input, outputs=final_model.layers[4].output)\n",
        "model_final.trainable = True\n",
        "model_final.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q_gjyXW8Gkd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d237949f-484b-4710-d506-dca3393aaaf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3595/3595 [==============================] - 9s 2ms/step\n",
            "14377/14377 [==============================] - 25s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_val_pred = model_final.predict(x_val)\n",
        "y_train_pred = model_final.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg_rryYaHDZG",
        "outputId": "4e279d24-4d8b-423f-b4d7-c53ff854e411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.01749465, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.00545098 0.01282824 0.01739667 0.01984034 0.01876509 0.01571899\n",
            " 0.01186001 0.0058276 ], shape=(8,), dtype=float32)\n",
            "tf.Tensor([7.99723], shape=(1,), dtype=float32)\n",
            "tf.Tensor(0.017334638, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.0032213  0.01233381 0.01727043 0.01987219 0.01850417 0.01559626\n",
            " 0.01135642 0.00533285], shape=(8,), dtype=float32)\n",
            "tf.Tensor([7.986329], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(AAR_metric(y_val, y_val_pred))\n",
        "print(AAR_metric(y_train, y_train_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3kciXyd7TKA"
      },
      "source": [
        "## Test of our final model without last dense layers replaced by XGBoost regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwlkHEg77YnM"
      },
      "outputs": [],
      "source": [
        "xg_reg = XGBRegressor(objective ='reg:squarederror', verbosity=2, n_jobs = 10, learning_rate = 0.1, max_depth = 35, \n",
        "                      eval_metric='mae', tree_method='gpu_hist', gpu_id=0, predictor='gpu_predictor')\n",
        "\n",
        "xg_reg.fit(x_train,y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvrrhNMx8T3X"
      },
      "outputs": [],
      "source": [
        "y_val_pred = xg_reg.predict(x_val)\n",
        "y_train_pred = xg_reg.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvVM7htO8WvA",
        "outputId": "0876e894-d484-4ec6-ebf4-d08c97b423f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.015682062, shape=(), dtype=float32)\n",
            "tf.Tensor(0.019262753, shape=(), dtype=float32)\n",
            "tf.Tensor(0.016103636, shape=(), dtype=float32)\n",
            "tf.Tensor(0.01887714, shape=(), dtype=float32)\n",
            "tf.Tensor(0.018676082, shape=(), dtype=float32)\n",
            "tf.Tensor(0.016328454, shape=(), dtype=float32)\n",
            "tf.Tensor(0.014996841, shape=(), dtype=float32)\n",
            "0.008977595\n",
            "tf.Tensor([8.049485], shape=(1,), dtype=float32)\n",
            "tf.Tensor(0.00021891166, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00025325033, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021649954, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00020756247, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0001875833, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00019738004, shape=(), dtype=float32)\n",
            "tf.Tensor(0.00021674715, shape=(), dtype=float32)\n",
            "0.0002146763\n",
            "tf.Tensor([9.976643], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(AAR_metric(y_val, y_val_pred))\n",
        "print(AAR_metric(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2MDnG-S8c-1"
      },
      "source": [
        "## Test of our final model without last dense layers replaced by Light GBM regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahCHRbTM9MJi"
      },
      "outputs": [],
      "source": [
        "lgb_train = lgb.Dataset(x_train, y_train)\n",
        "lgb_eval = lgb.Dataset(x_val, y_val, reference=lgb_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07Q0KE_E8gCn",
        "outputId": "e34f566a-6f1e-4806-f810-b196807c496f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\tvalid_0's l1: 0.0972531\n",
            "Training until validation scores don't improve for 20 rounds.\n",
            "[2]\tvalid_0's l1: 0.088045\n",
            "[3]\tvalid_0's l1: 0.079797\n",
            "[4]\tvalid_0's l1: 0.0724194\n",
            "[5]\tvalid_0's l1: 0.0658224\n",
            "[6]\tvalid_0's l1: 0.0599321\n",
            "[7]\tvalid_0's l1: 0.0546803\n",
            "[8]\tvalid_0's l1: 0.049991\n",
            "[9]\tvalid_0's l1: 0.0458181\n",
            "[10]\tvalid_0's l1: 0.0421152\n",
            "[11]\tvalid_0's l1: 0.0388277\n",
            "[12]\tvalid_0's l1: 0.0359249\n",
            "[13]\tvalid_0's l1: 0.0333625\n",
            "[14]\tvalid_0's l1: 0.0311066\n",
            "[15]\tvalid_0's l1: 0.0291227\n",
            "[16]\tvalid_0's l1: 0.0273903\n",
            "[17]\tvalid_0's l1: 0.0258818\n",
            "[18]\tvalid_0's l1: 0.0245685\n",
            "[19]\tvalid_0's l1: 0.023431\n",
            "[20]\tvalid_0's l1: 0.0224521\n",
            "[21]\tvalid_0's l1: 0.0216097\n",
            "[22]\tvalid_0's l1: 0.0208867\n",
            "[23]\tvalid_0's l1: 0.0202687\n",
            "[24]\tvalid_0's l1: 0.0197424\n",
            "[25]\tvalid_0's l1: 0.0192971\n",
            "[26]\tvalid_0's l1: 0.0189185\n",
            "[27]\tvalid_0's l1: 0.0185979\n",
            "[28]\tvalid_0's l1: 0.0183274\n",
            "[29]\tvalid_0's l1: 0.0180977\n",
            "[30]\tvalid_0's l1: 0.0179028\n",
            "[31]\tvalid_0's l1: 0.01774\n",
            "[32]\tvalid_0's l1: 0.0176031\n",
            "[33]\tvalid_0's l1: 0.0174855\n",
            "[34]\tvalid_0's l1: 0.0173868\n",
            "[35]\tvalid_0's l1: 0.0173025\n",
            "[36]\tvalid_0's l1: 0.0172317\n",
            "[37]\tvalid_0's l1: 0.0171725\n",
            "[38]\tvalid_0's l1: 0.017121\n",
            "[39]\tvalid_0's l1: 0.0170775\n",
            "[40]\tvalid_0's l1: 0.0170399\n",
            "[41]\tvalid_0's l1: 0.0170085\n",
            "[42]\tvalid_0's l1: 0.0169798\n",
            "[43]\tvalid_0's l1: 0.0169556\n",
            "[44]\tvalid_0's l1: 0.0169353\n",
            "[45]\tvalid_0's l1: 0.0169166\n",
            "[46]\tvalid_0's l1: 0.0169005\n",
            "[47]\tvalid_0's l1: 0.0168863\n",
            "[48]\tvalid_0's l1: 0.0168748\n",
            "[49]\tvalid_0's l1: 0.0168642\n",
            "[50]\tvalid_0's l1: 0.0168542\n",
            "[51]\tvalid_0's l1: 0.0168467\n",
            "[52]\tvalid_0's l1: 0.0168387\n",
            "[53]\tvalid_0's l1: 0.0168322\n",
            "[54]\tvalid_0's l1: 0.016826\n",
            "[55]\tvalid_0's l1: 0.0168203\n",
            "[56]\tvalid_0's l1: 0.0168163\n",
            "[57]\tvalid_0's l1: 0.0168112\n",
            "[58]\tvalid_0's l1: 0.0168081\n",
            "[59]\tvalid_0's l1: 0.0168048\n",
            "[60]\tvalid_0's l1: 0.0168031\n",
            "[61]\tvalid_0's l1: 0.0168009\n",
            "[62]\tvalid_0's l1: 0.0167984\n",
            "[63]\tvalid_0's l1: 0.0167959\n",
            "[64]\tvalid_0's l1: 0.0167936\n",
            "[65]\tvalid_0's l1: 0.0167911\n",
            "[66]\tvalid_0's l1: 0.0167884\n",
            "[67]\tvalid_0's l1: 0.0167866\n",
            "[68]\tvalid_0's l1: 0.016785\n",
            "[69]\tvalid_0's l1: 0.0167834\n",
            "[70]\tvalid_0's l1: 0.0167815\n",
            "[71]\tvalid_0's l1: 0.0167799\n",
            "[72]\tvalid_0's l1: 0.0167785\n",
            "[73]\tvalid_0's l1: 0.016776\n",
            "[74]\tvalid_0's l1: 0.0167759\n",
            "[75]\tvalid_0's l1: 0.0167747\n",
            "[76]\tvalid_0's l1: 0.016773\n",
            "[77]\tvalid_0's l1: 0.0167723\n",
            "[78]\tvalid_0's l1: 0.0167717\n",
            "[79]\tvalid_0's l1: 0.0167698\n",
            "[80]\tvalid_0's l1: 0.0167685\n",
            "[81]\tvalid_0's l1: 0.0167659\n",
            "[82]\tvalid_0's l1: 0.0167659\n",
            "[83]\tvalid_0's l1: 0.016765\n",
            "[84]\tvalid_0's l1: 0.0167626\n",
            "[85]\tvalid_0's l1: 0.0167624\n",
            "[86]\tvalid_0's l1: 0.0167605\n",
            "[87]\tvalid_0's l1: 0.0167598\n",
            "[88]\tvalid_0's l1: 0.0167577\n",
            "[89]\tvalid_0's l1: 0.0167574\n",
            "[90]\tvalid_0's l1: 0.0167557\n",
            "[91]\tvalid_0's l1: 0.0167548\n",
            "[92]\tvalid_0's l1: 0.0167544\n",
            "[93]\tvalid_0's l1: 0.0167537\n",
            "[94]\tvalid_0's l1: 0.0167525\n",
            "[95]\tvalid_0's l1: 0.0167517\n",
            "[96]\tvalid_0's l1: 0.016751\n",
            "[97]\tvalid_0's l1: 0.0167507\n",
            "[98]\tvalid_0's l1: 0.0167506\n",
            "[99]\tvalid_0's l1: 0.0167503\n",
            "[100]\tvalid_0's l1: 0.0167499\n",
            "[101]\tvalid_0's l1: 0.0167495\n",
            "[102]\tvalid_0's l1: 0.0167492\n",
            "[103]\tvalid_0's l1: 0.0167483\n",
            "[104]\tvalid_0's l1: 0.0167474\n",
            "[105]\tvalid_0's l1: 0.0167478\n",
            "[106]\tvalid_0's l1: 0.0167465\n",
            "[107]\tvalid_0's l1: 0.0167468\n",
            "[108]\tvalid_0's l1: 0.0167463\n",
            "[109]\tvalid_0's l1: 0.0167457\n",
            "[110]\tvalid_0's l1: 0.0167449\n",
            "[111]\tvalid_0's l1: 0.0167448\n",
            "[112]\tvalid_0's l1: 0.0167442\n",
            "[113]\tvalid_0's l1: 0.0167436\n",
            "[114]\tvalid_0's l1: 0.0167434\n",
            "[115]\tvalid_0's l1: 0.016742\n",
            "[116]\tvalid_0's l1: 0.0167418\n",
            "[117]\tvalid_0's l1: 0.016741\n",
            "[118]\tvalid_0's l1: 0.0167404\n",
            "[119]\tvalid_0's l1: 0.0167386\n",
            "[120]\tvalid_0's l1: 0.0167393\n",
            "[121]\tvalid_0's l1: 0.0167379\n",
            "[122]\tvalid_0's l1: 0.0167371\n",
            "[123]\tvalid_0's l1: 0.016737\n",
            "[124]\tvalid_0's l1: 0.0167365\n",
            "[125]\tvalid_0's l1: 0.0167363\n",
            "[126]\tvalid_0's l1: 0.016736\n",
            "[127]\tvalid_0's l1: 0.0167358\n",
            "[128]\tvalid_0's l1: 0.0167346\n",
            "[129]\tvalid_0's l1: 0.0167343\n",
            "[130]\tvalid_0's l1: 0.0167337\n",
            "[131]\tvalid_0's l1: 0.0167332\n",
            "[132]\tvalid_0's l1: 0.0167324\n",
            "[133]\tvalid_0's l1: 0.0167315\n",
            "[134]\tvalid_0's l1: 0.016731\n",
            "[135]\tvalid_0's l1: 0.0167305\n",
            "[136]\tvalid_0's l1: 0.0167298\n",
            "[137]\tvalid_0's l1: 0.016729\n",
            "[138]\tvalid_0's l1: 0.0167293\n",
            "[139]\tvalid_0's l1: 0.0167284\n",
            "[140]\tvalid_0's l1: 0.016728\n",
            "[141]\tvalid_0's l1: 0.0167281\n",
            "[142]\tvalid_0's l1: 0.0167269\n",
            "[143]\tvalid_0's l1: 0.0167268\n",
            "[144]\tvalid_0's l1: 0.0167268\n",
            "[145]\tvalid_0's l1: 0.0167256\n",
            "[146]\tvalid_0's l1: 0.0167253\n",
            "[147]\tvalid_0's l1: 0.0167253\n",
            "[148]\tvalid_0's l1: 0.0167254\n",
            "[149]\tvalid_0's l1: 0.0167251\n",
            "[150]\tvalid_0's l1: 0.0167246\n",
            "[151]\tvalid_0's l1: 0.0167248\n",
            "[152]\tvalid_0's l1: 0.0167242\n",
            "[153]\tvalid_0's l1: 0.0167241\n",
            "[154]\tvalid_0's l1: 0.0167236\n",
            "[155]\tvalid_0's l1: 0.0167238\n",
            "[156]\tvalid_0's l1: 0.0167237\n",
            "[157]\tvalid_0's l1: 0.0167239\n",
            "[158]\tvalid_0's l1: 0.0167239\n",
            "[159]\tvalid_0's l1: 0.0167233\n",
            "[160]\tvalid_0's l1: 0.0167228\n",
            "[161]\tvalid_0's l1: 0.0167222\n",
            "[162]\tvalid_0's l1: 0.0167222\n",
            "[163]\tvalid_0's l1: 0.0167221\n",
            "[164]\tvalid_0's l1: 0.0167215\n",
            "[165]\tvalid_0's l1: 0.0167215\n",
            "[166]\tvalid_0's l1: 0.0167218\n",
            "[167]\tvalid_0's l1: 0.0167215\n",
            "[168]\tvalid_0's l1: 0.0167214\n",
            "[169]\tvalid_0's l1: 0.0167206\n",
            "[170]\tvalid_0's l1: 0.0167198\n",
            "[171]\tvalid_0's l1: 0.0167193\n",
            "[172]\tvalid_0's l1: 0.0167186\n",
            "[173]\tvalid_0's l1: 0.016718\n",
            "[174]\tvalid_0's l1: 0.0167184\n",
            "[175]\tvalid_0's l1: 0.0167186\n",
            "[176]\tvalid_0's l1: 0.0167187\n",
            "[177]\tvalid_0's l1: 0.0167186\n",
            "[178]\tvalid_0's l1: 0.0167186\n",
            "[179]\tvalid_0's l1: 0.0167189\n",
            "[180]\tvalid_0's l1: 0.0167186\n",
            "[181]\tvalid_0's l1: 0.0167179\n",
            "[182]\tvalid_0's l1: 0.0167181\n",
            "[183]\tvalid_0's l1: 0.0167171\n",
            "[184]\tvalid_0's l1: 0.016717\n",
            "[185]\tvalid_0's l1: 0.0167169\n",
            "[186]\tvalid_0's l1: 0.0167163\n",
            "[187]\tvalid_0's l1: 0.0167164\n",
            "[188]\tvalid_0's l1: 0.0167159\n",
            "[189]\tvalid_0's l1: 0.0167159\n",
            "[190]\tvalid_0's l1: 0.0167161\n",
            "[191]\tvalid_0's l1: 0.0167157\n",
            "[192]\tvalid_0's l1: 0.0167157\n",
            "[193]\tvalid_0's l1: 0.0167151\n",
            "[194]\tvalid_0's l1: 0.016715\n",
            "[195]\tvalid_0's l1: 0.0167141\n",
            "[196]\tvalid_0's l1: 0.0167138\n",
            "[197]\tvalid_0's l1: 0.016713\n",
            "[198]\tvalid_0's l1: 0.0167132\n",
            "[199]\tvalid_0's l1: 0.0167131\n",
            "[200]\tvalid_0's l1: 0.0167125\n",
            "[201]\tvalid_0's l1: 0.0167121\n",
            "[202]\tvalid_0's l1: 0.0167119\n",
            "[203]\tvalid_0's l1: 0.0167116\n",
            "[204]\tvalid_0's l1: 0.0167115\n",
            "[205]\tvalid_0's l1: 0.0167113\n",
            "[206]\tvalid_0's l1: 0.0167106\n",
            "[207]\tvalid_0's l1: 0.0167109\n",
            "[208]\tvalid_0's l1: 0.016711\n",
            "[209]\tvalid_0's l1: 0.0167108\n",
            "[210]\tvalid_0's l1: 0.0167112\n",
            "[211]\tvalid_0's l1: 0.0167111\n",
            "[212]\tvalid_0's l1: 0.0167113\n",
            "[213]\tvalid_0's l1: 0.0167113\n",
            "[214]\tvalid_0's l1: 0.016711\n",
            "[215]\tvalid_0's l1: 0.01671\n",
            "[216]\tvalid_0's l1: 0.0167104\n",
            "[217]\tvalid_0's l1: 0.0167107\n",
            "[218]\tvalid_0's l1: 0.01671\n",
            "[219]\tvalid_0's l1: 0.01671\n",
            "[220]\tvalid_0's l1: 0.0167098\n",
            "[221]\tvalid_0's l1: 0.0167101\n",
            "[222]\tvalid_0's l1: 0.0167097\n",
            "[223]\tvalid_0's l1: 0.0167091\n",
            "[224]\tvalid_0's l1: 0.0167082\n",
            "[225]\tvalid_0's l1: 0.0167082\n",
            "[226]\tvalid_0's l1: 0.0167081\n",
            "[227]\tvalid_0's l1: 0.016708\n",
            "[228]\tvalid_0's l1: 0.0167083\n",
            "[229]\tvalid_0's l1: 0.0167082\n",
            "[230]\tvalid_0's l1: 0.0167078\n",
            "[231]\tvalid_0's l1: 0.0167073\n",
            "[232]\tvalid_0's l1: 0.0167082\n",
            "[233]\tvalid_0's l1: 0.0167082\n",
            "[234]\tvalid_0's l1: 0.0167087\n",
            "[235]\tvalid_0's l1: 0.0167088\n",
            "[236]\tvalid_0's l1: 0.0167093\n",
            "[237]\tvalid_0's l1: 0.0167099\n",
            "[238]\tvalid_0's l1: 0.0167088\n",
            "[239]\tvalid_0's l1: 0.0167084\n",
            "[240]\tvalid_0's l1: 0.0167084\n",
            "[241]\tvalid_0's l1: 0.0167087\n",
            "[242]\tvalid_0's l1: 0.0167089\n",
            "[243]\tvalid_0's l1: 0.0167085\n",
            "[244]\tvalid_0's l1: 0.0167091\n",
            "[245]\tvalid_0's l1: 0.0167086\n",
            "[246]\tvalid_0's l1: 0.0167087\n",
            "[247]\tvalid_0's l1: 0.0167089\n",
            "[248]\tvalid_0's l1: 0.0167081\n",
            "[249]\tvalid_0's l1: 0.0167079\n",
            "[250]\tvalid_0's l1: 0.016709\n",
            "[251]\tvalid_0's l1: 0.0167089\n",
            "Early stopping, best iteration is:\n",
            "[231]\tvalid_0's l1: 0.0167073\n"
          ]
        }
      ],
      "source": [
        "params = {\n",
        "    'task': 'train', \n",
        "    'boosting': 'gbdt',\n",
        "    'objective': 'regression',\n",
        "    'num_leaves': 40,\n",
        "    'metric': {'l1'},\n",
        "    'verbose': -1,\n",
        "    'n_estimators' : 300,\n",
        "    'learning_rates' : 'eta',\n",
        "    'tree_learner' : 'voting',\n",
        "    'num_boost_round' : 300\n",
        "}\n",
        "\n",
        "LGBmodel = lgb.train(params,\n",
        "                 train_set=lgb_train,\n",
        "                 valid_sets=lgb_eval,\n",
        "                 early_stopping_rounds=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXEfKg2d9UUR"
      },
      "outputs": [],
      "source": [
        "y_val_pred = LGBmodel.predict(x_val)\n",
        "y_train_pred = LGBmodel.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKZFKlUE9hGn",
        "outputId": "eb0f1901-3cde-4e54-ac56-93f3b00cefcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(0.013781094, shape=(), dtype=float32)\n",
            "tf.Tensor(0.01715588, shape=(), dtype=float32)\n",
            "tf.Tensor(0.014945913, shape=(), dtype=float32)\n",
            "tf.Tensor(0.017966801, shape=(), dtype=float32)\n",
            "tf.Tensor(0.018246852, shape=(), dtype=float32)\n",
            "tf.Tensor(0.015416433, shape=(), dtype=float32)\n",
            "tf.Tensor(0.013256189, shape=(), dtype=float32)\n",
            "0.008165327\n",
            "tf.Tensor([8.164072], shape=(1,), dtype=float32)\n",
            "tf.Tensor(0.009943959, shape=(), dtype=float32)\n",
            "tf.Tensor(0.015220477, shape=(), dtype=float32)\n",
            "tf.Tensor(0.014210201, shape=(), dtype=float32)\n",
            "tf.Tensor(0.017115692, shape=(), dtype=float32)\n",
            "tf.Tensor(0.017082805, shape=(), dtype=float32)\n",
            "tf.Tensor(0.014520914, shape=(), dtype=float32)\n",
            "tf.Tensor(0.012114633, shape=(), dtype=float32)\n",
            "0.0077492483\n",
            "tf.Tensor([8.275942], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(AAR_metric(y_val, np.around(y_val_pred, 2)))\n",
        "print(AAR_metric(y_train, np.around(y_train_pred, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWvhMhQgF2wE"
      },
      "source": [
        "## Test of our final model without last dense layers replaced by CatBoost regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOjoWRqeF2ca",
        "outputId": "9be53c00-536e-4d5b-f36b-0b2f96d61f2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Default metric period is 5 because MAE is/are not implemented for GPU\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.1071542\ttest: 0.1072402\tbest: 0.1072402 (0)\ttotal: 131ms\tremaining: 32m 45s\n",
            "10:\tlearn: 0.1067478\ttest: 0.1068329\tbest: 0.1068329 (10)\ttotal: 836ms\tremaining: 18m 59s\n",
            "20:\tlearn: 0.1063421\ttest: 0.1064265\tbest: 0.1064265 (20)\ttotal: 1.48s\tremaining: 17m 35s\n",
            "30:\tlearn: 0.1059358\ttest: 0.1060195\tbest: 0.1060195 (30)\ttotal: 2.11s\tremaining: 17m\n",
            "40:\tlearn: 0.1055299\ttest: 0.1056128\tbest: 0.1056128 (40)\ttotal: 2.75s\tremaining: 16m 44s\n",
            "50:\tlearn: 0.1051238\ttest: 0.1052060\tbest: 0.1052060 (50)\ttotal: 3.4s\tremaining: 16m 36s\n",
            "60:\tlearn: 0.1047180\ttest: 0.1047993\tbest: 0.1047993 (60)\ttotal: 4.04s\tremaining: 16m 28s\n",
            "70:\tlearn: 0.1043119\ttest: 0.1043925\tbest: 0.1043925 (70)\ttotal: 4.67s\tremaining: 16m 22s\n",
            "80:\tlearn: 0.1039063\ttest: 0.1039862\tbest: 0.1039862 (80)\ttotal: 5.31s\tremaining: 16m 18s\n",
            "90:\tlearn: 0.1035001\ttest: 0.1035793\tbest: 0.1035793 (90)\ttotal: 5.95s\tremaining: 16m 14s\n",
            "100:\tlearn: 0.1030943\ttest: 0.1031726\tbest: 0.1031726 (100)\ttotal: 6.58s\tremaining: 16m 10s\n",
            "110:\tlearn: 0.1026880\ttest: 0.1027656\tbest: 0.1027656 (110)\ttotal: 7.21s\tremaining: 16m 7s\n",
            "120:\tlearn: 0.1022818\ttest: 0.1023586\tbest: 0.1023586 (120)\ttotal: 7.86s\tremaining: 16m 6s\n",
            "130:\tlearn: 0.1018758\ttest: 0.1019520\tbest: 0.1019520 (130)\ttotal: 8.49s\tremaining: 16m 3s\n",
            "140:\tlearn: 0.1014697\ttest: 0.1015450\tbest: 0.1015450 (140)\ttotal: 9.12s\tremaining: 16m 1s\n",
            "150:\tlearn: 0.1010632\ttest: 0.1011378\tbest: 0.1011378 (150)\ttotal: 9.78s\tremaining: 16m 1s\n",
            "160:\tlearn: 0.1006572\ttest: 0.1007310\tbest: 0.1007310 (160)\ttotal: 10.4s\tremaining: 16m\n",
            "170:\tlearn: 0.1002505\ttest: 0.1003235\tbest: 0.1003235 (170)\ttotal: 11.1s\tremaining: 15m 59s\n",
            "180:\tlearn: 0.0998449\ttest: 0.0999171\tbest: 0.0999171 (180)\ttotal: 11.7s\tremaining: 15m 56s\n",
            "190:\tlearn: 0.0994389\ttest: 0.0995103\tbest: 0.0995103 (190)\ttotal: 12.3s\tremaining: 15m 55s\n",
            "200:\tlearn: 0.0990328\ttest: 0.0991036\tbest: 0.0991036 (200)\ttotal: 13s\tremaining: 15m 55s\n",
            "210:\tlearn: 0.0986291\ttest: 0.0986989\tbest: 0.0986989 (210)\ttotal: 13.6s\tremaining: 15m 53s\n",
            "220:\tlearn: 0.0982300\ttest: 0.0982990\tbest: 0.0982990 (220)\ttotal: 14.3s\tremaining: 15m 53s\n",
            "230:\tlearn: 0.0978333\ttest: 0.0979015\tbest: 0.0979015 (230)\ttotal: 14.9s\tremaining: 15m 53s\n",
            "240:\tlearn: 0.0974382\ttest: 0.0975057\tbest: 0.0975057 (240)\ttotal: 15.6s\tremaining: 15m 54s\n",
            "250:\tlearn: 0.0970448\ttest: 0.0971114\tbest: 0.0971114 (250)\ttotal: 16.2s\tremaining: 15m 54s\n",
            "260:\tlearn: 0.0966520\ttest: 0.0967176\tbest: 0.0967176 (260)\ttotal: 16.9s\tremaining: 15m 55s\n",
            "270:\tlearn: 0.0962600\ttest: 0.0963249\tbest: 0.0963249 (270)\ttotal: 17.6s\tremaining: 15m 56s\n",
            "280:\tlearn: 0.0958695\ttest: 0.0959336\tbest: 0.0959336 (280)\ttotal: 18.3s\tremaining: 15m 58s\n",
            "290:\tlearn: 0.0954802\ttest: 0.0955435\tbest: 0.0955435 (290)\ttotal: 19s\tremaining: 15m 59s\n",
            "300:\tlearn: 0.0950912\ttest: 0.0951537\tbest: 0.0951537 (300)\ttotal: 19.7s\tremaining: 15m 59s\n",
            "310:\tlearn: 0.0947029\ttest: 0.0947647\tbest: 0.0947647 (310)\ttotal: 20.3s\tremaining: 16m\n",
            "320:\tlearn: 0.0943149\ttest: 0.0943759\tbest: 0.0943759 (320)\ttotal: 21s\tremaining: 16m 2s\n",
            "330:\tlearn: 0.0939276\ttest: 0.0939877\tbest: 0.0939877 (330)\ttotal: 21.7s\tremaining: 16m 3s\n",
            "340:\tlearn: 0.0935414\ttest: 0.0936009\tbest: 0.0936009 (340)\ttotal: 22.4s\tremaining: 16m 3s\n",
            "350:\tlearn: 0.0931548\ttest: 0.0932136\tbest: 0.0932136 (350)\ttotal: 23.1s\tremaining: 16m 4s\n",
            "360:\tlearn: 0.0927684\ttest: 0.0928265\tbest: 0.0928265 (360)\ttotal: 23.8s\tremaining: 16m 4s\n",
            "370:\tlearn: 0.0923829\ttest: 0.0924402\tbest: 0.0924402 (370)\ttotal: 24.5s\tremaining: 16m 5s\n",
            "380:\tlearn: 0.0919982\ttest: 0.0920549\tbest: 0.0920549 (380)\ttotal: 25.2s\tremaining: 16m 6s\n",
            "390:\tlearn: 0.0916131\ttest: 0.0916692\tbest: 0.0916692 (390)\ttotal: 25.9s\tremaining: 16m 7s\n",
            "400:\tlearn: 0.0912283\ttest: 0.0912837\tbest: 0.0912837 (400)\ttotal: 26.6s\tremaining: 16m 8s\n",
            "410:\tlearn: 0.0908442\ttest: 0.0908988\tbest: 0.0908988 (410)\ttotal: 27.3s\tremaining: 16m 8s\n",
            "420:\tlearn: 0.0904631\ttest: 0.0905173\tbest: 0.0905173 (420)\ttotal: 28s\tremaining: 16m 8s\n",
            "430:\tlearn: 0.0900849\ttest: 0.0901388\tbest: 0.0901388 (430)\ttotal: 28.7s\tremaining: 16m 9s\n",
            "440:\tlearn: 0.0897089\ttest: 0.0897627\tbest: 0.0897627 (440)\ttotal: 29.4s\tremaining: 16m 10s\n",
            "450:\tlearn: 0.0893358\ttest: 0.0893894\tbest: 0.0893894 (450)\ttotal: 30.1s\tremaining: 16m 10s\n",
            "460:\tlearn: 0.0889647\ttest: 0.0890179\tbest: 0.0890179 (460)\ttotal: 30.8s\tremaining: 16m 11s\n",
            "470:\tlearn: 0.0885947\ttest: 0.0886475\tbest: 0.0886475 (470)\ttotal: 31.5s\tremaining: 16m 12s\n",
            "480:\tlearn: 0.0882258\ttest: 0.0882781\tbest: 0.0882781 (480)\ttotal: 32.2s\tremaining: 16m 13s\n",
            "490:\tlearn: 0.0878582\ttest: 0.0879101\tbest: 0.0879101 (490)\ttotal: 33s\tremaining: 16m 13s\n",
            "500:\tlearn: 0.0874922\ttest: 0.0875436\tbest: 0.0875436 (500)\ttotal: 33.7s\tremaining: 16m 14s\n",
            "510:\tlearn: 0.0871264\ttest: 0.0871774\tbest: 0.0871774 (510)\ttotal: 34.4s\tremaining: 16m 15s\n",
            "520:\tlearn: 0.0867618\ttest: 0.0868123\tbest: 0.0868123 (520)\ttotal: 35.1s\tremaining: 16m 15s\n",
            "530:\tlearn: 0.0863976\ttest: 0.0864477\tbest: 0.0864477 (530)\ttotal: 35.8s\tremaining: 16m 15s\n",
            "540:\tlearn: 0.0860334\ttest: 0.0860829\tbest: 0.0860829 (540)\ttotal: 36.5s\tremaining: 16m 16s\n",
            "550:\tlearn: 0.0856703\ttest: 0.0857193\tbest: 0.0857193 (550)\ttotal: 37.2s\tremaining: 16m 16s\n",
            "560:\tlearn: 0.0853082\ttest: 0.0853568\tbest: 0.0853568 (560)\ttotal: 37.9s\tremaining: 16m 16s\n",
            "570:\tlearn: 0.0849458\ttest: 0.0849941\tbest: 0.0849941 (570)\ttotal: 38.7s\tremaining: 16m 16s\n",
            "580:\tlearn: 0.0845834\ttest: 0.0846310\tbest: 0.0846310 (580)\ttotal: 39.4s\tremaining: 16m 17s\n",
            "590:\tlearn: 0.0842211\ttest: 0.0842683\tbest: 0.0842683 (590)\ttotal: 40.1s\tremaining: 16m 17s\n",
            "600:\tlearn: 0.0838593\ttest: 0.0839060\tbest: 0.0839060 (600)\ttotal: 40.8s\tremaining: 16m 17s\n",
            "610:\tlearn: 0.0834980\ttest: 0.0835442\tbest: 0.0835442 (610)\ttotal: 41.5s\tremaining: 16m 18s\n",
            "620:\tlearn: 0.0831382\ttest: 0.0831842\tbest: 0.0831842 (620)\ttotal: 42.2s\tremaining: 16m 18s\n",
            "630:\tlearn: 0.0827813\ttest: 0.0828271\tbest: 0.0828271 (630)\ttotal: 43s\tremaining: 16m 18s\n",
            "640:\tlearn: 0.0824274\ttest: 0.0824731\tbest: 0.0824731 (640)\ttotal: 43.7s\tremaining: 16m 18s\n",
            "650:\tlearn: 0.0820747\ttest: 0.0821203\tbest: 0.0821203 (650)\ttotal: 44.4s\tremaining: 16m 18s\n",
            "660:\tlearn: 0.0817233\ttest: 0.0817689\tbest: 0.0817689 (660)\ttotal: 45.1s\tremaining: 16m 19s\n",
            "670:\tlearn: 0.0813732\ttest: 0.0814190\tbest: 0.0814190 (670)\ttotal: 45.9s\tremaining: 16m 19s\n",
            "680:\tlearn: 0.0810250\ttest: 0.0810707\tbest: 0.0810707 (680)\ttotal: 46.6s\tremaining: 16m 19s\n",
            "690:\tlearn: 0.0806783\ttest: 0.0807240\tbest: 0.0807240 (690)\ttotal: 47.3s\tremaining: 16m 19s\n",
            "700:\tlearn: 0.0803323\ttest: 0.0803781\tbest: 0.0803781 (700)\ttotal: 48s\tremaining: 16m 20s\n",
            "710:\tlearn: 0.0799874\ttest: 0.0800331\tbest: 0.0800331 (710)\ttotal: 48.8s\tremaining: 16m 20s\n",
            "720:\tlearn: 0.0796432\ttest: 0.0796887\tbest: 0.0796887 (720)\ttotal: 49.5s\tremaining: 16m 20s\n",
            "730:\tlearn: 0.0793002\ttest: 0.0793457\tbest: 0.0793457 (730)\ttotal: 50.2s\tremaining: 16m 20s\n",
            "740:\tlearn: 0.0789588\ttest: 0.0790041\tbest: 0.0790041 (740)\ttotal: 50.9s\tremaining: 16m 20s\n",
            "750:\tlearn: 0.0786173\ttest: 0.0786625\tbest: 0.0786625 (750)\ttotal: 51.7s\tremaining: 16m 20s\n",
            "760:\tlearn: 0.0782766\ttest: 0.0783216\tbest: 0.0783216 (760)\ttotal: 52.4s\tremaining: 16m 20s\n",
            "770:\tlearn: 0.0779361\ttest: 0.0779808\tbest: 0.0779808 (770)\ttotal: 53.1s\tremaining: 16m 20s\n",
            "780:\tlearn: 0.0775960\ttest: 0.0776406\tbest: 0.0776406 (780)\ttotal: 53.9s\tremaining: 16m 20s\n",
            "790:\tlearn: 0.0772564\ttest: 0.0773007\tbest: 0.0773007 (790)\ttotal: 54.6s\tremaining: 16m 20s\n",
            "800:\tlearn: 0.0769173\ttest: 0.0769615\tbest: 0.0769615 (800)\ttotal: 55.3s\tremaining: 16m 21s\n",
            "810:\tlearn: 0.0765788\ttest: 0.0766230\tbest: 0.0766230 (810)\ttotal: 56.1s\tremaining: 16m 21s\n",
            "820:\tlearn: 0.0762415\ttest: 0.0762855\tbest: 0.0762855 (820)\ttotal: 56.8s\tremaining: 16m 20s\n",
            "830:\tlearn: 0.0759059\ttest: 0.0759496\tbest: 0.0759496 (830)\ttotal: 57.5s\tremaining: 16m 20s\n",
            "840:\tlearn: 0.0755731\ttest: 0.0756168\tbest: 0.0756168 (840)\ttotal: 58.2s\tremaining: 16m 20s\n",
            "850:\tlearn: 0.0752422\ttest: 0.0752859\tbest: 0.0752859 (850)\ttotal: 59s\tremaining: 16m 20s\n",
            "860:\tlearn: 0.0749135\ttest: 0.0749569\tbest: 0.0749569 (860)\ttotal: 59.7s\tremaining: 16m 20s\n",
            "870:\tlearn: 0.0745864\ttest: 0.0746295\tbest: 0.0746295 (870)\ttotal: 1m\tremaining: 16m 20s\n",
            "880:\tlearn: 0.0742605\ttest: 0.0743033\tbest: 0.0743033 (880)\ttotal: 1m 1s\tremaining: 16m 20s\n",
            "890:\tlearn: 0.0739358\ttest: 0.0739782\tbest: 0.0739782 (890)\ttotal: 1m 1s\tremaining: 16m 20s\n",
            "900:\tlearn: 0.0736124\ttest: 0.0736546\tbest: 0.0736546 (900)\ttotal: 1m 2s\tremaining: 16m 19s\n",
            "910:\tlearn: 0.0732895\ttest: 0.0733315\tbest: 0.0733315 (910)\ttotal: 1m 3s\tremaining: 16m 19s\n",
            "920:\tlearn: 0.0729682\ttest: 0.0730099\tbest: 0.0730099 (920)\ttotal: 1m 4s\tremaining: 16m 19s\n",
            "930:\tlearn: 0.0726477\ttest: 0.0726891\tbest: 0.0726891 (930)\ttotal: 1m 4s\tremaining: 16m 20s\n",
            "940:\tlearn: 0.0723276\ttest: 0.0723686\tbest: 0.0723686 (940)\ttotal: 1m 5s\tremaining: 16m 19s\n",
            "950:\tlearn: 0.0720081\ttest: 0.0720486\tbest: 0.0720486 (950)\ttotal: 1m 6s\tremaining: 16m 19s\n",
            "960:\tlearn: 0.0716896\ttest: 0.0717298\tbest: 0.0717298 (960)\ttotal: 1m 7s\tremaining: 16m 19s\n",
            "970:\tlearn: 0.0713712\ttest: 0.0714113\tbest: 0.0714113 (970)\ttotal: 1m 7s\tremaining: 16m 19s\n",
            "980:\tlearn: 0.0710537\ttest: 0.0710935\tbest: 0.0710935 (980)\ttotal: 1m 8s\tremaining: 16m 19s\n",
            "990:\tlearn: 0.0707372\ttest: 0.0707769\tbest: 0.0707769 (990)\ttotal: 1m 9s\tremaining: 16m 19s\n",
            "1000:\tlearn: 0.0704212\ttest: 0.0704608\tbest: 0.0704608 (1000)\ttotal: 1m 10s\tremaining: 16m 19s\n",
            "1010:\tlearn: 0.0701056\ttest: 0.0701451\tbest: 0.0701451 (1010)\ttotal: 1m 10s\tremaining: 16m 18s\n",
            "1020:\tlearn: 0.0697903\ttest: 0.0698296\tbest: 0.0698296 (1020)\ttotal: 1m 11s\tremaining: 16m 18s\n",
            "1030:\tlearn: 0.0694765\ttest: 0.0695158\tbest: 0.0695158 (1030)\ttotal: 1m 12s\tremaining: 16m 18s\n",
            "1040:\tlearn: 0.0691649\ttest: 0.0692040\tbest: 0.0692040 (1040)\ttotal: 1m 12s\tremaining: 16m 18s\n",
            "1050:\tlearn: 0.0688554\ttest: 0.0688947\tbest: 0.0688947 (1050)\ttotal: 1m 13s\tremaining: 16m 18s\n",
            "1060:\tlearn: 0.0685481\ttest: 0.0685874\tbest: 0.0685874 (1060)\ttotal: 1m 14s\tremaining: 16m 17s\n",
            "1070:\tlearn: 0.0682424\ttest: 0.0682820\tbest: 0.0682820 (1070)\ttotal: 1m 15s\tremaining: 16m 17s\n",
            "1080:\tlearn: 0.0679387\ttest: 0.0679787\tbest: 0.0679787 (1080)\ttotal: 1m 15s\tremaining: 16m 17s\n",
            "1090:\tlearn: 0.0676357\ttest: 0.0676759\tbest: 0.0676759 (1090)\ttotal: 1m 16s\tremaining: 16m 16s\n",
            "1100:\tlearn: 0.0673340\ttest: 0.0673746\tbest: 0.0673746 (1100)\ttotal: 1m 17s\tremaining: 16m 17s\n",
            "1110:\tlearn: 0.0670327\ttest: 0.0670738\tbest: 0.0670738 (1110)\ttotal: 1m 18s\tremaining: 16m 16s\n",
            "1120:\tlearn: 0.0667328\ttest: 0.0667744\tbest: 0.0667744 (1120)\ttotal: 1m 18s\tremaining: 16m 16s\n",
            "1130:\tlearn: 0.0664342\ttest: 0.0664764\tbest: 0.0664764 (1130)\ttotal: 1m 19s\tremaining: 16m 16s\n",
            "1140:\tlearn: 0.0661363\ttest: 0.0661788\tbest: 0.0661788 (1140)\ttotal: 1m 20s\tremaining: 16m 15s\n",
            "1150:\tlearn: 0.0658389\ttest: 0.0658820\tbest: 0.0658820 (1150)\ttotal: 1m 21s\tremaining: 16m 15s\n",
            "1160:\tlearn: 0.0655421\ttest: 0.0655856\tbest: 0.0655856 (1160)\ttotal: 1m 21s\tremaining: 16m 15s\n",
            "1170:\tlearn: 0.0652462\ttest: 0.0652901\tbest: 0.0652901 (1170)\ttotal: 1m 22s\tremaining: 16m 15s\n",
            "1180:\tlearn: 0.0649508\ttest: 0.0649952\tbest: 0.0649952 (1180)\ttotal: 1m 23s\tremaining: 16m 15s\n",
            "1190:\tlearn: 0.0646559\ttest: 0.0647010\tbest: 0.0647010 (1190)\ttotal: 1m 24s\tremaining: 16m 15s\n",
            "1200:\tlearn: 0.0643621\ttest: 0.0644076\tbest: 0.0644076 (1200)\ttotal: 1m 24s\tremaining: 16m 15s\n",
            "1210:\tlearn: 0.0640681\ttest: 0.0641140\tbest: 0.0641140 (1210)\ttotal: 1m 25s\tremaining: 16m 14s\n",
            "1220:\tlearn: 0.0637749\ttest: 0.0638214\tbest: 0.0638214 (1220)\ttotal: 1m 26s\tremaining: 16m 14s\n",
            "1230:\tlearn: 0.0634821\ttest: 0.0635289\tbest: 0.0635289 (1230)\ttotal: 1m 27s\tremaining: 16m 14s\n",
            "1240:\tlearn: 0.0631913\ttest: 0.0632385\tbest: 0.0632385 (1240)\ttotal: 1m 27s\tremaining: 16m 13s\n",
            "1250:\tlearn: 0.0629029\ttest: 0.0629505\tbest: 0.0629505 (1250)\ttotal: 1m 28s\tremaining: 16m 13s\n",
            "1260:\tlearn: 0.0626165\ttest: 0.0626642\tbest: 0.0626642 (1260)\ttotal: 1m 29s\tremaining: 16m 12s\n",
            "1270:\tlearn: 0.0623315\ttest: 0.0623793\tbest: 0.0623793 (1270)\ttotal: 1m 30s\tremaining: 16m 12s\n",
            "1280:\tlearn: 0.0620477\ttest: 0.0620956\tbest: 0.0620956 (1280)\ttotal: 1m 30s\tremaining: 16m 12s\n",
            "1290:\tlearn: 0.0617657\ttest: 0.0618138\tbest: 0.0618138 (1290)\ttotal: 1m 31s\tremaining: 16m 11s\n",
            "1300:\tlearn: 0.0614853\ttest: 0.0615336\tbest: 0.0615336 (1300)\ttotal: 1m 32s\tremaining: 16m 11s\n",
            "1310:\tlearn: 0.0612058\ttest: 0.0612545\tbest: 0.0612545 (1310)\ttotal: 1m 33s\tremaining: 16m 11s\n",
            "1320:\tlearn: 0.0609274\ttest: 0.0609765\tbest: 0.0609765 (1320)\ttotal: 1m 33s\tremaining: 16m 10s\n",
            "1330:\tlearn: 0.0606497\ttest: 0.0606991\tbest: 0.0606991 (1330)\ttotal: 1m 34s\tremaining: 16m 10s\n",
            "1340:\tlearn: 0.0603732\ttest: 0.0604231\tbest: 0.0604231 (1340)\ttotal: 1m 35s\tremaining: 16m 10s\n",
            "1350:\tlearn: 0.0600975\ttest: 0.0601477\tbest: 0.0601477 (1350)\ttotal: 1m 35s\tremaining: 16m 9s\n",
            "1360:\tlearn: 0.0598231\ttest: 0.0598736\tbest: 0.0598736 (1360)\ttotal: 1m 36s\tremaining: 16m 9s\n",
            "1370:\tlearn: 0.0595483\ttest: 0.0595992\tbest: 0.0595992 (1370)\ttotal: 1m 37s\tremaining: 16m 8s\n",
            "1380:\tlearn: 0.0592743\ttest: 0.0593255\tbest: 0.0593255 (1380)\ttotal: 1m 38s\tremaining: 16m 8s\n",
            "1390:\tlearn: 0.0590015\ttest: 0.0590530\tbest: 0.0590530 (1390)\ttotal: 1m 38s\tremaining: 16m 8s\n",
            "1400:\tlearn: 0.0587287\ttest: 0.0587806\tbest: 0.0587806 (1400)\ttotal: 1m 39s\tremaining: 16m 7s\n",
            "1410:\tlearn: 0.0584574\ttest: 0.0585096\tbest: 0.0585096 (1410)\ttotal: 1m 40s\tremaining: 16m 7s\n",
            "1420:\tlearn: 0.0581857\ttest: 0.0582383\tbest: 0.0582383 (1420)\ttotal: 1m 41s\tremaining: 16m 7s\n",
            "1430:\tlearn: 0.0579141\ttest: 0.0579671\tbest: 0.0579671 (1430)\ttotal: 1m 41s\tremaining: 16m 6s\n",
            "1440:\tlearn: 0.0576431\ttest: 0.0576964\tbest: 0.0576964 (1440)\ttotal: 1m 42s\tremaining: 16m 6s\n",
            "1450:\tlearn: 0.0573749\ttest: 0.0574285\tbest: 0.0574285 (1450)\ttotal: 1m 43s\tremaining: 16m 6s\n",
            "1460:\tlearn: 0.0571088\ttest: 0.0571625\tbest: 0.0571625 (1460)\ttotal: 1m 44s\tremaining: 16m 5s\n",
            "1470:\tlearn: 0.0568445\ttest: 0.0568984\tbest: 0.0568984 (1470)\ttotal: 1m 44s\tremaining: 16m 5s\n",
            "1480:\tlearn: 0.0565822\ttest: 0.0566363\tbest: 0.0566363 (1480)\ttotal: 1m 45s\tremaining: 16m 5s\n",
            "1490:\tlearn: 0.0563213\ttest: 0.0563757\tbest: 0.0563757 (1490)\ttotal: 1m 46s\tremaining: 16m 4s\n",
            "1500:\tlearn: 0.0560621\ttest: 0.0561170\tbest: 0.0561170 (1500)\ttotal: 1m 47s\tremaining: 16m 4s\n",
            "1510:\tlearn: 0.0558044\ttest: 0.0558597\tbest: 0.0558597 (1510)\ttotal: 1m 48s\tremaining: 16m 4s\n",
            "1520:\tlearn: 0.0555479\ttest: 0.0556036\tbest: 0.0556036 (1520)\ttotal: 1m 48s\tremaining: 16m 3s\n",
            "1530:\tlearn: 0.0552917\ttest: 0.0553478\tbest: 0.0553478 (1530)\ttotal: 1m 49s\tremaining: 16m 3s\n",
            "1540:\tlearn: 0.0550363\ttest: 0.0550927\tbest: 0.0550927 (1540)\ttotal: 1m 50s\tremaining: 16m 2s\n",
            "1550:\tlearn: 0.0547823\ttest: 0.0548392\tbest: 0.0548392 (1550)\ttotal: 1m 51s\tremaining: 16m 2s\n",
            "1560:\tlearn: 0.0545287\ttest: 0.0545861\tbest: 0.0545861 (1560)\ttotal: 1m 51s\tremaining: 16m 2s\n",
            "1570:\tlearn: 0.0542758\ttest: 0.0543338\tbest: 0.0543338 (1570)\ttotal: 1m 52s\tremaining: 16m 1s\n",
            "1580:\tlearn: 0.0540232\ttest: 0.0540817\tbest: 0.0540817 (1580)\ttotal: 1m 53s\tremaining: 16m 1s\n",
            "1590:\tlearn: 0.0537717\ttest: 0.0538308\tbest: 0.0538308 (1590)\ttotal: 1m 54s\tremaining: 16m\n",
            "1600:\tlearn: 0.0535214\ttest: 0.0535809\tbest: 0.0535809 (1600)\ttotal: 1m 54s\tremaining: 16m\n",
            "1610:\tlearn: 0.0532707\ttest: 0.0533306\tbest: 0.0533306 (1610)\ttotal: 1m 55s\tremaining: 15m 59s\n",
            "1620:\tlearn: 0.0530204\ttest: 0.0530807\tbest: 0.0530807 (1620)\ttotal: 1m 56s\tremaining: 15m 59s\n",
            "1630:\tlearn: 0.0527701\ttest: 0.0528309\tbest: 0.0528309 (1630)\ttotal: 1m 56s\tremaining: 15m 58s\n",
            "1640:\tlearn: 0.0525202\ttest: 0.0525814\tbest: 0.0525814 (1640)\ttotal: 1m 57s\tremaining: 15m 58s\n",
            "1650:\tlearn: 0.0522721\ttest: 0.0523337\tbest: 0.0523337 (1650)\ttotal: 1m 58s\tremaining: 15m 57s\n",
            "1660:\tlearn: 0.0520265\ttest: 0.0520882\tbest: 0.0520882 (1660)\ttotal: 1m 59s\tremaining: 15m 56s\n",
            "1670:\tlearn: 0.0517823\ttest: 0.0518443\tbest: 0.0518443 (1670)\ttotal: 1m 59s\tremaining: 15m 56s\n",
            "1680:\tlearn: 0.0515406\ttest: 0.0516026\tbest: 0.0516026 (1680)\ttotal: 2m\tremaining: 15m 55s\n",
            "1690:\tlearn: 0.0513000\ttest: 0.0513622\tbest: 0.0513622 (1690)\ttotal: 2m 1s\tremaining: 15m 55s\n",
            "1700:\tlearn: 0.0510611\ttest: 0.0511235\tbest: 0.0511235 (1700)\ttotal: 2m 2s\tremaining: 15m 54s\n",
            "1710:\tlearn: 0.0508236\ttest: 0.0508859\tbest: 0.0508859 (1710)\ttotal: 2m 2s\tremaining: 15m 53s\n",
            "1720:\tlearn: 0.0505873\ttest: 0.0506497\tbest: 0.0506497 (1720)\ttotal: 2m 3s\tremaining: 15m 53s\n",
            "1730:\tlearn: 0.0503523\ttest: 0.0504148\tbest: 0.0504148 (1730)\ttotal: 2m 4s\tremaining: 15m 52s\n",
            "1740:\tlearn: 0.0501178\ttest: 0.0501804\tbest: 0.0501804 (1740)\ttotal: 2m 5s\tremaining: 15m 52s\n",
            "1750:\tlearn: 0.0498848\ttest: 0.0499476\tbest: 0.0499476 (1750)\ttotal: 2m 5s\tremaining: 15m 51s\n",
            "1760:\tlearn: 0.0496528\ttest: 0.0497157\tbest: 0.0497157 (1760)\ttotal: 2m 6s\tremaining: 15m 50s\n",
            "1770:\tlearn: 0.0494207\ttest: 0.0494837\tbest: 0.0494837 (1770)\ttotal: 2m 7s\tremaining: 15m 50s\n",
            "1780:\tlearn: 0.0491888\ttest: 0.0492518\tbest: 0.0492518 (1780)\ttotal: 2m 7s\tremaining: 15m 49s\n",
            "1790:\tlearn: 0.0489583\ttest: 0.0490215\tbest: 0.0490215 (1790)\ttotal: 2m 8s\tremaining: 15m 49s\n",
            "1800:\tlearn: 0.0487275\ttest: 0.0487908\tbest: 0.0487908 (1800)\ttotal: 2m 9s\tremaining: 15m 48s\n",
            "1810:\tlearn: 0.0484976\ttest: 0.0485608\tbest: 0.0485608 (1810)\ttotal: 2m 10s\tremaining: 15m 48s\n",
            "1820:\tlearn: 0.0482676\ttest: 0.0483308\tbest: 0.0483308 (1820)\ttotal: 2m 10s\tremaining: 15m 47s\n",
            "1830:\tlearn: 0.0480391\ttest: 0.0481022\tbest: 0.0481022 (1830)\ttotal: 2m 11s\tremaining: 15m 46s\n",
            "1840:\tlearn: 0.0478103\ttest: 0.0478734\tbest: 0.0478734 (1840)\ttotal: 2m 12s\tremaining: 15m 46s\n",
            "1850:\tlearn: 0.0475822\ttest: 0.0476454\tbest: 0.0476454 (1850)\ttotal: 2m 13s\tremaining: 15m 45s\n",
            "1860:\tlearn: 0.0473554\ttest: 0.0474186\tbest: 0.0474186 (1860)\ttotal: 2m 13s\tremaining: 15m 44s\n",
            "1870:\tlearn: 0.0471305\ttest: 0.0471936\tbest: 0.0471936 (1870)\ttotal: 2m 14s\tremaining: 15m 44s\n",
            "1880:\tlearn: 0.0469076\ttest: 0.0469706\tbest: 0.0469706 (1880)\ttotal: 2m 15s\tremaining: 15m 43s\n",
            "1890:\tlearn: 0.0466868\ttest: 0.0467497\tbest: 0.0467497 (1890)\ttotal: 2m 16s\tremaining: 15m 42s\n",
            "1900:\tlearn: 0.0464676\ttest: 0.0465303\tbest: 0.0465303 (1900)\ttotal: 2m 16s\tremaining: 15m 42s\n",
            "1910:\tlearn: 0.0462492\ttest: 0.0463121\tbest: 0.0463121 (1910)\ttotal: 2m 17s\tremaining: 15m 41s\n",
            "1920:\tlearn: 0.0460325\ttest: 0.0460954\tbest: 0.0460954 (1920)\ttotal: 2m 18s\tremaining: 15m 41s\n",
            "1930:\tlearn: 0.0458170\ttest: 0.0458799\tbest: 0.0458799 (1930)\ttotal: 2m 18s\tremaining: 15m 40s\n",
            "1940:\tlearn: 0.0456028\ttest: 0.0456657\tbest: 0.0456657 (1940)\ttotal: 2m 19s\tremaining: 15m 40s\n",
            "1950:\tlearn: 0.0453894\ttest: 0.0454520\tbest: 0.0454520 (1950)\ttotal: 2m 20s\tremaining: 15m 39s\n",
            "1960:\tlearn: 0.0451773\ttest: 0.0452400\tbest: 0.0452400 (1960)\ttotal: 2m 21s\tremaining: 15m 38s\n",
            "1970:\tlearn: 0.0449652\ttest: 0.0450279\tbest: 0.0450279 (1970)\ttotal: 2m 21s\tremaining: 15m 38s\n",
            "1980:\tlearn: 0.0447537\ttest: 0.0448165\tbest: 0.0448165 (1980)\ttotal: 2m 22s\tremaining: 15m 37s\n",
            "1990:\tlearn: 0.0445427\ttest: 0.0446056\tbest: 0.0446056 (1990)\ttotal: 2m 23s\tremaining: 15m 36s\n",
            "2000:\tlearn: 0.0443330\ttest: 0.0443959\tbest: 0.0443959 (2000)\ttotal: 2m 24s\tremaining: 15m 36s\n",
            "2010:\tlearn: 0.0441236\ttest: 0.0441864\tbest: 0.0441864 (2010)\ttotal: 2m 24s\tremaining: 15m 35s\n",
            "2020:\tlearn: 0.0439150\ttest: 0.0439778\tbest: 0.0439778 (2020)\ttotal: 2m 25s\tremaining: 15m 34s\n",
            "2030:\tlearn: 0.0437064\ttest: 0.0437691\tbest: 0.0437691 (2030)\ttotal: 2m 26s\tremaining: 15m 34s\n",
            "2040:\tlearn: 0.0434983\ttest: 0.0435610\tbest: 0.0435610 (2040)\ttotal: 2m 27s\tremaining: 15m 33s\n",
            "2050:\tlearn: 0.0432903\ttest: 0.0433531\tbest: 0.0433531 (2050)\ttotal: 2m 27s\tremaining: 15m 33s\n",
            "2060:\tlearn: 0.0430838\ttest: 0.0431466\tbest: 0.0431466 (2060)\ttotal: 2m 28s\tremaining: 15m 32s\n",
            "2070:\tlearn: 0.0428778\ttest: 0.0429406\tbest: 0.0429406 (2070)\ttotal: 2m 29s\tremaining: 15m 31s\n",
            "2080:\tlearn: 0.0426747\ttest: 0.0427376\tbest: 0.0427376 (2080)\ttotal: 2m 29s\tremaining: 15m 30s\n",
            "2090:\tlearn: 0.0424737\ttest: 0.0425365\tbest: 0.0425365 (2090)\ttotal: 2m 30s\tremaining: 15m 30s\n",
            "2100:\tlearn: 0.0422742\ttest: 0.0423372\tbest: 0.0423372 (2100)\ttotal: 2m 31s\tremaining: 15m 29s\n",
            "2110:\tlearn: 0.0420759\ttest: 0.0421388\tbest: 0.0421388 (2110)\ttotal: 2m 32s\tremaining: 15m 28s\n",
            "2120:\tlearn: 0.0418785\ttest: 0.0419413\tbest: 0.0419413 (2120)\ttotal: 2m 32s\tremaining: 15m 27s\n",
            "2130:\tlearn: 0.0416829\ttest: 0.0417457\tbest: 0.0417457 (2130)\ttotal: 2m 33s\tremaining: 15m 27s\n",
            "2140:\tlearn: 0.0414883\ttest: 0.0415510\tbest: 0.0415510 (2140)\ttotal: 2m 34s\tremaining: 15m 26s\n",
            "2150:\tlearn: 0.0412946\ttest: 0.0413572\tbest: 0.0413572 (2150)\ttotal: 2m 34s\tremaining: 15m 25s\n",
            "2160:\tlearn: 0.0411024\ttest: 0.0411650\tbest: 0.0411650 (2160)\ttotal: 2m 35s\tremaining: 15m 24s\n",
            "2170:\tlearn: 0.0409105\ttest: 0.0409730\tbest: 0.0409730 (2170)\ttotal: 2m 36s\tremaining: 15m 24s\n",
            "2180:\tlearn: 0.0407195\ttest: 0.0407820\tbest: 0.0407820 (2180)\ttotal: 2m 37s\tremaining: 15m 23s\n",
            "2190:\tlearn: 0.0405290\ttest: 0.0405914\tbest: 0.0405914 (2190)\ttotal: 2m 37s\tremaining: 15m 22s\n",
            "2200:\tlearn: 0.0403393\ttest: 0.0404017\tbest: 0.0404017 (2200)\ttotal: 2m 38s\tremaining: 15m 22s\n",
            "2210:\tlearn: 0.0401501\ttest: 0.0402124\tbest: 0.0402124 (2210)\ttotal: 2m 39s\tremaining: 15m 21s\n",
            "2220:\tlearn: 0.0399610\ttest: 0.0400235\tbest: 0.0400235 (2220)\ttotal: 2m 40s\tremaining: 15m 20s\n",
            "2230:\tlearn: 0.0397732\ttest: 0.0398355\tbest: 0.0398355 (2230)\ttotal: 2m 40s\tremaining: 15m 20s\n",
            "2240:\tlearn: 0.0395847\ttest: 0.0396471\tbest: 0.0396471 (2240)\ttotal: 2m 41s\tremaining: 15m 19s\n",
            "2250:\tlearn: 0.0393982\ttest: 0.0394605\tbest: 0.0394605 (2250)\ttotal: 2m 42s\tremaining: 15m 18s\n",
            "2260:\tlearn: 0.0392118\ttest: 0.0392741\tbest: 0.0392741 (2260)\ttotal: 2m 42s\tremaining: 15m 17s\n",
            "2270:\tlearn: 0.0390258\ttest: 0.0390881\tbest: 0.0390881 (2270)\ttotal: 2m 43s\tremaining: 15m 16s\n",
            "2280:\tlearn: 0.0388407\ttest: 0.0389029\tbest: 0.0389029 (2280)\ttotal: 2m 44s\tremaining: 15m 16s\n",
            "2290:\tlearn: 0.0386579\ttest: 0.0387201\tbest: 0.0387201 (2290)\ttotal: 2m 45s\tremaining: 15m 15s\n",
            "2300:\tlearn: 0.0384772\ttest: 0.0385390\tbest: 0.0385390 (2300)\ttotal: 2m 45s\tremaining: 15m 14s\n",
            "2310:\tlearn: 0.0382985\ttest: 0.0383602\tbest: 0.0383602 (2310)\ttotal: 2m 46s\tremaining: 15m 13s\n",
            "2320:\tlearn: 0.0381213\ttest: 0.0381826\tbest: 0.0381826 (2320)\ttotal: 2m 47s\tremaining: 15m 13s\n",
            "2330:\tlearn: 0.0379455\ttest: 0.0380065\tbest: 0.0380065 (2330)\ttotal: 2m 47s\tremaining: 15m 12s\n",
            "2340:\tlearn: 0.0377708\ttest: 0.0378314\tbest: 0.0378314 (2340)\ttotal: 2m 48s\tremaining: 15m 11s\n",
            "2350:\tlearn: 0.0375970\ttest: 0.0376576\tbest: 0.0376576 (2350)\ttotal: 2m 49s\tremaining: 15m 10s\n",
            "2360:\tlearn: 0.0374245\ttest: 0.0374850\tbest: 0.0374850 (2360)\ttotal: 2m 49s\tremaining: 15m 9s\n",
            "2370:\tlearn: 0.0372532\ttest: 0.0373135\tbest: 0.0373135 (2370)\ttotal: 2m 50s\tremaining: 15m 9s\n",
            "2380:\tlearn: 0.0370826\ttest: 0.0371428\tbest: 0.0371428 (2380)\ttotal: 2m 51s\tremaining: 15m 8s\n",
            "2390:\tlearn: 0.0369132\ttest: 0.0369733\tbest: 0.0369733 (2390)\ttotal: 2m 52s\tremaining: 15m 7s\n",
            "2400:\tlearn: 0.0367435\ttest: 0.0368035\tbest: 0.0368035 (2400)\ttotal: 2m 52s\tremaining: 15m 6s\n",
            "2410:\tlearn: 0.0365749\ttest: 0.0366349\tbest: 0.0366349 (2410)\ttotal: 2m 53s\tremaining: 15m 6s\n",
            "2420:\tlearn: 0.0364072\ttest: 0.0364670\tbest: 0.0364670 (2420)\ttotal: 2m 54s\tremaining: 15m 5s\n",
            "2430:\tlearn: 0.0362396\ttest: 0.0362995\tbest: 0.0362995 (2430)\ttotal: 2m 54s\tremaining: 15m 4s\n",
            "2440:\tlearn: 0.0360726\ttest: 0.0361324\tbest: 0.0361324 (2440)\ttotal: 2m 55s\tremaining: 15m 3s\n",
            "2450:\tlearn: 0.0359064\ttest: 0.0359661\tbest: 0.0359661 (2450)\ttotal: 2m 56s\tremaining: 15m 3s\n",
            "2460:\tlearn: 0.0357406\ttest: 0.0358002\tbest: 0.0358002 (2460)\ttotal: 2m 57s\tremaining: 15m 2s\n",
            "2470:\tlearn: 0.0355754\ttest: 0.0356348\tbest: 0.0356348 (2470)\ttotal: 2m 57s\tremaining: 15m 1s\n",
            "2480:\tlearn: 0.0354110\ttest: 0.0354702\tbest: 0.0354702 (2480)\ttotal: 2m 58s\tremaining: 15m\n",
            "2490:\tlearn: 0.0352478\ttest: 0.0353070\tbest: 0.0353070 (2490)\ttotal: 2m 59s\tremaining: 14m 59s\n",
            "2500:\tlearn: 0.0350858\ttest: 0.0351450\tbest: 0.0351450 (2500)\ttotal: 2m 59s\tremaining: 14m 58s\n",
            "2510:\tlearn: 0.0349263\ttest: 0.0349855\tbest: 0.0349855 (2510)\ttotal: 3m\tremaining: 14m 57s\n",
            "2520:\tlearn: 0.0347683\ttest: 0.0348276\tbest: 0.0348276 (2520)\ttotal: 3m 1s\tremaining: 14m 56s\n",
            "2530:\tlearn: 0.0346119\ttest: 0.0346712\tbest: 0.0346712 (2530)\ttotal: 3m 1s\tremaining: 14m 56s\n",
            "2540:\tlearn: 0.0344567\ttest: 0.0345161\tbest: 0.0345161 (2540)\ttotal: 3m 2s\tremaining: 14m 55s\n",
            "2550:\tlearn: 0.0343029\ttest: 0.0343622\tbest: 0.0343622 (2550)\ttotal: 3m 3s\tremaining: 14m 54s\n",
            "2560:\tlearn: 0.0341507\ttest: 0.0342099\tbest: 0.0342099 (2560)\ttotal: 3m 4s\tremaining: 14m 53s\n",
            "2570:\tlearn: 0.0339996\ttest: 0.0340587\tbest: 0.0340587 (2570)\ttotal: 3m 4s\tremaining: 14m 52s\n",
            "2580:\tlearn: 0.0338490\ttest: 0.0339081\tbest: 0.0339081 (2580)\ttotal: 3m 5s\tremaining: 14m 51s\n",
            "2590:\tlearn: 0.0336991\ttest: 0.0337581\tbest: 0.0337581 (2590)\ttotal: 3m 6s\tremaining: 14m 51s\n",
            "2600:\tlearn: 0.0335501\ttest: 0.0336091\tbest: 0.0336091 (2600)\ttotal: 3m 6s\tremaining: 14m 50s\n",
            "2610:\tlearn: 0.0334019\ttest: 0.0334608\tbest: 0.0334608 (2610)\ttotal: 3m 7s\tremaining: 14m 49s\n",
            "2620:\tlearn: 0.0332550\ttest: 0.0333137\tbest: 0.0333137 (2620)\ttotal: 3m 8s\tremaining: 14m 48s\n",
            "2630:\tlearn: 0.0331085\ttest: 0.0331670\tbest: 0.0331670 (2630)\ttotal: 3m 8s\tremaining: 14m 47s\n",
            "2640:\tlearn: 0.0329621\ttest: 0.0330207\tbest: 0.0330207 (2640)\ttotal: 3m 9s\tremaining: 14m 47s\n",
            "2650:\tlearn: 0.0328161\ttest: 0.0328747\tbest: 0.0328747 (2650)\ttotal: 3m 10s\tremaining: 14m 46s\n",
            "2660:\tlearn: 0.0326707\ttest: 0.0327293\tbest: 0.0327293 (2660)\ttotal: 3m 10s\tremaining: 14m 45s\n",
            "2670:\tlearn: 0.0325259\ttest: 0.0325844\tbest: 0.0325844 (2670)\ttotal: 3m 11s\tremaining: 14m 44s\n",
            "2680:\tlearn: 0.0323817\ttest: 0.0324401\tbest: 0.0324401 (2680)\ttotal: 3m 12s\tremaining: 14m 43s\n",
            "2690:\tlearn: 0.0322382\ttest: 0.0322966\tbest: 0.0322966 (2690)\ttotal: 3m 12s\tremaining: 14m 42s\n",
            "2700:\tlearn: 0.0320960\ttest: 0.0321544\tbest: 0.0321544 (2700)\ttotal: 3m 13s\tremaining: 14m 41s\n",
            "2710:\tlearn: 0.0319539\ttest: 0.0320124\tbest: 0.0320124 (2710)\ttotal: 3m 14s\tremaining: 14m 40s\n",
            "2720:\tlearn: 0.0318145\ttest: 0.0318730\tbest: 0.0318730 (2720)\ttotal: 3m 14s\tremaining: 14m 39s\n",
            "2730:\tlearn: 0.0316771\ttest: 0.0317356\tbest: 0.0317356 (2730)\ttotal: 3m 15s\tremaining: 14m 38s\n",
            "2740:\tlearn: 0.0315409\ttest: 0.0315996\tbest: 0.0315996 (2740)\ttotal: 3m 16s\tremaining: 14m 38s\n",
            "2750:\tlearn: 0.0314065\ttest: 0.0314656\tbest: 0.0314656 (2750)\ttotal: 3m 17s\tremaining: 14m 37s\n",
            "2760:\tlearn: 0.0312736\ttest: 0.0313328\tbest: 0.0313328 (2760)\ttotal: 3m 17s\tremaining: 14m 36s\n",
            "2770:\tlearn: 0.0311415\ttest: 0.0312010\tbest: 0.0312010 (2770)\ttotal: 3m 18s\tremaining: 14m 35s\n",
            "2780:\tlearn: 0.0310105\ttest: 0.0310703\tbest: 0.0310703 (2780)\ttotal: 3m 19s\tremaining: 14m 34s\n",
            "2790:\tlearn: 0.0308805\ttest: 0.0309406\tbest: 0.0309406 (2790)\ttotal: 3m 19s\tremaining: 14m 33s\n",
            "2800:\tlearn: 0.0307515\ttest: 0.0308117\tbest: 0.0308117 (2800)\ttotal: 3m 20s\tremaining: 14m 32s\n",
            "2810:\tlearn: 0.0306230\ttest: 0.0306835\tbest: 0.0306835 (2810)\ttotal: 3m 21s\tremaining: 14m 31s\n",
            "2820:\tlearn: 0.0304952\ttest: 0.0305560\tbest: 0.0305560 (2820)\ttotal: 3m 21s\tremaining: 14m 30s\n",
            "2830:\tlearn: 0.0303681\ttest: 0.0304292\tbest: 0.0304292 (2830)\ttotal: 3m 22s\tremaining: 14m 29s\n",
            "2840:\tlearn: 0.0302413\ttest: 0.0303026\tbest: 0.0303026 (2840)\ttotal: 3m 23s\tremaining: 14m 29s\n",
            "2850:\tlearn: 0.0301149\ttest: 0.0301766\tbest: 0.0301766 (2850)\ttotal: 3m 23s\tremaining: 14m 28s\n",
            "2860:\tlearn: 0.0299894\ttest: 0.0300514\tbest: 0.0300514 (2860)\ttotal: 3m 24s\tremaining: 14m 27s\n",
            "2870:\tlearn: 0.0298641\ttest: 0.0299265\tbest: 0.0299265 (2870)\ttotal: 3m 25s\tremaining: 14m 26s\n",
            "2880:\tlearn: 0.0297396\ttest: 0.0298024\tbest: 0.0298024 (2880)\ttotal: 3m 25s\tremaining: 14m 25s\n",
            "2890:\tlearn: 0.0296159\ttest: 0.0296789\tbest: 0.0296789 (2890)\ttotal: 3m 26s\tremaining: 14m 24s\n",
            "2900:\tlearn: 0.0294926\ttest: 0.0295560\tbest: 0.0295560 (2900)\ttotal: 3m 27s\tremaining: 14m 23s\n",
            "2910:\tlearn: 0.0293707\ttest: 0.0294345\tbest: 0.0294345 (2910)\ttotal: 3m 27s\tremaining: 14m 22s\n",
            "2920:\tlearn: 0.0292488\ttest: 0.0293130\tbest: 0.0293130 (2920)\ttotal: 3m 28s\tremaining: 14m 21s\n",
            "2930:\tlearn: 0.0291280\ttest: 0.0291928\tbest: 0.0291928 (2930)\ttotal: 3m 29s\tremaining: 14m 20s\n",
            "2940:\tlearn: 0.0290089\ttest: 0.0290741\tbest: 0.0290741 (2940)\ttotal: 3m 29s\tremaining: 14m 19s\n",
            "2950:\tlearn: 0.0288918\ttest: 0.0289575\tbest: 0.0289575 (2950)\ttotal: 3m 30s\tremaining: 14m 18s\n",
            "2960:\tlearn: 0.0287765\ttest: 0.0288427\tbest: 0.0288427 (2960)\ttotal: 3m 31s\tremaining: 14m 17s\n",
            "2970:\tlearn: 0.0286626\ttest: 0.0287293\tbest: 0.0287293 (2970)\ttotal: 3m 31s\tremaining: 14m 17s\n",
            "2980:\tlearn: 0.0285499\ttest: 0.0286170\tbest: 0.0286170 (2980)\ttotal: 3m 32s\tremaining: 14m 16s\n",
            "2990:\tlearn: 0.0284383\ttest: 0.0285058\tbest: 0.0285058 (2990)\ttotal: 3m 33s\tremaining: 14m 15s\n",
            "3000:\tlearn: 0.0283279\ttest: 0.0283958\tbest: 0.0283958 (3000)\ttotal: 3m 33s\tremaining: 14m 14s\n",
            "3010:\tlearn: 0.0282182\ttest: 0.0282865\tbest: 0.0282865 (3010)\ttotal: 3m 34s\tremaining: 14m 13s\n",
            "3020:\tlearn: 0.0281095\ttest: 0.0281781\tbest: 0.0281781 (3020)\ttotal: 3m 35s\tremaining: 14m 12s\n",
            "3030:\tlearn: 0.0280014\ttest: 0.0280705\tbest: 0.0280705 (3030)\ttotal: 3m 35s\tremaining: 14m 11s\n",
            "3040:\tlearn: 0.0278937\ttest: 0.0279632\tbest: 0.0279632 (3040)\ttotal: 3m 36s\tremaining: 14m 10s\n",
            "3050:\tlearn: 0.0277867\ttest: 0.0278566\tbest: 0.0278566 (3050)\ttotal: 3m 37s\tremaining: 14m 9s\n",
            "3060:\tlearn: 0.0276803\ttest: 0.0277506\tbest: 0.0277506 (3060)\ttotal: 3m 37s\tremaining: 14m 8s\n",
            "3070:\tlearn: 0.0275744\ttest: 0.0276449\tbest: 0.0276449 (3070)\ttotal: 3m 38s\tremaining: 14m 7s\n",
            "3080:\tlearn: 0.0274689\ttest: 0.0275400\tbest: 0.0275400 (3080)\ttotal: 3m 38s\tremaining: 14m 6s\n",
            "3090:\tlearn: 0.0273643\ttest: 0.0274356\tbest: 0.0274356 (3090)\ttotal: 3m 39s\tremaining: 14m 6s\n",
            "3100:\tlearn: 0.0272604\ttest: 0.0273322\tbest: 0.0273322 (3100)\ttotal: 3m 40s\tremaining: 14m 5s\n",
            "3110:\tlearn: 0.0271572\ttest: 0.0272294\tbest: 0.0272294 (3110)\ttotal: 3m 40s\tremaining: 14m 4s\n",
            "3120:\tlearn: 0.0270546\ttest: 0.0271273\tbest: 0.0271273 (3120)\ttotal: 3m 41s\tremaining: 14m 3s\n",
            "3130:\tlearn: 0.0269527\ttest: 0.0270257\tbest: 0.0270257 (3130)\ttotal: 3m 42s\tremaining: 14m 2s\n",
            "3140:\tlearn: 0.0268518\ttest: 0.0269251\tbest: 0.0269251 (3140)\ttotal: 3m 42s\tremaining: 14m 1s\n",
            "3150:\tlearn: 0.0267508\ttest: 0.0268245\tbest: 0.0268245 (3150)\ttotal: 3m 43s\tremaining: 14m\n",
            "3160:\tlearn: 0.0266510\ttest: 0.0267252\tbest: 0.0267252 (3160)\ttotal: 3m 44s\tremaining: 13m 59s\n",
            "3170:\tlearn: 0.0265525\ttest: 0.0266270\tbest: 0.0266270 (3170)\ttotal: 3m 44s\tremaining: 13m 58s\n",
            "3180:\tlearn: 0.0264557\ttest: 0.0265305\tbest: 0.0265305 (3180)\ttotal: 3m 45s\tremaining: 13m 57s\n",
            "3190:\tlearn: 0.0263604\ttest: 0.0264356\tbest: 0.0264356 (3190)\ttotal: 3m 46s\tremaining: 13m 56s\n",
            "3200:\tlearn: 0.0262667\ttest: 0.0263422\tbest: 0.0263422 (3200)\ttotal: 3m 46s\tremaining: 13m 55s\n",
            "3210:\tlearn: 0.0261746\ttest: 0.0262506\tbest: 0.0262506 (3210)\ttotal: 3m 47s\tremaining: 13m 54s\n",
            "3220:\tlearn: 0.0260836\ttest: 0.0261601\tbest: 0.0261601 (3220)\ttotal: 3m 47s\tremaining: 13m 53s\n",
            "3230:\tlearn: 0.0259938\ttest: 0.0260710\tbest: 0.0260710 (3230)\ttotal: 3m 48s\tremaining: 13m 52s\n",
            "3240:\tlearn: 0.0259048\ttest: 0.0259825\tbest: 0.0259825 (3240)\ttotal: 3m 49s\tremaining: 13m 51s\n",
            "3250:\tlearn: 0.0258168\ttest: 0.0258951\tbest: 0.0258951 (3250)\ttotal: 3m 49s\tremaining: 13m 50s\n",
            "3260:\tlearn: 0.0257288\ttest: 0.0258079\tbest: 0.0258079 (3260)\ttotal: 3m 50s\tremaining: 13m 49s\n",
            "3270:\tlearn: 0.0256417\ttest: 0.0257214\tbest: 0.0257214 (3270)\ttotal: 3m 51s\tremaining: 13m 48s\n",
            "3280:\tlearn: 0.0255551\ttest: 0.0256354\tbest: 0.0256354 (3280)\ttotal: 3m 51s\tremaining: 13m 47s\n",
            "3290:\tlearn: 0.0254688\ttest: 0.0255498\tbest: 0.0255498 (3290)\ttotal: 3m 52s\tremaining: 13m 47s\n",
            "3300:\tlearn: 0.0253836\ttest: 0.0254654\tbest: 0.0254654 (3300)\ttotal: 3m 53s\tremaining: 13m 46s\n",
            "3310:\tlearn: 0.0252989\ttest: 0.0253816\tbest: 0.0253816 (3310)\ttotal: 3m 53s\tremaining: 13m 45s\n",
            "3320:\tlearn: 0.0252149\ttest: 0.0252984\tbest: 0.0252984 (3320)\ttotal: 3m 54s\tremaining: 13m 44s\n",
            "3330:\tlearn: 0.0251313\ttest: 0.0252158\tbest: 0.0252158 (3330)\ttotal: 3m 54s\tremaining: 13m 43s\n",
            "3340:\tlearn: 0.0250483\ttest: 0.0251335\tbest: 0.0251335 (3340)\ttotal: 3m 55s\tremaining: 13m 42s\n",
            "3350:\tlearn: 0.0249660\ttest: 0.0250521\tbest: 0.0250521 (3350)\ttotal: 3m 56s\tremaining: 13m 41s\n",
            "3360:\tlearn: 0.0248841\ttest: 0.0249709\tbest: 0.0249709 (3360)\ttotal: 3m 56s\tremaining: 13m 40s\n",
            "3370:\tlearn: 0.0248031\ttest: 0.0248907\tbest: 0.0248907 (3370)\ttotal: 3m 57s\tremaining: 13m 39s\n",
            "3380:\tlearn: 0.0247223\ttest: 0.0248108\tbest: 0.0248108 (3380)\ttotal: 3m 58s\tremaining: 13m 38s\n",
            "3390:\tlearn: 0.0246425\ttest: 0.0247317\tbest: 0.0247317 (3390)\ttotal: 3m 58s\tremaining: 13m 37s\n",
            "3400:\tlearn: 0.0245629\ttest: 0.0246528\tbest: 0.0246528 (3400)\ttotal: 3m 59s\tremaining: 13m 36s\n",
            "3410:\tlearn: 0.0244838\ttest: 0.0245745\tbest: 0.0245745 (3410)\ttotal: 4m\tremaining: 13m 35s\n",
            "3420:\tlearn: 0.0244061\ttest: 0.0244976\tbest: 0.0244976 (3420)\ttotal: 4m\tremaining: 13m 34s\n",
            "3430:\tlearn: 0.0243297\ttest: 0.0244221\tbest: 0.0244221 (3430)\ttotal: 4m 1s\tremaining: 13m 33s\n",
            "3440:\tlearn: 0.0242552\ttest: 0.0243485\tbest: 0.0243485 (3440)\ttotal: 4m 1s\tremaining: 13m 32s\n",
            "3450:\tlearn: 0.0241817\ttest: 0.0242757\tbest: 0.0242757 (3450)\ttotal: 4m 2s\tremaining: 13m 31s\n",
            "3460:\tlearn: 0.0241092\ttest: 0.0242040\tbest: 0.0242040 (3460)\ttotal: 4m 3s\tremaining: 13m 30s\n",
            "3470:\tlearn: 0.0240375\ttest: 0.0241331\tbest: 0.0241331 (3470)\ttotal: 4m 3s\tremaining: 13m 29s\n",
            "3480:\tlearn: 0.0239665\ttest: 0.0240630\tbest: 0.0240630 (3480)\ttotal: 4m 4s\tremaining: 13m 28s\n",
            "3490:\tlearn: 0.0238961\ttest: 0.0239934\tbest: 0.0239934 (3490)\ttotal: 4m 5s\tremaining: 13m 27s\n",
            "3500:\tlearn: 0.0238262\ttest: 0.0239243\tbest: 0.0239243 (3500)\ttotal: 4m 5s\tremaining: 13m 26s\n",
            "3510:\tlearn: 0.0237571\ttest: 0.0238560\tbest: 0.0238560 (3510)\ttotal: 4m 6s\tremaining: 13m 26s\n",
            "3520:\tlearn: 0.0236887\ttest: 0.0237883\tbest: 0.0237883 (3520)\ttotal: 4m 6s\tremaining: 13m 25s\n",
            "3530:\tlearn: 0.0236213\ttest: 0.0237217\tbest: 0.0237217 (3530)\ttotal: 4m 7s\tremaining: 13m 24s\n",
            "3540:\tlearn: 0.0235545\ttest: 0.0236557\tbest: 0.0236557 (3540)\ttotal: 4m 8s\tremaining: 13m 23s\n",
            "3550:\tlearn: 0.0234889\ttest: 0.0235907\tbest: 0.0235907 (3550)\ttotal: 4m 8s\tremaining: 13m 22s\n",
            "3560:\tlearn: 0.0234235\ttest: 0.0235260\tbest: 0.0235260 (3560)\ttotal: 4m 9s\tremaining: 13m 21s\n",
            "3570:\tlearn: 0.0233586\ttest: 0.0234618\tbest: 0.0234618 (3570)\ttotal: 4m 10s\tremaining: 13m 20s\n",
            "3580:\tlearn: 0.0232944\ttest: 0.0233984\tbest: 0.0233984 (3580)\ttotal: 4m 10s\tremaining: 13m 19s\n",
            "3590:\tlearn: 0.0232305\ttest: 0.0233353\tbest: 0.0233353 (3590)\ttotal: 4m 11s\tremaining: 13m 18s\n",
            "3600:\tlearn: 0.0231668\ttest: 0.0232723\tbest: 0.0232723 (3600)\ttotal: 4m 11s\tremaining: 13m 17s\n",
            "3610:\tlearn: 0.0231035\ttest: 0.0232098\tbest: 0.0232098 (3610)\ttotal: 4m 12s\tremaining: 13m 16s\n",
            "3620:\tlearn: 0.0230410\ttest: 0.0231480\tbest: 0.0231480 (3620)\ttotal: 4m 13s\tremaining: 13m 15s\n",
            "3630:\tlearn: 0.0229786\ttest: 0.0230864\tbest: 0.0230864 (3630)\ttotal: 4m 13s\tremaining: 13m 14s\n",
            "3640:\tlearn: 0.0229165\ttest: 0.0230251\tbest: 0.0230251 (3640)\ttotal: 4m 14s\tremaining: 13m 13s\n",
            "3650:\tlearn: 0.0228546\ttest: 0.0229639\tbest: 0.0229639 (3650)\ttotal: 4m 15s\tremaining: 13m 12s\n",
            "3660:\tlearn: 0.0227930\ttest: 0.0229030\tbest: 0.0229030 (3660)\ttotal: 4m 15s\tremaining: 13m 11s\n",
            "3670:\tlearn: 0.0227320\ttest: 0.0228426\tbest: 0.0228426 (3670)\ttotal: 4m 16s\tremaining: 13m 10s\n",
            "3680:\tlearn: 0.0226720\ttest: 0.0227833\tbest: 0.0227833 (3680)\ttotal: 4m 16s\tremaining: 13m 9s\n",
            "3690:\tlearn: 0.0226124\ttest: 0.0227244\tbest: 0.0227244 (3690)\ttotal: 4m 17s\tremaining: 13m 8s\n",
            "3700:\tlearn: 0.0225538\ttest: 0.0226665\tbest: 0.0226665 (3700)\ttotal: 4m 18s\tremaining: 13m 7s\n",
            "3710:\tlearn: 0.0224963\ttest: 0.0226098\tbest: 0.0226098 (3710)\ttotal: 4m 18s\tremaining: 13m 6s\n",
            "3720:\tlearn: 0.0224397\ttest: 0.0225538\tbest: 0.0225538 (3720)\ttotal: 4m 19s\tremaining: 13m 5s\n",
            "3730:\tlearn: 0.0223838\ttest: 0.0224987\tbest: 0.0224987 (3730)\ttotal: 4m 19s\tremaining: 13m 4s\n",
            "3740:\tlearn: 0.0223287\ttest: 0.0224443\tbest: 0.0224443 (3740)\ttotal: 4m 20s\tremaining: 13m 4s\n",
            "3750:\tlearn: 0.0222747\ttest: 0.0223908\tbest: 0.0223908 (3750)\ttotal: 4m 21s\tremaining: 13m 3s\n",
            "3760:\tlearn: 0.0222216\ttest: 0.0223382\tbest: 0.0223382 (3760)\ttotal: 4m 21s\tremaining: 13m 2s\n",
            "3770:\tlearn: 0.0221692\ttest: 0.0222863\tbest: 0.0222863 (3770)\ttotal: 4m 22s\tremaining: 13m 1s\n",
            "3780:\tlearn: 0.0221173\ttest: 0.0222349\tbest: 0.0222349 (3780)\ttotal: 4m 22s\tremaining: 13m\n",
            "3790:\tlearn: 0.0220660\ttest: 0.0221840\tbest: 0.0221840 (3790)\ttotal: 4m 23s\tremaining: 12m 59s\n",
            "3800:\tlearn: 0.0220153\ttest: 0.0221338\tbest: 0.0221338 (3800)\ttotal: 4m 24s\tremaining: 12m 58s\n",
            "3810:\tlearn: 0.0219648\ttest: 0.0220839\tbest: 0.0220839 (3810)\ttotal: 4m 24s\tremaining: 12m 57s\n",
            "3820:\tlearn: 0.0219146\ttest: 0.0220343\tbest: 0.0220343 (3820)\ttotal: 4m 25s\tremaining: 12m 56s\n",
            "3830:\tlearn: 0.0218646\ttest: 0.0219849\tbest: 0.0219849 (3830)\ttotal: 4m 25s\tremaining: 12m 55s\n",
            "3840:\tlearn: 0.0218149\ttest: 0.0219359\tbest: 0.0219359 (3840)\ttotal: 4m 26s\tremaining: 12m 54s\n",
            "3850:\tlearn: 0.0217653\ttest: 0.0218870\tbest: 0.0218870 (3850)\ttotal: 4m 27s\tremaining: 12m 53s\n",
            "3860:\tlearn: 0.0217160\ttest: 0.0218382\tbest: 0.0218382 (3860)\ttotal: 4m 27s\tremaining: 12m 52s\n",
            "3870:\tlearn: 0.0216669\ttest: 0.0217898\tbest: 0.0217898 (3870)\ttotal: 4m 28s\tremaining: 12m 51s\n",
            "3880:\tlearn: 0.0216185\ttest: 0.0217420\tbest: 0.0217420 (3880)\ttotal: 4m 28s\tremaining: 12m 50s\n",
            "3890:\tlearn: 0.0215698\ttest: 0.0216941\tbest: 0.0216941 (3890)\ttotal: 4m 29s\tremaining: 12m 49s\n",
            "3900:\tlearn: 0.0215217\ttest: 0.0216467\tbest: 0.0216467 (3900)\ttotal: 4m 30s\tremaining: 12m 48s\n",
            "3910:\tlearn: 0.0214735\ttest: 0.0215991\tbest: 0.0215991 (3910)\ttotal: 4m 30s\tremaining: 12m 47s\n",
            "3920:\tlearn: 0.0214257\ttest: 0.0215521\tbest: 0.0215521 (3920)\ttotal: 4m 31s\tremaining: 12m 46s\n",
            "3930:\tlearn: 0.0213783\ttest: 0.0215053\tbest: 0.0215053 (3930)\ttotal: 4m 31s\tremaining: 12m 45s\n",
            "3940:\tlearn: 0.0213317\ttest: 0.0214593\tbest: 0.0214593 (3940)\ttotal: 4m 32s\tremaining: 12m 44s\n",
            "3950:\tlearn: 0.0212859\ttest: 0.0214142\tbest: 0.0214142 (3950)\ttotal: 4m 33s\tremaining: 12m 43s\n",
            "3960:\tlearn: 0.0212403\ttest: 0.0213691\tbest: 0.0213691 (3960)\ttotal: 4m 33s\tremaining: 12m 42s\n",
            "3970:\tlearn: 0.0211958\ttest: 0.0213253\tbest: 0.0213253 (3970)\ttotal: 4m 34s\tremaining: 12m 41s\n",
            "3980:\tlearn: 0.0211519\ttest: 0.0212820\tbest: 0.0212820 (3980)\ttotal: 4m 34s\tremaining: 12m 40s\n",
            "3990:\tlearn: 0.0211087\ttest: 0.0212394\tbest: 0.0212394 (3990)\ttotal: 4m 35s\tremaining: 12m 39s\n",
            "4000:\tlearn: 0.0210656\ttest: 0.0211969\tbest: 0.0211969 (4000)\ttotal: 4m 35s\tremaining: 12m 38s\n",
            "4010:\tlearn: 0.0210233\ttest: 0.0211553\tbest: 0.0211553 (4010)\ttotal: 4m 36s\tremaining: 12m 37s\n",
            "4020:\tlearn: 0.0209811\ttest: 0.0211139\tbest: 0.0211139 (4020)\ttotal: 4m 37s\tremaining: 12m 36s\n",
            "4030:\tlearn: 0.0209392\ttest: 0.0210725\tbest: 0.0210725 (4030)\ttotal: 4m 37s\tremaining: 12m 35s\n",
            "4040:\tlearn: 0.0208980\ttest: 0.0210319\tbest: 0.0210319 (4040)\ttotal: 4m 38s\tremaining: 12m 34s\n",
            "4050:\tlearn: 0.0208570\ttest: 0.0209914\tbest: 0.0209914 (4050)\ttotal: 4m 38s\tremaining: 12m 33s\n",
            "4060:\tlearn: 0.0208166\ttest: 0.0209514\tbest: 0.0209514 (4060)\ttotal: 4m 39s\tremaining: 12m 32s\n",
            "4070:\tlearn: 0.0207763\ttest: 0.0209116\tbest: 0.0209116 (4070)\ttotal: 4m 40s\tremaining: 12m 31s\n",
            "4080:\tlearn: 0.0207363\ttest: 0.0208720\tbest: 0.0208720 (4080)\ttotal: 4m 40s\tremaining: 12m 30s\n",
            "4090:\tlearn: 0.0206965\ttest: 0.0208325\tbest: 0.0208325 (4090)\ttotal: 4m 41s\tremaining: 12m 29s\n",
            "4100:\tlearn: 0.0206566\ttest: 0.0207930\tbest: 0.0207930 (4100)\ttotal: 4m 41s\tremaining: 12m 28s\n",
            "4110:\tlearn: 0.0206172\ttest: 0.0207539\tbest: 0.0207539 (4110)\ttotal: 4m 42s\tremaining: 12m 27s\n",
            "4120:\tlearn: 0.0205781\ttest: 0.0207152\tbest: 0.0207152 (4120)\ttotal: 4m 42s\tremaining: 12m 26s\n",
            "4130:\tlearn: 0.0205390\ttest: 0.0206765\tbest: 0.0206765 (4130)\ttotal: 4m 43s\tremaining: 12m 25s\n",
            "4140:\tlearn: 0.0205004\ttest: 0.0206382\tbest: 0.0206382 (4140)\ttotal: 4m 43s\tremaining: 12m 24s\n",
            "4150:\tlearn: 0.0204628\ttest: 0.0206009\tbest: 0.0206009 (4150)\ttotal: 4m 44s\tremaining: 12m 23s\n",
            "4160:\tlearn: 0.0204253\ttest: 0.0205635\tbest: 0.0205635 (4160)\ttotal: 4m 45s\tremaining: 12m 22s\n",
            "4170:\tlearn: 0.0203884\ttest: 0.0205269\tbest: 0.0205269 (4170)\ttotal: 4m 45s\tremaining: 12m 21s\n",
            "4180:\tlearn: 0.0203520\ttest: 0.0204907\tbest: 0.0204907 (4180)\ttotal: 4m 46s\tremaining: 12m 20s\n",
            "4190:\tlearn: 0.0203161\ttest: 0.0204548\tbest: 0.0204548 (4190)\ttotal: 4m 46s\tremaining: 12m 19s\n",
            "4200:\tlearn: 0.0202806\ttest: 0.0204194\tbest: 0.0204194 (4200)\ttotal: 4m 47s\tremaining: 12m 18s\n",
            "4210:\tlearn: 0.0202457\ttest: 0.0203845\tbest: 0.0203845 (4210)\ttotal: 4m 48s\tremaining: 12m 17s\n",
            "4220:\tlearn: 0.0202110\ttest: 0.0203499\tbest: 0.0203499 (4220)\ttotal: 4m 48s\tremaining: 12m 16s\n",
            "4230:\tlearn: 0.0201765\ttest: 0.0203154\tbest: 0.0203154 (4230)\ttotal: 4m 49s\tremaining: 12m 16s\n",
            "4240:\tlearn: 0.0201423\ttest: 0.0202811\tbest: 0.0202811 (4240)\ttotal: 4m 49s\tremaining: 12m 15s\n",
            "4250:\tlearn: 0.0201083\ttest: 0.0202471\tbest: 0.0202471 (4250)\ttotal: 4m 50s\tremaining: 12m 14s\n",
            "4260:\tlearn: 0.0200744\ttest: 0.0202130\tbest: 0.0202130 (4260)\ttotal: 4m 50s\tremaining: 12m 13s\n",
            "4270:\tlearn: 0.0200410\ttest: 0.0201794\tbest: 0.0201794 (4270)\ttotal: 4m 51s\tremaining: 12m 12s\n",
            "4280:\tlearn: 0.0200076\ttest: 0.0201459\tbest: 0.0201459 (4280)\ttotal: 4m 52s\tremaining: 12m 11s\n",
            "4290:\tlearn: 0.0199747\ttest: 0.0201129\tbest: 0.0201129 (4290)\ttotal: 4m 52s\tremaining: 12m 10s\n",
            "4300:\tlearn: 0.0199418\ttest: 0.0200800\tbest: 0.0200800 (4300)\ttotal: 4m 53s\tremaining: 12m 9s\n",
            "4310:\tlearn: 0.0199091\ttest: 0.0200470\tbest: 0.0200470 (4310)\ttotal: 4m 53s\tremaining: 12m 8s\n",
            "4320:\tlearn: 0.0198768\ttest: 0.0200146\tbest: 0.0200146 (4320)\ttotal: 4m 54s\tremaining: 12m 7s\n",
            "4330:\tlearn: 0.0198447\ttest: 0.0199823\tbest: 0.0199823 (4330)\ttotal: 4m 54s\tremaining: 12m 6s\n",
            "4340:\tlearn: 0.0198125\ttest: 0.0199500\tbest: 0.0199500 (4340)\ttotal: 4m 55s\tremaining: 12m 5s\n",
            "4350:\tlearn: 0.0197809\ttest: 0.0199183\tbest: 0.0199183 (4350)\ttotal: 4m 56s\tremaining: 12m 4s\n",
            "4360:\tlearn: 0.0197497\ttest: 0.0198870\tbest: 0.0198870 (4360)\ttotal: 4m 56s\tremaining: 12m 3s\n",
            "4370:\tlearn: 0.0197190\ttest: 0.0198563\tbest: 0.0198563 (4370)\ttotal: 4m 57s\tremaining: 12m 2s\n",
            "4380:\tlearn: 0.0196889\ttest: 0.0198262\tbest: 0.0198262 (4380)\ttotal: 4m 57s\tremaining: 12m 1s\n",
            "4390:\tlearn: 0.0196592\ttest: 0.0197965\tbest: 0.0197965 (4390)\ttotal: 4m 58s\tremaining: 12m\n",
            "4400:\tlearn: 0.0196299\ttest: 0.0197672\tbest: 0.0197672 (4400)\ttotal: 4m 58s\tremaining: 11m 59s\n",
            "4410:\tlearn: 0.0196010\ttest: 0.0197382\tbest: 0.0197382 (4410)\ttotal: 4m 59s\tremaining: 11m 59s\n",
            "4420:\tlearn: 0.0195724\ttest: 0.0197096\tbest: 0.0197096 (4420)\ttotal: 5m\tremaining: 11m 58s\n",
            "4430:\tlearn: 0.0195441\ttest: 0.0196813\tbest: 0.0196813 (4430)\ttotal: 5m\tremaining: 11m 57s\n",
            "4440:\tlearn: 0.0195163\ttest: 0.0196535\tbest: 0.0196535 (4440)\ttotal: 5m 1s\tremaining: 11m 56s\n",
            "4450:\tlearn: 0.0194884\ttest: 0.0196257\tbest: 0.0196257 (4450)\ttotal: 5m 1s\tremaining: 11m 55s\n",
            "4460:\tlearn: 0.0194607\ttest: 0.0195980\tbest: 0.0195980 (4460)\ttotal: 5m 2s\tremaining: 11m 54s\n",
            "4470:\tlearn: 0.0194333\ttest: 0.0195706\tbest: 0.0195706 (4470)\ttotal: 5m 2s\tremaining: 11m 53s\n",
            "4480:\tlearn: 0.0194060\ttest: 0.0195434\tbest: 0.0195434 (4480)\ttotal: 5m 3s\tremaining: 11m 52s\n",
            "4490:\tlearn: 0.0193790\ttest: 0.0195165\tbest: 0.0195165 (4490)\ttotal: 5m 3s\tremaining: 11m 51s\n",
            "4500:\tlearn: 0.0193520\ttest: 0.0194895\tbest: 0.0194895 (4500)\ttotal: 5m 4s\tremaining: 11m 50s\n",
            "4510:\tlearn: 0.0193253\ttest: 0.0194629\tbest: 0.0194629 (4510)\ttotal: 5m 5s\tremaining: 11m 49s\n",
            "4520:\tlearn: 0.0192988\ttest: 0.0194364\tbest: 0.0194364 (4520)\ttotal: 5m 5s\tremaining: 11m 48s\n",
            "4530:\tlearn: 0.0192723\ttest: 0.0194100\tbest: 0.0194100 (4530)\ttotal: 5m 6s\tremaining: 11m 47s\n",
            "4540:\tlearn: 0.0192458\ttest: 0.0193835\tbest: 0.0193835 (4540)\ttotal: 5m 6s\tremaining: 11m 46s\n",
            "4550:\tlearn: 0.0192198\ttest: 0.0193576\tbest: 0.0193576 (4550)\ttotal: 5m 7s\tremaining: 11m 45s\n",
            "4560:\tlearn: 0.0191939\ttest: 0.0193318\tbest: 0.0193318 (4560)\ttotal: 5m 7s\tremaining: 11m 44s\n",
            "4570:\tlearn: 0.0191683\ttest: 0.0193062\tbest: 0.0193062 (4570)\ttotal: 5m 8s\tremaining: 11m 43s\n",
            "4580:\tlearn: 0.0191431\ttest: 0.0192810\tbest: 0.0192810 (4580)\ttotal: 5m 8s\tremaining: 11m 42s\n",
            "4590:\tlearn: 0.0191184\ttest: 0.0192563\tbest: 0.0192563 (4590)\ttotal: 5m 9s\tremaining: 11m 41s\n",
            "4600:\tlearn: 0.0190939\ttest: 0.0192318\tbest: 0.0192318 (4600)\ttotal: 5m 10s\tremaining: 11m 40s\n",
            "4610:\tlearn: 0.0190698\ttest: 0.0192077\tbest: 0.0192077 (4610)\ttotal: 5m 10s\tremaining: 11m 40s\n",
            "4620:\tlearn: 0.0190458\ttest: 0.0191837\tbest: 0.0191837 (4620)\ttotal: 5m 11s\tremaining: 11m 39s\n",
            "4630:\tlearn: 0.0190225\ttest: 0.0191605\tbest: 0.0191605 (4630)\ttotal: 5m 11s\tremaining: 11m 38s\n",
            "4640:\tlearn: 0.0189993\ttest: 0.0191373\tbest: 0.0191373 (4640)\ttotal: 5m 12s\tremaining: 11m 37s\n",
            "4650:\tlearn: 0.0189763\ttest: 0.0191144\tbest: 0.0191144 (4650)\ttotal: 5m 12s\tremaining: 11m 36s\n",
            "4660:\tlearn: 0.0189535\ttest: 0.0190914\tbest: 0.0190914 (4660)\ttotal: 5m 13s\tremaining: 11m 35s\n",
            "4670:\tlearn: 0.0189311\ttest: 0.0190689\tbest: 0.0190689 (4670)\ttotal: 5m 13s\tremaining: 11m 34s\n",
            "4680:\tlearn: 0.0189089\ttest: 0.0190467\tbest: 0.0190467 (4680)\ttotal: 5m 14s\tremaining: 11m 33s\n",
            "4690:\tlearn: 0.0188869\ttest: 0.0190246\tbest: 0.0190246 (4690)\ttotal: 5m 15s\tremaining: 11m 32s\n",
            "4700:\tlearn: 0.0188651\ttest: 0.0190028\tbest: 0.0190028 (4700)\ttotal: 5m 15s\tremaining: 11m 31s\n",
            "4710:\tlearn: 0.0188434\ttest: 0.0189811\tbest: 0.0189811 (4710)\ttotal: 5m 16s\tremaining: 11m 30s\n",
            "4720:\tlearn: 0.0188217\ttest: 0.0189595\tbest: 0.0189595 (4720)\ttotal: 5m 16s\tremaining: 11m 29s\n",
            "4730:\tlearn: 0.0188003\ttest: 0.0189381\tbest: 0.0189381 (4730)\ttotal: 5m 17s\tremaining: 11m 28s\n",
            "4740:\tlearn: 0.0187790\ttest: 0.0189168\tbest: 0.0189168 (4740)\ttotal: 5m 17s\tremaining: 11m 27s\n",
            "4750:\tlearn: 0.0187579\ttest: 0.0188959\tbest: 0.0188959 (4750)\ttotal: 5m 18s\tremaining: 11m 26s\n",
            "4760:\tlearn: 0.0187370\ttest: 0.0188750\tbest: 0.0188750 (4760)\ttotal: 5m 18s\tremaining: 11m 25s\n",
            "4770:\tlearn: 0.0187164\ttest: 0.0188545\tbest: 0.0188545 (4770)\ttotal: 5m 19s\tremaining: 11m 25s\n",
            "4780:\tlearn: 0.0186956\ttest: 0.0188338\tbest: 0.0188338 (4780)\ttotal: 5m 20s\tremaining: 11m 24s\n",
            "4790:\tlearn: 0.0186751\ttest: 0.0188134\tbest: 0.0188134 (4790)\ttotal: 5m 20s\tremaining: 11m 23s\n",
            "4800:\tlearn: 0.0186549\ttest: 0.0187934\tbest: 0.0187934 (4800)\ttotal: 5m 21s\tremaining: 11m 22s\n",
            "4810:\tlearn: 0.0186349\ttest: 0.0187736\tbest: 0.0187736 (4810)\ttotal: 5m 21s\tremaining: 11m 21s\n",
            "4820:\tlearn: 0.0186149\ttest: 0.0187537\tbest: 0.0187537 (4820)\ttotal: 5m 22s\tremaining: 11m 20s\n",
            "4830:\tlearn: 0.0185949\ttest: 0.0187338\tbest: 0.0187338 (4830)\ttotal: 5m 22s\tremaining: 11m 19s\n",
            "4840:\tlearn: 0.0185753\ttest: 0.0187143\tbest: 0.0187143 (4840)\ttotal: 5m 23s\tremaining: 11m 18s\n",
            "4850:\tlearn: 0.0185561\ttest: 0.0186953\tbest: 0.0186953 (4850)\ttotal: 5m 23s\tremaining: 11m 17s\n",
            "4860:\tlearn: 0.0185368\ttest: 0.0186762\tbest: 0.0186762 (4860)\ttotal: 5m 24s\tremaining: 11m 16s\n",
            "4870:\tlearn: 0.0185176\ttest: 0.0186571\tbest: 0.0186571 (4870)\ttotal: 5m 24s\tremaining: 11m 15s\n",
            "4880:\tlearn: 0.0184987\ttest: 0.0186384\tbest: 0.0186384 (4880)\ttotal: 5m 25s\tremaining: 11m 14s\n",
            "4890:\tlearn: 0.0184800\ttest: 0.0186199\tbest: 0.0186199 (4890)\ttotal: 5m 26s\tremaining: 11m 13s\n",
            "4900:\tlearn: 0.0184615\ttest: 0.0186016\tbest: 0.0186016 (4900)\ttotal: 5m 26s\tremaining: 11m 12s\n",
            "4910:\tlearn: 0.0184430\ttest: 0.0185833\tbest: 0.0185833 (4910)\ttotal: 5m 27s\tremaining: 11m 12s\n",
            "4920:\tlearn: 0.0184246\ttest: 0.0185651\tbest: 0.0185651 (4920)\ttotal: 5m 27s\tremaining: 11m 11s\n",
            "4930:\tlearn: 0.0184065\ttest: 0.0185472\tbest: 0.0185472 (4930)\ttotal: 5m 28s\tremaining: 11m 10s\n",
            "4940:\tlearn: 0.0183885\ttest: 0.0185294\tbest: 0.0185294 (4940)\ttotal: 5m 28s\tremaining: 11m 9s\n",
            "4950:\tlearn: 0.0183706\ttest: 0.0185117\tbest: 0.0185117 (4950)\ttotal: 5m 29s\tremaining: 11m 8s\n",
            "4960:\tlearn: 0.0183529\ttest: 0.0184943\tbest: 0.0184943 (4960)\ttotal: 5m 29s\tremaining: 11m 7s\n",
            "4970:\tlearn: 0.0183351\ttest: 0.0184767\tbest: 0.0184767 (4970)\ttotal: 5m 30s\tremaining: 11m 6s\n",
            "4980:\tlearn: 0.0183174\ttest: 0.0184592\tbest: 0.0184592 (4980)\ttotal: 5m 30s\tremaining: 11m 5s\n",
            "4990:\tlearn: 0.0182999\ttest: 0.0184419\tbest: 0.0184419 (4990)\ttotal: 5m 31s\tremaining: 11m 4s\n",
            "5000:\tlearn: 0.0182827\ttest: 0.0184248\tbest: 0.0184248 (5000)\ttotal: 5m 32s\tremaining: 11m 3s\n",
            "5010:\tlearn: 0.0182657\ttest: 0.0184080\tbest: 0.0184080 (5010)\ttotal: 5m 32s\tremaining: 11m 2s\n",
            "5020:\tlearn: 0.0182490\ttest: 0.0183914\tbest: 0.0183914 (5020)\ttotal: 5m 33s\tremaining: 11m 2s\n",
            "5030:\tlearn: 0.0182322\ttest: 0.0183748\tbest: 0.0183748 (5030)\ttotal: 5m 33s\tremaining: 11m 1s\n",
            "5040:\tlearn: 0.0182158\ttest: 0.0183586\tbest: 0.0183586 (5040)\ttotal: 5m 34s\tremaining: 11m\n",
            "5050:\tlearn: 0.0181995\ttest: 0.0183424\tbest: 0.0183424 (5050)\ttotal: 5m 34s\tremaining: 10m 59s\n",
            "5060:\tlearn: 0.0181833\ttest: 0.0183264\tbest: 0.0183264 (5060)\ttotal: 5m 35s\tremaining: 10m 58s\n",
            "5070:\tlearn: 0.0181673\ttest: 0.0183105\tbest: 0.0183105 (5070)\ttotal: 5m 35s\tremaining: 10m 57s\n",
            "5080:\tlearn: 0.0181515\ttest: 0.0182948\tbest: 0.0182948 (5080)\ttotal: 5m 36s\tremaining: 10m 56s\n",
            "5090:\tlearn: 0.0181357\ttest: 0.0182792\tbest: 0.0182792 (5090)\ttotal: 5m 36s\tremaining: 10m 55s\n",
            "5100:\tlearn: 0.0181201\ttest: 0.0182638\tbest: 0.0182638 (5100)\ttotal: 5m 37s\tremaining: 10m 54s\n",
            "5110:\tlearn: 0.0181044\ttest: 0.0182484\tbest: 0.0182484 (5110)\ttotal: 5m 38s\tremaining: 10m 54s\n",
            "5120:\tlearn: 0.0180890\ttest: 0.0182332\tbest: 0.0182332 (5120)\ttotal: 5m 38s\tremaining: 10m 53s\n",
            "5130:\tlearn: 0.0180736\ttest: 0.0182180\tbest: 0.0182180 (5130)\ttotal: 5m 39s\tremaining: 10m 52s\n",
            "5140:\tlearn: 0.0180585\ttest: 0.0182031\tbest: 0.0182031 (5140)\ttotal: 5m 39s\tremaining: 10m 51s\n",
            "5150:\tlearn: 0.0180432\ttest: 0.0181881\tbest: 0.0181881 (5150)\ttotal: 5m 40s\tremaining: 10m 50s\n",
            "5160:\tlearn: 0.0180282\ttest: 0.0181734\tbest: 0.0181734 (5160)\ttotal: 5m 40s\tremaining: 10m 49s\n",
            "5170:\tlearn: 0.0180133\ttest: 0.0181586\tbest: 0.0181586 (5170)\ttotal: 5m 41s\tremaining: 10m 48s\n",
            "5180:\tlearn: 0.0179985\ttest: 0.0181441\tbest: 0.0181441 (5180)\ttotal: 5m 41s\tremaining: 10m 47s\n",
            "5190:\tlearn: 0.0179838\ttest: 0.0181296\tbest: 0.0181296 (5190)\ttotal: 5m 42s\tremaining: 10m 46s\n",
            "5200:\tlearn: 0.0179691\ttest: 0.0181151\tbest: 0.0181151 (5200)\ttotal: 5m 42s\tremaining: 10m 45s\n",
            "5210:\tlearn: 0.0179549\ttest: 0.0181011\tbest: 0.0181011 (5210)\ttotal: 5m 43s\tremaining: 10m 45s\n",
            "5220:\tlearn: 0.0179406\ttest: 0.0180870\tbest: 0.0180870 (5220)\ttotal: 5m 43s\tremaining: 10m 44s\n",
            "5230:\tlearn: 0.0179266\ttest: 0.0180732\tbest: 0.0180732 (5230)\ttotal: 5m 44s\tremaining: 10m 43s\n",
            "5240:\tlearn: 0.0179127\ttest: 0.0180595\tbest: 0.0180595 (5240)\ttotal: 5m 44s\tremaining: 10m 42s\n",
            "5250:\tlearn: 0.0178990\ttest: 0.0180460\tbest: 0.0180460 (5250)\ttotal: 5m 45s\tremaining: 10m 41s\n",
            "5260:\tlearn: 0.0178854\ttest: 0.0180327\tbest: 0.0180327 (5260)\ttotal: 5m 46s\tremaining: 10m 40s\n",
            "5270:\tlearn: 0.0178720\ttest: 0.0180195\tbest: 0.0180195 (5270)\ttotal: 5m 46s\tremaining: 10m 39s\n",
            "5280:\tlearn: 0.0178588\ttest: 0.0180066\tbest: 0.0180066 (5280)\ttotal: 5m 47s\tremaining: 10m 38s\n",
            "5290:\tlearn: 0.0178457\ttest: 0.0179937\tbest: 0.0179937 (5290)\ttotal: 5m 47s\tremaining: 10m 37s\n",
            "5300:\tlearn: 0.0178326\ttest: 0.0179808\tbest: 0.0179808 (5300)\ttotal: 5m 48s\tremaining: 10m 36s\n",
            "5310:\tlearn: 0.0178195\ttest: 0.0179680\tbest: 0.0179680 (5310)\ttotal: 5m 48s\tremaining: 10m 35s\n",
            "5320:\tlearn: 0.0178067\ttest: 0.0179554\tbest: 0.0179554 (5320)\ttotal: 5m 49s\tremaining: 10m 35s\n",
            "5330:\tlearn: 0.0177939\ttest: 0.0179429\tbest: 0.0179429 (5330)\ttotal: 5m 49s\tremaining: 10m 34s\n",
            "5340:\tlearn: 0.0177813\ttest: 0.0179305\tbest: 0.0179305 (5340)\ttotal: 5m 50s\tremaining: 10m 33s\n",
            "5350:\tlearn: 0.0177687\ttest: 0.0179182\tbest: 0.0179182 (5350)\ttotal: 5m 50s\tremaining: 10m 32s\n",
            "5360:\tlearn: 0.0177563\ttest: 0.0179060\tbest: 0.0179060 (5360)\ttotal: 5m 51s\tremaining: 10m 31s\n",
            "5370:\tlearn: 0.0177440\ttest: 0.0178939\tbest: 0.0178939 (5370)\ttotal: 5m 51s\tremaining: 10m 30s\n",
            "5380:\tlearn: 0.0177319\ttest: 0.0178820\tbest: 0.0178820 (5380)\ttotal: 5m 52s\tremaining: 10m 29s\n",
            "5390:\tlearn: 0.0177197\ttest: 0.0178700\tbest: 0.0178700 (5390)\ttotal: 5m 52s\tremaining: 10m 28s\n",
            "5400:\tlearn: 0.0177076\ttest: 0.0178581\tbest: 0.0178581 (5400)\ttotal: 5m 53s\tremaining: 10m 28s\n",
            "5410:\tlearn: 0.0176956\ttest: 0.0178464\tbest: 0.0178464 (5410)\ttotal: 5m 53s\tremaining: 10m 27s\n",
            "5420:\tlearn: 0.0176837\ttest: 0.0178346\tbest: 0.0178346 (5420)\ttotal: 5m 54s\tremaining: 10m 26s\n",
            "5430:\tlearn: 0.0176721\ttest: 0.0178232\tbest: 0.0178232 (5430)\ttotal: 5m 54s\tremaining: 10m 25s\n",
            "5440:\tlearn: 0.0176606\ttest: 0.0178119\tbest: 0.0178119 (5440)\ttotal: 5m 55s\tremaining: 10m 24s\n",
            "5450:\tlearn: 0.0176493\ttest: 0.0178008\tbest: 0.0178008 (5450)\ttotal: 5m 55s\tremaining: 10m 23s\n",
            "5460:\tlearn: 0.0176380\ttest: 0.0177897\tbest: 0.0177897 (5460)\ttotal: 5m 56s\tremaining: 10m 22s\n",
            "5470:\tlearn: 0.0176268\ttest: 0.0177786\tbest: 0.0177786 (5470)\ttotal: 5m 57s\tremaining: 10m 21s\n",
            "5480:\tlearn: 0.0176158\ttest: 0.0177678\tbest: 0.0177678 (5480)\ttotal: 5m 57s\tremaining: 10m 20s\n",
            "5490:\tlearn: 0.0176050\ttest: 0.0177571\tbest: 0.0177571 (5490)\ttotal: 5m 57s\tremaining: 10m 19s\n",
            "5500:\tlearn: 0.0175944\ttest: 0.0177467\tbest: 0.0177467 (5500)\ttotal: 5m 58s\tremaining: 10m 19s\n",
            "5510:\tlearn: 0.0175839\ttest: 0.0177363\tbest: 0.0177363 (5510)\ttotal: 5m 59s\tremaining: 10m 18s\n",
            "5520:\tlearn: 0.0175731\ttest: 0.0177258\tbest: 0.0177258 (5520)\ttotal: 5m 59s\tremaining: 10m 17s\n",
            "5530:\tlearn: 0.0175627\ttest: 0.0177156\tbest: 0.0177156 (5530)\ttotal: 6m\tremaining: 10m 16s\n",
            "5540:\tlearn: 0.0175524\ttest: 0.0177055\tbest: 0.0177055 (5540)\ttotal: 6m\tremaining: 10m 15s\n",
            "5550:\tlearn: 0.0175421\ttest: 0.0176954\tbest: 0.0176954 (5550)\ttotal: 6m 1s\tremaining: 10m 14s\n",
            "5560:\tlearn: 0.0175318\ttest: 0.0176854\tbest: 0.0176854 (5560)\ttotal: 6m 1s\tremaining: 10m 13s\n",
            "5570:\tlearn: 0.0175217\ttest: 0.0176756\tbest: 0.0176756 (5570)\ttotal: 6m 2s\tremaining: 10m 12s\n",
            "5580:\tlearn: 0.0175117\ttest: 0.0176657\tbest: 0.0176657 (5580)\ttotal: 6m 2s\tremaining: 10m 12s\n",
            "5590:\tlearn: 0.0175017\ttest: 0.0176559\tbest: 0.0176559 (5590)\ttotal: 6m 3s\tremaining: 10m 11s\n",
            "5600:\tlearn: 0.0174917\ttest: 0.0176462\tbest: 0.0176462 (5600)\ttotal: 6m 3s\tremaining: 10m 10s\n",
            "5610:\tlearn: 0.0174817\ttest: 0.0176364\tbest: 0.0176364 (5610)\ttotal: 6m 4s\tremaining: 10m 9s\n",
            "5620:\tlearn: 0.0174720\ttest: 0.0176269\tbest: 0.0176269 (5620)\ttotal: 6m 4s\tremaining: 10m 8s\n",
            "5630:\tlearn: 0.0174625\ttest: 0.0176176\tbest: 0.0176176 (5630)\ttotal: 6m 5s\tremaining: 10m 7s\n",
            "5640:\tlearn: 0.0174527\ttest: 0.0176081\tbest: 0.0176081 (5640)\ttotal: 6m 5s\tremaining: 10m 6s\n",
            "5650:\tlearn: 0.0174432\ttest: 0.0175989\tbest: 0.0175989 (5650)\ttotal: 6m 6s\tremaining: 10m 5s\n",
            "5660:\tlearn: 0.0174340\ttest: 0.0175899\tbest: 0.0175899 (5660)\ttotal: 6m 6s\tremaining: 10m 4s\n",
            "5670:\tlearn: 0.0174248\ttest: 0.0175810\tbest: 0.0175810 (5670)\ttotal: 6m 7s\tremaining: 10m 4s\n",
            "5680:\tlearn: 0.0174156\ttest: 0.0175721\tbest: 0.0175721 (5680)\ttotal: 6m 7s\tremaining: 10m 3s\n",
            "5690:\tlearn: 0.0174067\ttest: 0.0175635\tbest: 0.0175635 (5690)\ttotal: 6m 8s\tremaining: 10m 2s\n",
            "5700:\tlearn: 0.0173978\ttest: 0.0175549\tbest: 0.0175549 (5700)\ttotal: 6m 8s\tremaining: 10m 1s\n",
            "5710:\tlearn: 0.0173891\ttest: 0.0175465\tbest: 0.0175465 (5710)\ttotal: 6m 9s\tremaining: 10m\n",
            "5720:\tlearn: 0.0173804\ttest: 0.0175381\tbest: 0.0175381 (5720)\ttotal: 6m 9s\tremaining: 9m 59s\n",
            "5730:\tlearn: 0.0173719\ttest: 0.0175299\tbest: 0.0175299 (5730)\ttotal: 6m 10s\tremaining: 9m 58s\n",
            "5740:\tlearn: 0.0173633\ttest: 0.0175216\tbest: 0.0175216 (5740)\ttotal: 6m 10s\tremaining: 9m 58s\n",
            "5750:\tlearn: 0.0173549\ttest: 0.0175136\tbest: 0.0175136 (5750)\ttotal: 6m 11s\tremaining: 9m 57s\n",
            "5760:\tlearn: 0.0173466\ttest: 0.0175056\tbest: 0.0175056 (5760)\ttotal: 6m 11s\tremaining: 9m 56s\n",
            "5770:\tlearn: 0.0173384\ttest: 0.0174977\tbest: 0.0174977 (5770)\ttotal: 6m 12s\tremaining: 9m 55s\n",
            "5780:\tlearn: 0.0173301\ttest: 0.0174898\tbest: 0.0174898 (5780)\ttotal: 6m 12s\tremaining: 9m 54s\n",
            "5790:\tlearn: 0.0173218\ttest: 0.0174818\tbest: 0.0174818 (5790)\ttotal: 6m 13s\tremaining: 9m 53s\n",
            "5800:\tlearn: 0.0173137\ttest: 0.0174740\tbest: 0.0174740 (5800)\ttotal: 6m 13s\tremaining: 9m 52s\n",
            "5810:\tlearn: 0.0173059\ttest: 0.0174665\tbest: 0.0174665 (5810)\ttotal: 6m 14s\tremaining: 9m 51s\n",
            "5820:\tlearn: 0.0172979\ttest: 0.0174588\tbest: 0.0174588 (5820)\ttotal: 6m 14s\tremaining: 9m 51s\n",
            "5830:\tlearn: 0.0172899\ttest: 0.0174511\tbest: 0.0174511 (5830)\ttotal: 6m 15s\tremaining: 9m 50s\n",
            "5840:\tlearn: 0.0172818\ttest: 0.0174434\tbest: 0.0174434 (5840)\ttotal: 6m 15s\tremaining: 9m 49s\n",
            "5850:\tlearn: 0.0172739\ttest: 0.0174358\tbest: 0.0174358 (5850)\ttotal: 6m 16s\tremaining: 9m 48s\n",
            "5860:\tlearn: 0.0172661\ttest: 0.0174283\tbest: 0.0174283 (5860)\ttotal: 6m 16s\tremaining: 9m 47s\n",
            "5870:\tlearn: 0.0172587\ttest: 0.0174211\tbest: 0.0174211 (5870)\ttotal: 6m 17s\tremaining: 9m 46s\n",
            "5880:\tlearn: 0.0172512\ttest: 0.0174139\tbest: 0.0174139 (5880)\ttotal: 6m 17s\tremaining: 9m 45s\n",
            "5890:\tlearn: 0.0172438\ttest: 0.0174068\tbest: 0.0174068 (5890)\ttotal: 6m 18s\tremaining: 9m 45s\n",
            "5900:\tlearn: 0.0172364\ttest: 0.0173996\tbest: 0.0173996 (5900)\ttotal: 6m 18s\tremaining: 9m 44s\n",
            "5910:\tlearn: 0.0172293\ttest: 0.0173928\tbest: 0.0173928 (5910)\ttotal: 6m 19s\tremaining: 9m 43s\n",
            "5920:\tlearn: 0.0172222\ttest: 0.0173859\tbest: 0.0173859 (5920)\ttotal: 6m 19s\tremaining: 9m 42s\n",
            "5930:\tlearn: 0.0172153\ttest: 0.0173791\tbest: 0.0173791 (5930)\ttotal: 6m 20s\tremaining: 9m 41s\n",
            "5940:\tlearn: 0.0172083\ttest: 0.0173725\tbest: 0.0173725 (5940)\ttotal: 6m 20s\tremaining: 9m 40s\n",
            "5950:\tlearn: 0.0172016\ttest: 0.0173659\tbest: 0.0173659 (5950)\ttotal: 6m 21s\tremaining: 9m 39s\n",
            "5960:\tlearn: 0.0171950\ttest: 0.0173596\tbest: 0.0173596 (5960)\ttotal: 6m 21s\tremaining: 9m 39s\n",
            "5970:\tlearn: 0.0171882\ttest: 0.0173530\tbest: 0.0173530 (5970)\ttotal: 6m 22s\tremaining: 9m 38s\n",
            "5980:\tlearn: 0.0171814\ttest: 0.0173465\tbest: 0.0173465 (5980)\ttotal: 6m 22s\tremaining: 9m 37s\n",
            "5990:\tlearn: 0.0171748\ttest: 0.0173401\tbest: 0.0173401 (5990)\ttotal: 6m 23s\tremaining: 9m 36s\n",
            "6000:\tlearn: 0.0171683\ttest: 0.0173338\tbest: 0.0173338 (6000)\ttotal: 6m 23s\tremaining: 9m 35s\n",
            "6010:\tlearn: 0.0171618\ttest: 0.0173275\tbest: 0.0173275 (6010)\ttotal: 6m 24s\tremaining: 9m 34s\n",
            "6020:\tlearn: 0.0171553\ttest: 0.0173213\tbest: 0.0173213 (6020)\ttotal: 6m 24s\tremaining: 9m 34s\n",
            "6030:\tlearn: 0.0171490\ttest: 0.0173151\tbest: 0.0173151 (6030)\ttotal: 6m 25s\tremaining: 9m 33s\n",
            "6040:\tlearn: 0.0171425\ttest: 0.0173089\tbest: 0.0173089 (6040)\ttotal: 6m 25s\tremaining: 9m 32s\n",
            "6050:\tlearn: 0.0171362\ttest: 0.0173029\tbest: 0.0173029 (6050)\ttotal: 6m 26s\tremaining: 9m 31s\n",
            "6060:\tlearn: 0.0171299\ttest: 0.0172969\tbest: 0.0172969 (6060)\ttotal: 6m 26s\tremaining: 9m 30s\n",
            "6070:\tlearn: 0.0171237\ttest: 0.0172908\tbest: 0.0172908 (6070)\ttotal: 6m 27s\tremaining: 9m 29s\n",
            "6080:\tlearn: 0.0171175\ttest: 0.0172850\tbest: 0.0172850 (6080)\ttotal: 6m 28s\tremaining: 9m 29s\n",
            "6090:\tlearn: 0.0171113\ttest: 0.0172790\tbest: 0.0172790 (6090)\ttotal: 6m 28s\tremaining: 9m 28s\n",
            "6100:\tlearn: 0.0171054\ttest: 0.0172733\tbest: 0.0172733 (6100)\ttotal: 6m 29s\tremaining: 9m 27s\n",
            "6110:\tlearn: 0.0170995\ttest: 0.0172677\tbest: 0.0172677 (6110)\ttotal: 6m 29s\tremaining: 9m 26s\n",
            "6120:\tlearn: 0.0170938\ttest: 0.0172622\tbest: 0.0172622 (6120)\ttotal: 6m 30s\tremaining: 9m 25s\n",
            "6130:\tlearn: 0.0170881\ttest: 0.0172567\tbest: 0.0172567 (6130)\ttotal: 6m 30s\tremaining: 9m 25s\n",
            "6140:\tlearn: 0.0170824\ttest: 0.0172513\tbest: 0.0172513 (6140)\ttotal: 6m 31s\tremaining: 9m 24s\n",
            "6150:\tlearn: 0.0170769\ttest: 0.0172461\tbest: 0.0172461 (6150)\ttotal: 6m 31s\tremaining: 9m 23s\n",
            "6160:\tlearn: 0.0170715\ttest: 0.0172408\tbest: 0.0172408 (6160)\ttotal: 6m 32s\tremaining: 9m 22s\n",
            "6170:\tlearn: 0.0170660\ttest: 0.0172355\tbest: 0.0172355 (6170)\ttotal: 6m 32s\tremaining: 9m 21s\n",
            "6180:\tlearn: 0.0170606\ttest: 0.0172303\tbest: 0.0172303 (6180)\ttotal: 6m 33s\tremaining: 9m 21s\n",
            "6190:\tlearn: 0.0170551\ttest: 0.0172251\tbest: 0.0172251 (6190)\ttotal: 6m 33s\tremaining: 9m 20s\n",
            "6200:\tlearn: 0.0170498\ttest: 0.0172199\tbest: 0.0172199 (6200)\ttotal: 6m 34s\tremaining: 9m 19s\n",
            "6210:\tlearn: 0.0170445\ttest: 0.0172149\tbest: 0.0172149 (6210)\ttotal: 6m 34s\tremaining: 9m 18s\n",
            "6220:\tlearn: 0.0170393\ttest: 0.0172098\tbest: 0.0172098 (6220)\ttotal: 6m 35s\tremaining: 9m 17s\n",
            "6230:\tlearn: 0.0170341\ttest: 0.0172048\tbest: 0.0172048 (6230)\ttotal: 6m 35s\tremaining: 9m 16s\n",
            "6240:\tlearn: 0.0170289\ttest: 0.0171998\tbest: 0.0171998 (6240)\ttotal: 6m 36s\tremaining: 9m 16s\n",
            "6250:\tlearn: 0.0170238\ttest: 0.0171949\tbest: 0.0171949 (6250)\ttotal: 6m 36s\tremaining: 9m 15s\n",
            "6260:\tlearn: 0.0170188\ttest: 0.0171901\tbest: 0.0171901 (6260)\ttotal: 6m 37s\tremaining: 9m 14s\n",
            "6270:\tlearn: 0.0170137\ttest: 0.0171851\tbest: 0.0171851 (6270)\ttotal: 6m 37s\tremaining: 9m 13s\n",
            "6280:\tlearn: 0.0170088\ttest: 0.0171804\tbest: 0.0171804 (6280)\ttotal: 6m 38s\tremaining: 9m 12s\n",
            "6290:\tlearn: 0.0170039\ttest: 0.0171757\tbest: 0.0171757 (6290)\ttotal: 6m 38s\tremaining: 9m 11s\n",
            "6300:\tlearn: 0.0169989\ttest: 0.0171709\tbest: 0.0171709 (6300)\ttotal: 6m 39s\tremaining: 9m 11s\n",
            "6310:\tlearn: 0.0169941\ttest: 0.0171662\tbest: 0.0171662 (6310)\ttotal: 6m 39s\tremaining: 9m 10s\n",
            "6320:\tlearn: 0.0169893\ttest: 0.0171616\tbest: 0.0171616 (6320)\ttotal: 6m 40s\tremaining: 9m 9s\n",
            "6330:\tlearn: 0.0169846\ttest: 0.0171571\tbest: 0.0171571 (6330)\ttotal: 6m 40s\tremaining: 9m 8s\n",
            "6340:\tlearn: 0.0169799\ttest: 0.0171527\tbest: 0.0171527 (6340)\ttotal: 6m 41s\tremaining: 9m 7s\n",
            "6350:\tlearn: 0.0169754\ttest: 0.0171483\tbest: 0.0171483 (6350)\ttotal: 6m 41s\tremaining: 9m 7s\n",
            "6360:\tlearn: 0.0169709\ttest: 0.0171440\tbest: 0.0171440 (6360)\ttotal: 6m 42s\tremaining: 9m 6s\n",
            "6370:\tlearn: 0.0169664\ttest: 0.0171398\tbest: 0.0171398 (6370)\ttotal: 6m 42s\tremaining: 9m 5s\n",
            "6380:\tlearn: 0.0169620\ttest: 0.0171356\tbest: 0.0171356 (6380)\ttotal: 6m 43s\tremaining: 9m 4s\n",
            "6390:\tlearn: 0.0169577\ttest: 0.0171315\tbest: 0.0171315 (6390)\ttotal: 6m 43s\tremaining: 9m 3s\n",
            "6400:\tlearn: 0.0169533\ttest: 0.0171273\tbest: 0.0171273 (6400)\ttotal: 6m 44s\tremaining: 9m 3s\n",
            "6410:\tlearn: 0.0169489\ttest: 0.0171231\tbest: 0.0171231 (6410)\ttotal: 6m 44s\tremaining: 9m 2s\n",
            "6420:\tlearn: 0.0169447\ttest: 0.0171191\tbest: 0.0171191 (6420)\ttotal: 6m 45s\tremaining: 9m 1s\n",
            "6430:\tlearn: 0.0169405\ttest: 0.0171151\tbest: 0.0171151 (6430)\ttotal: 6m 46s\tremaining: 9m 1s\n",
            "6440:\tlearn: 0.0169363\ttest: 0.0171110\tbest: 0.0171110 (6440)\ttotal: 6m 46s\tremaining: 9m\n",
            "6450:\tlearn: 0.0169323\ttest: 0.0171072\tbest: 0.0171072 (6450)\ttotal: 6m 47s\tremaining: 8m 59s\n",
            "6460:\tlearn: 0.0169281\ttest: 0.0171032\tbest: 0.0171032 (6460)\ttotal: 6m 47s\tremaining: 8m 58s\n",
            "6470:\tlearn: 0.0169240\ttest: 0.0170992\tbest: 0.0170992 (6470)\ttotal: 6m 48s\tremaining: 8m 57s\n",
            "6480:\tlearn: 0.0169199\ttest: 0.0170952\tbest: 0.0170952 (6480)\ttotal: 6m 48s\tremaining: 8m 57s\n",
            "6490:\tlearn: 0.0169157\ttest: 0.0170912\tbest: 0.0170912 (6490)\ttotal: 6m 49s\tremaining: 8m 56s\n",
            "6500:\tlearn: 0.0169117\ttest: 0.0170873\tbest: 0.0170873 (6500)\ttotal: 6m 49s\tremaining: 8m 55s\n",
            "6510:\tlearn: 0.0169077\ttest: 0.0170835\tbest: 0.0170835 (6510)\ttotal: 6m 50s\tremaining: 8m 54s\n",
            "6520:\tlearn: 0.0169036\ttest: 0.0170796\tbest: 0.0170796 (6520)\ttotal: 6m 50s\tremaining: 8m 54s\n",
            "6530:\tlearn: 0.0168998\ttest: 0.0170758\tbest: 0.0170758 (6530)\ttotal: 6m 51s\tremaining: 8m 53s\n",
            "6540:\tlearn: 0.0168960\ttest: 0.0170721\tbest: 0.0170721 (6540)\ttotal: 6m 51s\tremaining: 8m 52s\n",
            "6550:\tlearn: 0.0168921\ttest: 0.0170684\tbest: 0.0170684 (6550)\ttotal: 6m 52s\tremaining: 8m 51s\n",
            "6560:\tlearn: 0.0168884\ttest: 0.0170648\tbest: 0.0170648 (6560)\ttotal: 6m 52s\tremaining: 8m 51s\n",
            "6570:\tlearn: 0.0168848\ttest: 0.0170612\tbest: 0.0170612 (6570)\ttotal: 6m 53s\tremaining: 8m 50s\n",
            "6580:\tlearn: 0.0168812\ttest: 0.0170577\tbest: 0.0170577 (6580)\ttotal: 6m 53s\tremaining: 8m 49s\n",
            "6590:\tlearn: 0.0168776\ttest: 0.0170542\tbest: 0.0170542 (6590)\ttotal: 6m 54s\tremaining: 8m 48s\n",
            "6600:\tlearn: 0.0168741\ttest: 0.0170509\tbest: 0.0170509 (6600)\ttotal: 6m 54s\tremaining: 8m 47s\n",
            "6610:\tlearn: 0.0168707\ttest: 0.0170475\tbest: 0.0170475 (6610)\ttotal: 6m 55s\tremaining: 8m 47s\n",
            "6620:\tlearn: 0.0168673\ttest: 0.0170442\tbest: 0.0170442 (6620)\ttotal: 6m 55s\tremaining: 8m 46s\n",
            "6630:\tlearn: 0.0168640\ttest: 0.0170410\tbest: 0.0170410 (6630)\ttotal: 6m 56s\tremaining: 8m 45s\n",
            "6640:\tlearn: 0.0168607\ttest: 0.0170378\tbest: 0.0170378 (6640)\ttotal: 6m 56s\tremaining: 8m 44s\n",
            "6650:\tlearn: 0.0168575\ttest: 0.0170347\tbest: 0.0170347 (6650)\ttotal: 6m 57s\tremaining: 8m 44s\n",
            "6660:\tlearn: 0.0168542\ttest: 0.0170314\tbest: 0.0170314 (6660)\ttotal: 6m 57s\tremaining: 8m 43s\n",
            "6670:\tlearn: 0.0168510\ttest: 0.0170284\tbest: 0.0170284 (6670)\ttotal: 6m 58s\tremaining: 8m 42s\n",
            "6680:\tlearn: 0.0168478\ttest: 0.0170252\tbest: 0.0170252 (6680)\ttotal: 6m 59s\tremaining: 8m 41s\n",
            "6690:\tlearn: 0.0168446\ttest: 0.0170221\tbest: 0.0170221 (6690)\ttotal: 6m 59s\tremaining: 8m 41s\n",
            "6700:\tlearn: 0.0168414\ttest: 0.0170190\tbest: 0.0170190 (6700)\ttotal: 7m\tremaining: 8m 40s\n",
            "6710:\tlearn: 0.0168383\ttest: 0.0170160\tbest: 0.0170160 (6710)\ttotal: 7m\tremaining: 8m 39s\n",
            "6720:\tlearn: 0.0168352\ttest: 0.0170129\tbest: 0.0170129 (6720)\ttotal: 7m 1s\tremaining: 8m 38s\n",
            "6730:\tlearn: 0.0168320\ttest: 0.0170098\tbest: 0.0170098 (6730)\ttotal: 7m 1s\tremaining: 8m 37s\n",
            "6740:\tlearn: 0.0168289\ttest: 0.0170067\tbest: 0.0170067 (6740)\ttotal: 7m 2s\tremaining: 8m 37s\n",
            "6750:\tlearn: 0.0168258\ttest: 0.0170038\tbest: 0.0170038 (6750)\ttotal: 7m 2s\tremaining: 8m 36s\n",
            "6760:\tlearn: 0.0168227\ttest: 0.0170008\tbest: 0.0170008 (6760)\ttotal: 7m 3s\tremaining: 8m 35s\n",
            "6770:\tlearn: 0.0168197\ttest: 0.0169978\tbest: 0.0169978 (6770)\ttotal: 7m 3s\tremaining: 8m 35s\n",
            "6780:\tlearn: 0.0168167\ttest: 0.0169949\tbest: 0.0169949 (6780)\ttotal: 7m 4s\tremaining: 8m 34s\n",
            "6790:\tlearn: 0.0168138\ttest: 0.0169921\tbest: 0.0169921 (6790)\ttotal: 7m 4s\tremaining: 8m 33s\n",
            "6800:\tlearn: 0.0168109\ttest: 0.0169893\tbest: 0.0169893 (6800)\ttotal: 7m 5s\tremaining: 8m 32s\n",
            "6810:\tlearn: 0.0168080\ttest: 0.0169865\tbest: 0.0169865 (6810)\ttotal: 7m 5s\tremaining: 8m 32s\n",
            "6820:\tlearn: 0.0168052\ttest: 0.0169838\tbest: 0.0169838 (6820)\ttotal: 7m 6s\tremaining: 8m 31s\n",
            "6830:\tlearn: 0.0168025\ttest: 0.0169811\tbest: 0.0169811 (6830)\ttotal: 7m 6s\tremaining: 8m 30s\n",
            "6840:\tlearn: 0.0167997\ttest: 0.0169785\tbest: 0.0169785 (6840)\ttotal: 7m 7s\tremaining: 8m 29s\n",
            "6850:\tlearn: 0.0167970\ttest: 0.0169758\tbest: 0.0169758 (6850)\ttotal: 7m 7s\tremaining: 8m 29s\n",
            "6860:\tlearn: 0.0167944\ttest: 0.0169732\tbest: 0.0169732 (6860)\ttotal: 7m 8s\tremaining: 8m 28s\n",
            "6870:\tlearn: 0.0167918\ttest: 0.0169707\tbest: 0.0169707 (6870)\ttotal: 7m 9s\tremaining: 8m 27s\n",
            "6880:\tlearn: 0.0167892\ttest: 0.0169682\tbest: 0.0169682 (6880)\ttotal: 7m 9s\tremaining: 8m 26s\n",
            "6890:\tlearn: 0.0167866\ttest: 0.0169657\tbest: 0.0169657 (6890)\ttotal: 7m 10s\tremaining: 8m 26s\n",
            "6900:\tlearn: 0.0167840\ttest: 0.0169632\tbest: 0.0169632 (6900)\ttotal: 7m 10s\tremaining: 8m 25s\n",
            "6910:\tlearn: 0.0167815\ttest: 0.0169608\tbest: 0.0169608 (6910)\ttotal: 7m 11s\tremaining: 8m 24s\n",
            "6920:\tlearn: 0.0167790\ttest: 0.0169583\tbest: 0.0169583 (6920)\ttotal: 7m 11s\tremaining: 8m 23s\n",
            "6930:\tlearn: 0.0167765\ttest: 0.0169560\tbest: 0.0169560 (6930)\ttotal: 7m 12s\tremaining: 8m 23s\n",
            "6940:\tlearn: 0.0167740\ttest: 0.0169535\tbest: 0.0169535 (6940)\ttotal: 7m 12s\tremaining: 8m 22s\n",
            "6950:\tlearn: 0.0167715\ttest: 0.0169511\tbest: 0.0169511 (6950)\ttotal: 7m 13s\tremaining: 8m 21s\n",
            "6960:\tlearn: 0.0167690\ttest: 0.0169488\tbest: 0.0169488 (6960)\ttotal: 7m 13s\tremaining: 8m 20s\n",
            "6970:\tlearn: 0.0167667\ttest: 0.0169465\tbest: 0.0169465 (6970)\ttotal: 7m 14s\tremaining: 8m 20s\n",
            "6980:\tlearn: 0.0167642\ttest: 0.0169442\tbest: 0.0169442 (6980)\ttotal: 7m 14s\tremaining: 8m 19s\n",
            "6990:\tlearn: 0.0167618\ttest: 0.0169418\tbest: 0.0169418 (6990)\ttotal: 7m 15s\tremaining: 8m 18s\n",
            "7000:\tlearn: 0.0167594\ttest: 0.0169396\tbest: 0.0169396 (7000)\ttotal: 7m 15s\tremaining: 8m 17s\n",
            "7010:\tlearn: 0.0167569\ttest: 0.0169372\tbest: 0.0169372 (7010)\ttotal: 7m 16s\tremaining: 8m 17s\n",
            "7020:\tlearn: 0.0167546\ttest: 0.0169349\tbest: 0.0169349 (7020)\ttotal: 7m 16s\tremaining: 8m 16s\n",
            "7030:\tlearn: 0.0167522\ttest: 0.0169326\tbest: 0.0169326 (7030)\ttotal: 7m 17s\tremaining: 8m 15s\n",
            "7040:\tlearn: 0.0167500\ttest: 0.0169305\tbest: 0.0169305 (7040)\ttotal: 7m 17s\tremaining: 8m 15s\n",
            "7050:\tlearn: 0.0167477\ttest: 0.0169283\tbest: 0.0169283 (7050)\ttotal: 7m 18s\tremaining: 8m 14s\n",
            "7060:\tlearn: 0.0167456\ttest: 0.0169263\tbest: 0.0169263 (7060)\ttotal: 7m 19s\tremaining: 8m 13s\n",
            "7070:\tlearn: 0.0167436\ttest: 0.0169244\tbest: 0.0169244 (7070)\ttotal: 7m 19s\tremaining: 8m 12s\n",
            "7080:\tlearn: 0.0167415\ttest: 0.0169224\tbest: 0.0169224 (7080)\ttotal: 7m 20s\tremaining: 8m 12s\n",
            "7090:\tlearn: 0.0167394\ttest: 0.0169204\tbest: 0.0169204 (7090)\ttotal: 7m 20s\tremaining: 8m 11s\n",
            "7100:\tlearn: 0.0167373\ttest: 0.0169184\tbest: 0.0169184 (7100)\ttotal: 7m 21s\tremaining: 8m 10s\n",
            "7110:\tlearn: 0.0167352\ttest: 0.0169164\tbest: 0.0169164 (7110)\ttotal: 7m 21s\tremaining: 8m 10s\n",
            "7120:\tlearn: 0.0167332\ttest: 0.0169146\tbest: 0.0169146 (7120)\ttotal: 7m 22s\tremaining: 8m 9s\n",
            "7130:\tlearn: 0.0167312\ttest: 0.0169127\tbest: 0.0169127 (7130)\ttotal: 7m 22s\tremaining: 8m 8s\n",
            "7140:\tlearn: 0.0167292\ttest: 0.0169108\tbest: 0.0169108 (7140)\ttotal: 7m 23s\tremaining: 8m 7s\n",
            "7150:\tlearn: 0.0167272\ttest: 0.0169089\tbest: 0.0169089 (7150)\ttotal: 7m 23s\tremaining: 8m 7s\n",
            "7160:\tlearn: 0.0167252\ttest: 0.0169070\tbest: 0.0169070 (7160)\ttotal: 7m 24s\tremaining: 8m 6s\n",
            "7170:\tlearn: 0.0167233\ttest: 0.0169051\tbest: 0.0169051 (7170)\ttotal: 7m 25s\tremaining: 8m 5s\n",
            "7180:\tlearn: 0.0167214\ttest: 0.0169032\tbest: 0.0169032 (7180)\ttotal: 7m 25s\tremaining: 8m 5s\n",
            "7190:\tlearn: 0.0167194\ttest: 0.0169014\tbest: 0.0169014 (7190)\ttotal: 7m 26s\tremaining: 8m 4s\n",
            "7200:\tlearn: 0.0167176\ttest: 0.0168996\tbest: 0.0168996 (7200)\ttotal: 7m 26s\tremaining: 8m 3s\n",
            "7210:\tlearn: 0.0167157\ttest: 0.0168978\tbest: 0.0168978 (7210)\ttotal: 7m 27s\tremaining: 8m 3s\n",
            "7220:\tlearn: 0.0167139\ttest: 0.0168961\tbest: 0.0168961 (7220)\ttotal: 7m 27s\tremaining: 8m 2s\n",
            "7230:\tlearn: 0.0167121\ttest: 0.0168943\tbest: 0.0168943 (7230)\ttotal: 7m 28s\tremaining: 8m 1s\n",
            "7240:\tlearn: 0.0167103\ttest: 0.0168926\tbest: 0.0168926 (7240)\ttotal: 7m 28s\tremaining: 8m 1s\n",
            "7250:\tlearn: 0.0167086\ttest: 0.0168910\tbest: 0.0168910 (7250)\ttotal: 7m 29s\tremaining: 8m\n",
            "7260:\tlearn: 0.0167067\ttest: 0.0168892\tbest: 0.0168892 (7260)\ttotal: 7m 30s\tremaining: 7m 59s\n",
            "7270:\tlearn: 0.0167050\ttest: 0.0168876\tbest: 0.0168876 (7270)\ttotal: 7m 30s\tremaining: 7m 58s\n",
            "7280:\tlearn: 0.0167034\ttest: 0.0168860\tbest: 0.0168860 (7280)\ttotal: 7m 31s\tremaining: 7m 58s\n",
            "7290:\tlearn: 0.0167016\ttest: 0.0168843\tbest: 0.0168843 (7290)\ttotal: 7m 31s\tremaining: 7m 57s\n",
            "7300:\tlearn: 0.0167000\ttest: 0.0168828\tbest: 0.0168828 (7300)\ttotal: 7m 32s\tremaining: 7m 56s\n",
            "7310:\tlearn: 0.0166983\ttest: 0.0168812\tbest: 0.0168812 (7310)\ttotal: 7m 32s\tremaining: 7m 56s\n",
            "7320:\tlearn: 0.0166966\ttest: 0.0168796\tbest: 0.0168796 (7320)\ttotal: 7m 33s\tremaining: 7m 55s\n",
            "7330:\tlearn: 0.0166951\ttest: 0.0168781\tbest: 0.0168781 (7330)\ttotal: 7m 33s\tremaining: 7m 54s\n",
            "7340:\tlearn: 0.0166936\ttest: 0.0168768\tbest: 0.0168768 (7340)\ttotal: 7m 34s\tremaining: 7m 53s\n",
            "7350:\tlearn: 0.0166921\ttest: 0.0168754\tbest: 0.0168754 (7350)\ttotal: 7m 34s\tremaining: 7m 53s\n",
            "7360:\tlearn: 0.0166905\ttest: 0.0168740\tbest: 0.0168740 (7360)\ttotal: 7m 35s\tremaining: 7m 52s\n",
            "7370:\tlearn: 0.0166890\ttest: 0.0168726\tbest: 0.0168726 (7370)\ttotal: 7m 35s\tremaining: 7m 51s\n",
            "7380:\tlearn: 0.0166876\ttest: 0.0168712\tbest: 0.0168712 (7380)\ttotal: 7m 36s\tremaining: 7m 51s\n",
            "7390:\tlearn: 0.0166861\ttest: 0.0168699\tbest: 0.0168699 (7390)\ttotal: 7m 37s\tremaining: 7m 50s\n",
            "7400:\tlearn: 0.0166847\ttest: 0.0168685\tbest: 0.0168685 (7400)\ttotal: 7m 37s\tremaining: 7m 49s\n",
            "7410:\tlearn: 0.0166833\ttest: 0.0168672\tbest: 0.0168672 (7410)\ttotal: 7m 38s\tremaining: 7m 49s\n",
            "7420:\tlearn: 0.0166820\ttest: 0.0168660\tbest: 0.0168660 (7420)\ttotal: 7m 38s\tremaining: 7m 48s\n",
            "7430:\tlearn: 0.0166806\ttest: 0.0168647\tbest: 0.0168647 (7430)\ttotal: 7m 39s\tremaining: 7m 47s\n",
            "7440:\tlearn: 0.0166792\ttest: 0.0168634\tbest: 0.0168634 (7440)\ttotal: 7m 39s\tremaining: 7m 47s\n",
            "7450:\tlearn: 0.0166778\ttest: 0.0168621\tbest: 0.0168621 (7450)\ttotal: 7m 40s\tremaining: 7m 46s\n",
            "7460:\tlearn: 0.0166765\ttest: 0.0168609\tbest: 0.0168609 (7460)\ttotal: 7m 40s\tremaining: 7m 45s\n",
            "7470:\tlearn: 0.0166752\ttest: 0.0168596\tbest: 0.0168596 (7470)\ttotal: 7m 41s\tremaining: 7m 45s\n",
            "7480:\tlearn: 0.0166740\ttest: 0.0168585\tbest: 0.0168585 (7480)\ttotal: 7m 41s\tremaining: 7m 44s\n",
            "7490:\tlearn: 0.0166727\ttest: 0.0168573\tbest: 0.0168573 (7490)\ttotal: 7m 42s\tremaining: 7m 43s\n",
            "7500:\tlearn: 0.0166713\ttest: 0.0168561\tbest: 0.0168561 (7500)\ttotal: 7m 43s\tremaining: 7m 42s\n",
            "7510:\tlearn: 0.0166701\ttest: 0.0168549\tbest: 0.0168549 (7510)\ttotal: 7m 43s\tremaining: 7m 42s\n",
            "7520:\tlearn: 0.0166688\ttest: 0.0168538\tbest: 0.0168538 (7520)\ttotal: 7m 44s\tremaining: 7m 41s\n",
            "7530:\tlearn: 0.0166675\ttest: 0.0168526\tbest: 0.0168526 (7530)\ttotal: 7m 44s\tremaining: 7m 40s\n",
            "7540:\tlearn: 0.0166662\ttest: 0.0168515\tbest: 0.0168515 (7540)\ttotal: 7m 45s\tremaining: 7m 40s\n",
            "7550:\tlearn: 0.0166650\ttest: 0.0168504\tbest: 0.0168504 (7550)\ttotal: 7m 45s\tremaining: 7m 39s\n",
            "7560:\tlearn: 0.0166638\ttest: 0.0168493\tbest: 0.0168493 (7560)\ttotal: 7m 46s\tremaining: 7m 38s\n",
            "7570:\tlearn: 0.0166626\ttest: 0.0168483\tbest: 0.0168483 (7570)\ttotal: 7m 46s\tremaining: 7m 38s\n",
            "7580:\tlearn: 0.0166615\ttest: 0.0168473\tbest: 0.0168473 (7580)\ttotal: 7m 47s\tremaining: 7m 37s\n",
            "7590:\tlearn: 0.0166603\ttest: 0.0168462\tbest: 0.0168462 (7590)\ttotal: 7m 48s\tremaining: 7m 36s\n",
            "7600:\tlearn: 0.0166592\ttest: 0.0168453\tbest: 0.0168453 (7600)\ttotal: 7m 48s\tremaining: 7m 36s\n",
            "7610:\tlearn: 0.0166581\ttest: 0.0168443\tbest: 0.0168443 (7610)\ttotal: 7m 49s\tremaining: 7m 35s\n",
            "7620:\tlearn: 0.0166570\ttest: 0.0168434\tbest: 0.0168434 (7620)\ttotal: 7m 49s\tremaining: 7m 34s\n",
            "7630:\tlearn: 0.0166558\ttest: 0.0168424\tbest: 0.0168424 (7630)\ttotal: 7m 50s\tremaining: 7m 34s\n",
            "7640:\tlearn: 0.0166547\ttest: 0.0168415\tbest: 0.0168415 (7640)\ttotal: 7m 50s\tremaining: 7m 33s\n",
            "7650:\tlearn: 0.0166537\ttest: 0.0168406\tbest: 0.0168406 (7650)\ttotal: 7m 51s\tremaining: 7m 32s\n",
            "7660:\tlearn: 0.0166525\ttest: 0.0168395\tbest: 0.0168395 (7660)\ttotal: 7m 52s\tremaining: 7m 32s\n",
            "7670:\tlearn: 0.0166514\ttest: 0.0168385\tbest: 0.0168385 (7670)\ttotal: 7m 52s\tremaining: 7m 31s\n",
            "7680:\tlearn: 0.0166503\ttest: 0.0168376\tbest: 0.0168376 (7680)\ttotal: 7m 53s\tremaining: 7m 30s\n",
            "7690:\tlearn: 0.0166493\ttest: 0.0168367\tbest: 0.0168367 (7690)\ttotal: 7m 53s\tremaining: 7m 30s\n",
            "7700:\tlearn: 0.0166482\ttest: 0.0168358\tbest: 0.0168358 (7700)\ttotal: 7m 54s\tremaining: 7m 29s\n",
            "7710:\tlearn: 0.0166472\ttest: 0.0168349\tbest: 0.0168349 (7710)\ttotal: 7m 54s\tremaining: 7m 28s\n",
            "7720:\tlearn: 0.0166461\ttest: 0.0168340\tbest: 0.0168340 (7720)\ttotal: 7m 55s\tremaining: 7m 28s\n",
            "7730:\tlearn: 0.0166450\ttest: 0.0168330\tbest: 0.0168330 (7730)\ttotal: 7m 56s\tremaining: 7m 27s\n",
            "7740:\tlearn: 0.0166439\ttest: 0.0168322\tbest: 0.0168322 (7740)\ttotal: 7m 56s\tremaining: 7m 27s\n",
            "7750:\tlearn: 0.0166429\ttest: 0.0168312\tbest: 0.0168312 (7750)\ttotal: 7m 57s\tremaining: 7m 26s\n",
            "7760:\tlearn: 0.0166418\ttest: 0.0168303\tbest: 0.0168303 (7760)\ttotal: 7m 57s\tremaining: 7m 25s\n",
            "7770:\tlearn: 0.0166407\ttest: 0.0168294\tbest: 0.0168294 (7770)\ttotal: 7m 58s\tremaining: 7m 25s\n",
            "7780:\tlearn: 0.0166398\ttest: 0.0168286\tbest: 0.0168286 (7780)\ttotal: 7m 59s\tremaining: 7m 24s\n",
            "7790:\tlearn: 0.0166388\ttest: 0.0168278\tbest: 0.0168278 (7790)\ttotal: 7m 59s\tremaining: 7m 23s\n",
            "7800:\tlearn: 0.0166378\ttest: 0.0168270\tbest: 0.0168270 (7800)\ttotal: 8m\tremaining: 7m 23s\n",
            "7810:\tlearn: 0.0166370\ttest: 0.0168263\tbest: 0.0168263 (7810)\ttotal: 8m\tremaining: 7m 22s\n",
            "7820:\tlearn: 0.0166360\ttest: 0.0168255\tbest: 0.0168255 (7820)\ttotal: 8m 1s\tremaining: 7m 22s\n",
            "7830:\tlearn: 0.0166351\ttest: 0.0168247\tbest: 0.0168247 (7830)\ttotal: 8m 2s\tremaining: 7m 21s\n",
            "7840:\tlearn: 0.0166341\ttest: 0.0168239\tbest: 0.0168239 (7840)\ttotal: 8m 2s\tremaining: 7m 20s\n",
            "7850:\tlearn: 0.0166332\ttest: 0.0168231\tbest: 0.0168231 (7850)\ttotal: 8m 3s\tremaining: 7m 20s\n",
            "7860:\tlearn: 0.0166322\ttest: 0.0168223\tbest: 0.0168223 (7860)\ttotal: 8m 4s\tremaining: 7m 19s\n",
            "7870:\tlearn: 0.0166313\ttest: 0.0168215\tbest: 0.0168215 (7870)\ttotal: 8m 4s\tremaining: 7m 18s\n",
            "7880:\tlearn: 0.0166303\ttest: 0.0168207\tbest: 0.0168207 (7880)\ttotal: 8m 5s\tremaining: 7m 18s\n",
            "7890:\tlearn: 0.0166294\ttest: 0.0168199\tbest: 0.0168199 (7890)\ttotal: 8m 5s\tremaining: 7m 17s\n",
            "7900:\tlearn: 0.0166286\ttest: 0.0168192\tbest: 0.0168192 (7900)\ttotal: 8m 6s\tremaining: 7m 17s\n",
            "7910:\tlearn: 0.0166277\ttest: 0.0168184\tbest: 0.0168184 (7910)\ttotal: 8m 7s\tremaining: 7m 16s\n",
            "7920:\tlearn: 0.0166268\ttest: 0.0168177\tbest: 0.0168177 (7920)\ttotal: 8m 7s\tremaining: 7m 15s\n",
            "7930:\tlearn: 0.0166260\ttest: 0.0168170\tbest: 0.0168170 (7930)\ttotal: 8m 8s\tremaining: 7m 15s\n",
            "7940:\tlearn: 0.0166252\ttest: 0.0168162\tbest: 0.0168162 (7940)\ttotal: 8m 8s\tremaining: 7m 14s\n",
            "7950:\tlearn: 0.0166243\ttest: 0.0168155\tbest: 0.0168155 (7950)\ttotal: 8m 9s\tremaining: 7m 13s\n",
            "7960:\tlearn: 0.0166236\ttest: 0.0168148\tbest: 0.0168148 (7960)\ttotal: 8m 10s\tremaining: 7m 13s\n",
            "7970:\tlearn: 0.0166227\ttest: 0.0168141\tbest: 0.0168141 (7970)\ttotal: 8m 10s\tremaining: 7m 12s\n",
            "7980:\tlearn: 0.0166219\ttest: 0.0168134\tbest: 0.0168134 (7980)\ttotal: 8m 11s\tremaining: 7m 12s\n",
            "7990:\tlearn: 0.0166211\ttest: 0.0168127\tbest: 0.0168127 (7990)\ttotal: 8m 11s\tremaining: 7m 11s\n",
            "8000:\tlearn: 0.0166203\ttest: 0.0168120\tbest: 0.0168120 (8000)\ttotal: 8m 12s\tremaining: 7m 10s\n",
            "8010:\tlearn: 0.0166195\ttest: 0.0168114\tbest: 0.0168114 (8010)\ttotal: 8m 13s\tremaining: 7m 10s\n",
            "8020:\tlearn: 0.0166187\ttest: 0.0168107\tbest: 0.0168107 (8020)\ttotal: 8m 13s\tremaining: 7m 9s\n",
            "8030:\tlearn: 0.0166179\ttest: 0.0168100\tbest: 0.0168100 (8030)\ttotal: 8m 14s\tremaining: 7m 9s\n",
            "8040:\tlearn: 0.0166171\ttest: 0.0168094\tbest: 0.0168094 (8040)\ttotal: 8m 15s\tremaining: 7m 8s\n",
            "8050:\tlearn: 0.0166163\ttest: 0.0168087\tbest: 0.0168087 (8050)\ttotal: 8m 15s\tremaining: 7m 7s\n",
            "8060:\tlearn: 0.0166155\ttest: 0.0168079\tbest: 0.0168079 (8060)\ttotal: 8m 16s\tremaining: 7m 7s\n",
            "8070:\tlearn: 0.0166146\ttest: 0.0168072\tbest: 0.0168072 (8070)\ttotal: 8m 16s\tremaining: 7m 6s\n",
            "8080:\tlearn: 0.0166138\ttest: 0.0168065\tbest: 0.0168065 (8080)\ttotal: 8m 17s\tremaining: 7m 6s\n",
            "8090:\tlearn: 0.0166130\ttest: 0.0168058\tbest: 0.0168058 (8090)\ttotal: 8m 18s\tremaining: 7m 5s\n",
            "8100:\tlearn: 0.0166122\ttest: 0.0168051\tbest: 0.0168051 (8100)\ttotal: 8m 18s\tremaining: 7m 4s\n",
            "8110:\tlearn: 0.0166114\ttest: 0.0168045\tbest: 0.0168045 (8110)\ttotal: 8m 19s\tremaining: 7m 4s\n",
            "8120:\tlearn: 0.0166106\ttest: 0.0168038\tbest: 0.0168038 (8120)\ttotal: 8m 20s\tremaining: 7m 3s\n",
            "8130:\tlearn: 0.0166099\ttest: 0.0168031\tbest: 0.0168031 (8130)\ttotal: 8m 20s\tremaining: 7m 2s\n",
            "8140:\tlearn: 0.0166091\ttest: 0.0168024\tbest: 0.0168024 (8140)\ttotal: 8m 21s\tremaining: 7m 2s\n",
            "8150:\tlearn: 0.0166083\ttest: 0.0168018\tbest: 0.0168018 (8150)\ttotal: 8m 21s\tremaining: 7m 1s\n",
            "8160:\tlearn: 0.0166076\ttest: 0.0168012\tbest: 0.0168012 (8160)\ttotal: 8m 22s\tremaining: 7m 1s\n",
            "8170:\tlearn: 0.0166069\ttest: 0.0168007\tbest: 0.0168007 (8170)\ttotal: 8m 23s\tremaining: 7m\n",
            "8180:\tlearn: 0.0166062\ttest: 0.0168001\tbest: 0.0168001 (8180)\ttotal: 8m 23s\tremaining: 6m 59s\n",
            "8190:\tlearn: 0.0166056\ttest: 0.0167995\tbest: 0.0167995 (8190)\ttotal: 8m 24s\tremaining: 6m 59s\n",
            "8200:\tlearn: 0.0166047\ttest: 0.0167988\tbest: 0.0167988 (8200)\ttotal: 8m 25s\tremaining: 6m 58s\n",
            "8210:\tlearn: 0.0166040\ttest: 0.0167982\tbest: 0.0167982 (8210)\ttotal: 8m 25s\tremaining: 6m 58s\n",
            "8220:\tlearn: 0.0166033\ttest: 0.0167976\tbest: 0.0167976 (8220)\ttotal: 8m 26s\tremaining: 6m 57s\n",
            "8230:\tlearn: 0.0166026\ttest: 0.0167970\tbest: 0.0167970 (8230)\ttotal: 8m 27s\tremaining: 6m 57s\n",
            "8240:\tlearn: 0.0166019\ttest: 0.0167964\tbest: 0.0167964 (8240)\ttotal: 8m 27s\tremaining: 6m 56s\n",
            "8250:\tlearn: 0.0166011\ttest: 0.0167957\tbest: 0.0167957 (8250)\ttotal: 8m 28s\tremaining: 6m 55s\n",
            "8260:\tlearn: 0.0166005\ttest: 0.0167951\tbest: 0.0167951 (8260)\ttotal: 8m 29s\tremaining: 6m 55s\n",
            "8270:\tlearn: 0.0165997\ttest: 0.0167946\tbest: 0.0167946 (8270)\ttotal: 8m 29s\tremaining: 6m 54s\n",
            "8280:\tlearn: 0.0165990\ttest: 0.0167940\tbest: 0.0167940 (8280)\ttotal: 8m 30s\tremaining: 6m 54s\n",
            "8290:\tlearn: 0.0165984\ttest: 0.0167934\tbest: 0.0167934 (8290)\ttotal: 8m 30s\tremaining: 6m 53s\n",
            "8300:\tlearn: 0.0165978\ttest: 0.0167929\tbest: 0.0167929 (8300)\ttotal: 8m 31s\tremaining: 6m 52s\n",
            "8310:\tlearn: 0.0165971\ttest: 0.0167923\tbest: 0.0167923 (8310)\ttotal: 8m 32s\tremaining: 6m 52s\n",
            "8320:\tlearn: 0.0165963\ttest: 0.0167916\tbest: 0.0167916 (8320)\ttotal: 8m 32s\tremaining: 6m 51s\n",
            "8330:\tlearn: 0.0165957\ttest: 0.0167911\tbest: 0.0167911 (8330)\ttotal: 8m 33s\tremaining: 6m 51s\n",
            "8340:\tlearn: 0.0165950\ttest: 0.0167905\tbest: 0.0167905 (8340)\ttotal: 8m 34s\tremaining: 6m 50s\n",
            "8350:\tlearn: 0.0165943\ttest: 0.0167899\tbest: 0.0167899 (8350)\ttotal: 8m 34s\tremaining: 6m 50s\n",
            "8360:\tlearn: 0.0165936\ttest: 0.0167893\tbest: 0.0167893 (8360)\ttotal: 8m 35s\tremaining: 6m 49s\n",
            "8370:\tlearn: 0.0165930\ttest: 0.0167888\tbest: 0.0167888 (8370)\ttotal: 8m 36s\tremaining: 6m 48s\n",
            "8380:\tlearn: 0.0165923\ttest: 0.0167882\tbest: 0.0167882 (8380)\ttotal: 8m 36s\tremaining: 6m 48s\n",
            "8390:\tlearn: 0.0165916\ttest: 0.0167877\tbest: 0.0167877 (8390)\ttotal: 8m 37s\tremaining: 6m 47s\n",
            "8400:\tlearn: 0.0165910\ttest: 0.0167871\tbest: 0.0167871 (8400)\ttotal: 8m 38s\tremaining: 6m 47s\n",
            "8410:\tlearn: 0.0165903\ttest: 0.0167865\tbest: 0.0167865 (8410)\ttotal: 8m 39s\tremaining: 6m 46s\n",
            "8420:\tlearn: 0.0165897\ttest: 0.0167861\tbest: 0.0167861 (8420)\ttotal: 8m 39s\tremaining: 6m 46s\n",
            "8430:\tlearn: 0.0165890\ttest: 0.0167855\tbest: 0.0167855 (8430)\ttotal: 8m 40s\tremaining: 6m 45s\n",
            "8440:\tlearn: 0.0165883\ttest: 0.0167850\tbest: 0.0167850 (8440)\ttotal: 8m 41s\tremaining: 6m 44s\n",
            "8450:\tlearn: 0.0165876\ttest: 0.0167844\tbest: 0.0167844 (8450)\ttotal: 8m 41s\tremaining: 6m 44s\n",
            "8460:\tlearn: 0.0165870\ttest: 0.0167838\tbest: 0.0167838 (8460)\ttotal: 8m 42s\tremaining: 6m 43s\n",
            "8470:\tlearn: 0.0165864\ttest: 0.0167833\tbest: 0.0167833 (8470)\ttotal: 8m 43s\tremaining: 6m 43s\n",
            "8480:\tlearn: 0.0165858\ttest: 0.0167828\tbest: 0.0167828 (8480)\ttotal: 8m 43s\tremaining: 6m 42s\n",
            "8490:\tlearn: 0.0165851\ttest: 0.0167823\tbest: 0.0167823 (8490)\ttotal: 8m 44s\tremaining: 6m 41s\n",
            "8500:\tlearn: 0.0165845\ttest: 0.0167818\tbest: 0.0167818 (8500)\ttotal: 8m 45s\tremaining: 6m 41s\n",
            "8510:\tlearn: 0.0165839\ttest: 0.0167813\tbest: 0.0167813 (8510)\ttotal: 8m 45s\tremaining: 6m 40s\n",
            "8520:\tlearn: 0.0165832\ttest: 0.0167807\tbest: 0.0167807 (8520)\ttotal: 8m 46s\tremaining: 6m 40s\n",
            "8530:\tlearn: 0.0165826\ttest: 0.0167802\tbest: 0.0167802 (8530)\ttotal: 8m 47s\tremaining: 6m 39s\n",
            "8540:\tlearn: 0.0165819\ttest: 0.0167796\tbest: 0.0167796 (8540)\ttotal: 8m 47s\tremaining: 6m 39s\n",
            "8550:\tlearn: 0.0165813\ttest: 0.0167792\tbest: 0.0167792 (8550)\ttotal: 8m 48s\tremaining: 6m 38s\n",
            "8560:\tlearn: 0.0165807\ttest: 0.0167786\tbest: 0.0167786 (8560)\ttotal: 8m 49s\tremaining: 6m 38s\n",
            "8570:\tlearn: 0.0165800\ttest: 0.0167781\tbest: 0.0167781 (8570)\ttotal: 8m 49s\tremaining: 6m 37s\n",
            "8580:\tlearn: 0.0165794\ttest: 0.0167776\tbest: 0.0167776 (8580)\ttotal: 8m 50s\tremaining: 6m 36s\n",
            "8590:\tlearn: 0.0165788\ttest: 0.0167771\tbest: 0.0167771 (8590)\ttotal: 8m 51s\tremaining: 6m 36s\n",
            "8600:\tlearn: 0.0165782\ttest: 0.0167765\tbest: 0.0167765 (8600)\ttotal: 8m 52s\tremaining: 6m 35s\n",
            "8610:\tlearn: 0.0165776\ttest: 0.0167760\tbest: 0.0167760 (8610)\ttotal: 8m 52s\tremaining: 6m 35s\n",
            "8620:\tlearn: 0.0165770\ttest: 0.0167755\tbest: 0.0167755 (8620)\ttotal: 8m 53s\tremaining: 6m 34s\n",
            "8630:\tlearn: 0.0165764\ttest: 0.0167750\tbest: 0.0167750 (8630)\ttotal: 8m 53s\tremaining: 6m 34s\n",
            "8640:\tlearn: 0.0165758\ttest: 0.0167746\tbest: 0.0167746 (8640)\ttotal: 8m 54s\tremaining: 6m 33s\n",
            "8650:\tlearn: 0.0165752\ttest: 0.0167741\tbest: 0.0167741 (8650)\ttotal: 8m 55s\tremaining: 6m 32s\n",
            "8660:\tlearn: 0.0165746\ttest: 0.0167736\tbest: 0.0167736 (8660)\ttotal: 8m 56s\tremaining: 6m 32s\n",
            "8670:\tlearn: 0.0165739\ttest: 0.0167731\tbest: 0.0167731 (8670)\ttotal: 8m 56s\tremaining: 6m 31s\n",
            "8680:\tlearn: 0.0165734\ttest: 0.0167727\tbest: 0.0167727 (8680)\ttotal: 8m 57s\tremaining: 6m 31s\n",
            "8690:\tlearn: 0.0165728\ttest: 0.0167722\tbest: 0.0167722 (8690)\ttotal: 8m 58s\tremaining: 6m 30s\n",
            "8700:\tlearn: 0.0165722\ttest: 0.0167717\tbest: 0.0167717 (8700)\ttotal: 8m 58s\tremaining: 6m 30s\n",
            "8710:\tlearn: 0.0165715\ttest: 0.0167712\tbest: 0.0167712 (8710)\ttotal: 8m 59s\tremaining: 6m 29s\n",
            "8720:\tlearn: 0.0165710\ttest: 0.0167707\tbest: 0.0167707 (8720)\ttotal: 9m\tremaining: 6m 29s\n",
            "8730:\tlearn: 0.0165703\ttest: 0.0167702\tbest: 0.0167702 (8730)\ttotal: 9m 1s\tremaining: 6m 28s\n",
            "8740:\tlearn: 0.0165697\ttest: 0.0167698\tbest: 0.0167698 (8740)\ttotal: 9m 1s\tremaining: 6m 27s\n",
            "8750:\tlearn: 0.0165691\ttest: 0.0167693\tbest: 0.0167693 (8750)\ttotal: 9m 2s\tremaining: 6m 27s\n",
            "8760:\tlearn: 0.0165685\ttest: 0.0167688\tbest: 0.0167688 (8760)\ttotal: 9m 3s\tremaining: 6m 26s\n",
            "8770:\tlearn: 0.0165679\ttest: 0.0167683\tbest: 0.0167683 (8770)\ttotal: 9m 3s\tremaining: 6m 26s\n",
            "8780:\tlearn: 0.0165674\ttest: 0.0167679\tbest: 0.0167679 (8780)\ttotal: 9m 4s\tremaining: 6m 25s\n",
            "8790:\tlearn: 0.0165668\ttest: 0.0167674\tbest: 0.0167674 (8790)\ttotal: 9m 5s\tremaining: 6m 25s\n",
            "8800:\tlearn: 0.0165664\ttest: 0.0167671\tbest: 0.0167671 (8800)\ttotal: 9m 5s\tremaining: 6m 24s\n",
            "8810:\tlearn: 0.0165658\ttest: 0.0167666\tbest: 0.0167666 (8810)\ttotal: 9m 6s\tremaining: 6m 23s\n",
            "8820:\tlearn: 0.0165652\ttest: 0.0167662\tbest: 0.0167662 (8820)\ttotal: 9m 7s\tremaining: 6m 23s\n",
            "8830:\tlearn: 0.0165647\ttest: 0.0167658\tbest: 0.0167658 (8830)\ttotal: 9m 8s\tremaining: 6m 22s\n",
            "8840:\tlearn: 0.0165640\ttest: 0.0167653\tbest: 0.0167653 (8840)\ttotal: 9m 8s\tremaining: 6m 22s\n",
            "8850:\tlearn: 0.0165635\ttest: 0.0167648\tbest: 0.0167648 (8850)\ttotal: 9m 9s\tremaining: 6m 21s\n",
            "8860:\tlearn: 0.0165629\ttest: 0.0167644\tbest: 0.0167644 (8860)\ttotal: 9m 10s\tremaining: 6m 21s\n",
            "8870:\tlearn: 0.0165623\ttest: 0.0167639\tbest: 0.0167639 (8870)\ttotal: 9m 10s\tremaining: 6m 20s\n",
            "8880:\tlearn: 0.0165618\ttest: 0.0167635\tbest: 0.0167635 (8880)\ttotal: 9m 11s\tremaining: 6m 20s\n",
            "8890:\tlearn: 0.0165613\ttest: 0.0167631\tbest: 0.0167631 (8890)\ttotal: 9m 12s\tremaining: 6m 19s\n",
            "8900:\tlearn: 0.0165608\ttest: 0.0167627\tbest: 0.0167627 (8900)\ttotal: 9m 12s\tremaining: 6m 18s\n",
            "8910:\tlearn: 0.0165602\ttest: 0.0167623\tbest: 0.0167623 (8910)\ttotal: 9m 13s\tremaining: 6m 18s\n",
            "8920:\tlearn: 0.0165596\ttest: 0.0167618\tbest: 0.0167618 (8920)\ttotal: 9m 14s\tremaining: 6m 17s\n",
            "8930:\tlearn: 0.0165591\ttest: 0.0167614\tbest: 0.0167614 (8930)\ttotal: 9m 15s\tremaining: 6m 17s\n",
            "8940:\tlearn: 0.0165586\ttest: 0.0167610\tbest: 0.0167610 (8940)\ttotal: 9m 15s\tremaining: 6m 16s\n",
            "8950:\tlearn: 0.0165581\ttest: 0.0167606\tbest: 0.0167606 (8950)\ttotal: 9m 16s\tremaining: 6m 16s\n",
            "8960:\tlearn: 0.0165575\ttest: 0.0167602\tbest: 0.0167602 (8960)\ttotal: 9m 17s\tremaining: 6m 15s\n",
            "8970:\tlearn: 0.0165570\ttest: 0.0167598\tbest: 0.0167598 (8970)\ttotal: 9m 17s\tremaining: 6m 14s\n",
            "8980:\tlearn: 0.0165564\ttest: 0.0167594\tbest: 0.0167594 (8980)\ttotal: 9m 18s\tremaining: 6m 14s\n",
            "8990:\tlearn: 0.0165559\ttest: 0.0167590\tbest: 0.0167590 (8990)\ttotal: 9m 19s\tremaining: 6m 13s\n",
            "9000:\tlearn: 0.0165553\ttest: 0.0167585\tbest: 0.0167585 (9000)\ttotal: 9m 20s\tremaining: 6m 13s\n",
            "9010:\tlearn: 0.0165547\ttest: 0.0167581\tbest: 0.0167581 (9010)\ttotal: 9m 20s\tremaining: 6m 12s\n",
            "9020:\tlearn: 0.0165542\ttest: 0.0167576\tbest: 0.0167576 (9020)\ttotal: 9m 21s\tremaining: 6m 12s\n",
            "9030:\tlearn: 0.0165536\ttest: 0.0167572\tbest: 0.0167572 (9030)\ttotal: 9m 22s\tremaining: 6m 11s\n",
            "9040:\tlearn: 0.0165531\ttest: 0.0167568\tbest: 0.0167568 (9040)\ttotal: 9m 23s\tremaining: 6m 11s\n",
            "9050:\tlearn: 0.0165525\ttest: 0.0167564\tbest: 0.0167564 (9050)\ttotal: 9m 23s\tremaining: 6m 10s\n",
            "9060:\tlearn: 0.0165520\ttest: 0.0167560\tbest: 0.0167560 (9060)\ttotal: 9m 24s\tremaining: 6m 10s\n",
            "9070:\tlearn: 0.0165515\ttest: 0.0167556\tbest: 0.0167556 (9070)\ttotal: 9m 25s\tremaining: 6m 9s\n",
            "9080:\tlearn: 0.0165510\ttest: 0.0167551\tbest: 0.0167551 (9080)\ttotal: 9m 25s\tremaining: 6m 8s\n",
            "9090:\tlearn: 0.0165505\ttest: 0.0167548\tbest: 0.0167548 (9090)\ttotal: 9m 26s\tremaining: 6m 8s\n",
            "9100:\tlearn: 0.0165499\ttest: 0.0167544\tbest: 0.0167544 (9100)\ttotal: 9m 27s\tremaining: 6m 7s\n",
            "9110:\tlearn: 0.0165494\ttest: 0.0167540\tbest: 0.0167540 (9110)\ttotal: 9m 28s\tremaining: 6m 7s\n",
            "9120:\tlearn: 0.0165489\ttest: 0.0167536\tbest: 0.0167536 (9120)\ttotal: 9m 28s\tremaining: 6m 6s\n",
            "9130:\tlearn: 0.0165484\ttest: 0.0167532\tbest: 0.0167532 (9130)\ttotal: 9m 29s\tremaining: 6m 6s\n",
            "9140:\tlearn: 0.0165479\ttest: 0.0167528\tbest: 0.0167528 (9140)\ttotal: 9m 30s\tremaining: 6m 5s\n",
            "9150:\tlearn: 0.0165475\ttest: 0.0167525\tbest: 0.0167525 (9150)\ttotal: 9m 30s\tremaining: 6m 4s\n",
            "9160:\tlearn: 0.0165470\ttest: 0.0167521\tbest: 0.0167521 (9160)\ttotal: 9m 31s\tremaining: 6m 4s\n",
            "9170:\tlearn: 0.0165465\ttest: 0.0167517\tbest: 0.0167517 (9170)\ttotal: 9m 32s\tremaining: 6m 3s\n",
            "9180:\tlearn: 0.0165459\ttest: 0.0167513\tbest: 0.0167513 (9180)\ttotal: 9m 32s\tremaining: 6m 3s\n",
            "9190:\tlearn: 0.0165454\ttest: 0.0167509\tbest: 0.0167509 (9190)\ttotal: 9m 33s\tremaining: 6m 2s\n",
            "9200:\tlearn: 0.0165449\ttest: 0.0167505\tbest: 0.0167505 (9200)\ttotal: 9m 34s\tremaining: 6m 1s\n",
            "9210:\tlearn: 0.0165444\ttest: 0.0167501\tbest: 0.0167501 (9210)\ttotal: 9m 35s\tremaining: 6m 1s\n",
            "9220:\tlearn: 0.0165438\ttest: 0.0167497\tbest: 0.0167497 (9220)\ttotal: 9m 35s\tremaining: 6m\n",
            "9230:\tlearn: 0.0165434\ttest: 0.0167493\tbest: 0.0167493 (9230)\ttotal: 9m 36s\tremaining: 6m\n",
            "9240:\tlearn: 0.0165429\ttest: 0.0167489\tbest: 0.0167489 (9240)\ttotal: 9m 37s\tremaining: 5m 59s\n",
            "9250:\tlearn: 0.0165424\ttest: 0.0167485\tbest: 0.0167485 (9250)\ttotal: 9m 37s\tremaining: 5m 59s\n",
            "9260:\tlearn: 0.0165419\ttest: 0.0167482\tbest: 0.0167482 (9260)\ttotal: 9m 38s\tremaining: 5m 58s\n",
            "9270:\tlearn: 0.0165413\ttest: 0.0167478\tbest: 0.0167478 (9270)\ttotal: 9m 39s\tremaining: 5m 58s\n",
            "9280:\tlearn: 0.0165408\ttest: 0.0167474\tbest: 0.0167474 (9280)\ttotal: 9m 40s\tremaining: 5m 57s\n",
            "9290:\tlearn: 0.0165404\ttest: 0.0167471\tbest: 0.0167471 (9290)\ttotal: 9m 40s\tremaining: 5m 56s\n",
            "9300:\tlearn: 0.0165399\ttest: 0.0167467\tbest: 0.0167467 (9300)\ttotal: 9m 41s\tremaining: 5m 56s\n",
            "9310:\tlearn: 0.0165394\ttest: 0.0167463\tbest: 0.0167463 (9310)\ttotal: 9m 42s\tremaining: 5m 55s\n",
            "9320:\tlearn: 0.0165389\ttest: 0.0167459\tbest: 0.0167459 (9320)\ttotal: 9m 43s\tremaining: 5m 55s\n",
            "9330:\tlearn: 0.0165384\ttest: 0.0167455\tbest: 0.0167455 (9330)\ttotal: 9m 43s\tremaining: 5m 54s\n",
            "9340:\tlearn: 0.0165379\ttest: 0.0167451\tbest: 0.0167451 (9340)\ttotal: 9m 44s\tremaining: 5m 54s\n",
            "9350:\tlearn: 0.0165374\ttest: 0.0167447\tbest: 0.0167447 (9350)\ttotal: 9m 45s\tremaining: 5m 53s\n",
            "9360:\tlearn: 0.0165368\ttest: 0.0167443\tbest: 0.0167443 (9360)\ttotal: 9m 46s\tremaining: 5m 53s\n",
            "9370:\tlearn: 0.0165364\ttest: 0.0167439\tbest: 0.0167439 (9370)\ttotal: 9m 46s\tremaining: 5m 52s\n",
            "9380:\tlearn: 0.0165359\ttest: 0.0167436\tbest: 0.0167436 (9380)\ttotal: 9m 47s\tremaining: 5m 51s\n",
            "9390:\tlearn: 0.0165354\ttest: 0.0167432\tbest: 0.0167432 (9390)\ttotal: 9m 48s\tremaining: 5m 51s\n",
            "9400:\tlearn: 0.0165349\ttest: 0.0167429\tbest: 0.0167429 (9400)\ttotal: 9m 48s\tremaining: 5m 50s\n",
            "9410:\tlearn: 0.0165345\ttest: 0.0167425\tbest: 0.0167425 (9410)\ttotal: 9m 49s\tremaining: 5m 50s\n",
            "9420:\tlearn: 0.0165340\ttest: 0.0167421\tbest: 0.0167421 (9420)\ttotal: 9m 50s\tremaining: 5m 49s\n",
            "9430:\tlearn: 0.0165335\ttest: 0.0167418\tbest: 0.0167418 (9430)\ttotal: 9m 51s\tremaining: 5m 49s\n",
            "9440:\tlearn: 0.0165330\ttest: 0.0167414\tbest: 0.0167414 (9440)\ttotal: 9m 51s\tremaining: 5m 48s\n",
            "9450:\tlearn: 0.0165326\ttest: 0.0167411\tbest: 0.0167411 (9450)\ttotal: 9m 52s\tremaining: 5m 47s\n",
            "9460:\tlearn: 0.0165321\ttest: 0.0167407\tbest: 0.0167407 (9460)\ttotal: 9m 53s\tremaining: 5m 47s\n",
            "9470:\tlearn: 0.0165316\ttest: 0.0167403\tbest: 0.0167403 (9470)\ttotal: 9m 54s\tremaining: 5m 46s\n",
            "9480:\tlearn: 0.0165311\ttest: 0.0167399\tbest: 0.0167399 (9480)\ttotal: 9m 54s\tremaining: 5m 46s\n",
            "9490:\tlearn: 0.0165306\ttest: 0.0167396\tbest: 0.0167396 (9490)\ttotal: 9m 55s\tremaining: 5m 45s\n",
            "9500:\tlearn: 0.0165302\ttest: 0.0167392\tbest: 0.0167392 (9500)\ttotal: 9m 56s\tremaining: 5m 45s\n",
            "9510:\tlearn: 0.0165298\ttest: 0.0167389\tbest: 0.0167389 (9510)\ttotal: 9m 56s\tremaining: 5m 44s\n",
            "9520:\tlearn: 0.0165293\ttest: 0.0167385\tbest: 0.0167385 (9520)\ttotal: 9m 57s\tremaining: 5m 43s\n",
            "9530:\tlearn: 0.0165289\ttest: 0.0167382\tbest: 0.0167382 (9530)\ttotal: 9m 58s\tremaining: 5m 43s\n",
            "9540:\tlearn: 0.0165284\ttest: 0.0167378\tbest: 0.0167378 (9540)\ttotal: 9m 58s\tremaining: 5m 42s\n",
            "9550:\tlearn: 0.0165280\ttest: 0.0167375\tbest: 0.0167375 (9550)\ttotal: 9m 59s\tremaining: 5m 42s\n",
            "9560:\tlearn: 0.0165275\ttest: 0.0167371\tbest: 0.0167371 (9560)\ttotal: 10m\tremaining: 5m 41s\n",
            "9570:\tlearn: 0.0165270\ttest: 0.0167368\tbest: 0.0167368 (9570)\ttotal: 10m 1s\tremaining: 5m 41s\n",
            "9580:\tlearn: 0.0165265\ttest: 0.0167364\tbest: 0.0167364 (9580)\ttotal: 10m 1s\tremaining: 5m 40s\n",
            "9590:\tlearn: 0.0165260\ttest: 0.0167361\tbest: 0.0167361 (9590)\ttotal: 10m 2s\tremaining: 5m 39s\n",
            "9600:\tlearn: 0.0165256\ttest: 0.0167357\tbest: 0.0167357 (9600)\ttotal: 10m 3s\tremaining: 5m 39s\n",
            "9610:\tlearn: 0.0165252\ttest: 0.0167354\tbest: 0.0167354 (9610)\ttotal: 10m 4s\tremaining: 5m 38s\n",
            "9620:\tlearn: 0.0165247\ttest: 0.0167351\tbest: 0.0167351 (9620)\ttotal: 10m 4s\tremaining: 5m 38s\n",
            "9630:\tlearn: 0.0165243\ttest: 0.0167348\tbest: 0.0167348 (9630)\ttotal: 10m 5s\tremaining: 5m 37s\n",
            "9640:\tlearn: 0.0165239\ttest: 0.0167345\tbest: 0.0167345 (9640)\ttotal: 10m 6s\tremaining: 5m 36s\n",
            "9650:\tlearn: 0.0165235\ttest: 0.0167342\tbest: 0.0167342 (9650)\ttotal: 10m 6s\tremaining: 5m 36s\n",
            "9660:\tlearn: 0.0165231\ttest: 0.0167339\tbest: 0.0167339 (9660)\ttotal: 10m 7s\tremaining: 5m 35s\n",
            "9670:\tlearn: 0.0165226\ttest: 0.0167336\tbest: 0.0167336 (9670)\ttotal: 10m 8s\tremaining: 5m 35s\n",
            "9680:\tlearn: 0.0165222\ttest: 0.0167332\tbest: 0.0167332 (9680)\ttotal: 10m 8s\tremaining: 5m 34s\n",
            "9690:\tlearn: 0.0165217\ttest: 0.0167329\tbest: 0.0167329 (9690)\ttotal: 10m 9s\tremaining: 5m 33s\n",
            "9700:\tlearn: 0.0165212\ttest: 0.0167325\tbest: 0.0167325 (9700)\ttotal: 10m 10s\tremaining: 5m 33s\n",
            "9710:\tlearn: 0.0165208\ttest: 0.0167322\tbest: 0.0167322 (9710)\ttotal: 10m 11s\tremaining: 5m 32s\n",
            "9720:\tlearn: 0.0165203\ttest: 0.0167318\tbest: 0.0167318 (9720)\ttotal: 10m 11s\tremaining: 5m 32s\n",
            "9730:\tlearn: 0.0165199\ttest: 0.0167315\tbest: 0.0167315 (9730)\ttotal: 10m 12s\tremaining: 5m 31s\n",
            "9740:\tlearn: 0.0165194\ttest: 0.0167312\tbest: 0.0167312 (9740)\ttotal: 10m 13s\tremaining: 5m 31s\n",
            "9750:\tlearn: 0.0165191\ttest: 0.0167309\tbest: 0.0167309 (9750)\ttotal: 10m 13s\tremaining: 5m 30s\n",
            "9760:\tlearn: 0.0165186\ttest: 0.0167305\tbest: 0.0167305 (9760)\ttotal: 10m 14s\tremaining: 5m 29s\n",
            "9770:\tlearn: 0.0165182\ttest: 0.0167302\tbest: 0.0167302 (9770)\ttotal: 10m 15s\tremaining: 5m 29s\n",
            "9780:\tlearn: 0.0165178\ttest: 0.0167299\tbest: 0.0167299 (9780)\ttotal: 10m 16s\tremaining: 5m 28s\n",
            "9790:\tlearn: 0.0165173\ttest: 0.0167296\tbest: 0.0167296 (9790)\ttotal: 10m 16s\tremaining: 5m 28s\n",
            "9800:\tlearn: 0.0165169\ttest: 0.0167292\tbest: 0.0167292 (9800)\ttotal: 10m 17s\tremaining: 5m 27s\n",
            "9810:\tlearn: 0.0165164\ttest: 0.0167288\tbest: 0.0167288 (9810)\ttotal: 10m 18s\tremaining: 5m 27s\n",
            "9820:\tlearn: 0.0165160\ttest: 0.0167285\tbest: 0.0167285 (9820)\ttotal: 10m 19s\tremaining: 5m 26s\n",
            "9830:\tlearn: 0.0165155\ttest: 0.0167282\tbest: 0.0167282 (9830)\ttotal: 10m 19s\tremaining: 5m 25s\n",
            "9840:\tlearn: 0.0165151\ttest: 0.0167279\tbest: 0.0167279 (9840)\ttotal: 10m 20s\tremaining: 5m 25s\n",
            "9850:\tlearn: 0.0165147\ttest: 0.0167276\tbest: 0.0167276 (9850)\ttotal: 10m 21s\tremaining: 5m 24s\n",
            "9860:\tlearn: 0.0165143\ttest: 0.0167272\tbest: 0.0167272 (9860)\ttotal: 10m 21s\tremaining: 5m 24s\n",
            "9870:\tlearn: 0.0165139\ttest: 0.0167269\tbest: 0.0167269 (9870)\ttotal: 10m 22s\tremaining: 5m 23s\n",
            "9880:\tlearn: 0.0165135\ttest: 0.0167266\tbest: 0.0167266 (9880)\ttotal: 10m 23s\tremaining: 5m 22s\n",
            "9890:\tlearn: 0.0165131\ttest: 0.0167264\tbest: 0.0167264 (9890)\ttotal: 10m 24s\tremaining: 5m 22s\n",
            "9900:\tlearn: 0.0165126\ttest: 0.0167260\tbest: 0.0167260 (9900)\ttotal: 10m 24s\tremaining: 5m 21s\n",
            "9910:\tlearn: 0.0165123\ttest: 0.0167257\tbest: 0.0167257 (9910)\ttotal: 10m 25s\tremaining: 5m 21s\n",
            "9920:\tlearn: 0.0165118\ttest: 0.0167254\tbest: 0.0167254 (9920)\ttotal: 10m 26s\tremaining: 5m 20s\n",
            "9930:\tlearn: 0.0165115\ttest: 0.0167251\tbest: 0.0167251 (9930)\ttotal: 10m 26s\tremaining: 5m 19s\n",
            "9940:\tlearn: 0.0165111\ttest: 0.0167249\tbest: 0.0167249 (9940)\ttotal: 10m 27s\tremaining: 5m 19s\n",
            "9950:\tlearn: 0.0165107\ttest: 0.0167245\tbest: 0.0167245 (9950)\ttotal: 10m 28s\tremaining: 5m 18s\n",
            "9960:\tlearn: 0.0165102\ttest: 0.0167242\tbest: 0.0167242 (9960)\ttotal: 10m 29s\tremaining: 5m 18s\n",
            "9970:\tlearn: 0.0165098\ttest: 0.0167240\tbest: 0.0167240 (9970)\ttotal: 10m 29s\tremaining: 5m 17s\n",
            "9980:\tlearn: 0.0165094\ttest: 0.0167236\tbest: 0.0167236 (9980)\ttotal: 10m 30s\tremaining: 5m 17s\n",
            "9990:\tlearn: 0.0165090\ttest: 0.0167233\tbest: 0.0167233 (9990)\ttotal: 10m 31s\tremaining: 5m 16s\n",
            "10000:\tlearn: 0.0165086\ttest: 0.0167230\tbest: 0.0167230 (10000)\ttotal: 10m 31s\tremaining: 5m 15s\n",
            "10010:\tlearn: 0.0165082\ttest: 0.0167227\tbest: 0.0167227 (10010)\ttotal: 10m 32s\tremaining: 5m 15s\n",
            "10020:\tlearn: 0.0165077\ttest: 0.0167224\tbest: 0.0167224 (10020)\ttotal: 10m 33s\tremaining: 5m 14s\n",
            "10030:\tlearn: 0.0165073\ttest: 0.0167221\tbest: 0.0167221 (10030)\ttotal: 10m 34s\tremaining: 5m 14s\n",
            "10040:\tlearn: 0.0165069\ttest: 0.0167218\tbest: 0.0167218 (10040)\ttotal: 10m 34s\tremaining: 5m 13s\n",
            "10050:\tlearn: 0.0165065\ttest: 0.0167214\tbest: 0.0167214 (10050)\ttotal: 10m 35s\tremaining: 5m 13s\n",
            "10060:\tlearn: 0.0165061\ttest: 0.0167212\tbest: 0.0167212 (10060)\ttotal: 10m 36s\tremaining: 5m 12s\n",
            "10070:\tlearn: 0.0165057\ttest: 0.0167209\tbest: 0.0167209 (10070)\ttotal: 10m 37s\tremaining: 5m 11s\n",
            "10080:\tlearn: 0.0165053\ttest: 0.0167206\tbest: 0.0167206 (10080)\ttotal: 10m 37s\tremaining: 5m 11s\n",
            "10090:\tlearn: 0.0165049\ttest: 0.0167203\tbest: 0.0167203 (10090)\ttotal: 10m 38s\tremaining: 5m 10s\n",
            "10100:\tlearn: 0.0165045\ttest: 0.0167200\tbest: 0.0167200 (10100)\ttotal: 10m 39s\tremaining: 5m 10s\n",
            "10110:\tlearn: 0.0165041\ttest: 0.0167198\tbest: 0.0167198 (10110)\ttotal: 10m 40s\tremaining: 5m 9s\n",
            "10120:\tlearn: 0.0165038\ttest: 0.0167195\tbest: 0.0167195 (10120)\ttotal: 10m 40s\tremaining: 5m 8s\n",
            "10130:\tlearn: 0.0165034\ttest: 0.0167193\tbest: 0.0167193 (10130)\ttotal: 10m 41s\tremaining: 5m 8s\n",
            "10140:\tlearn: 0.0165030\ttest: 0.0167190\tbest: 0.0167190 (10140)\ttotal: 10m 42s\tremaining: 5m 7s\n",
            "10150:\tlearn: 0.0165027\ttest: 0.0167187\tbest: 0.0167187 (10150)\ttotal: 10m 42s\tremaining: 5m 7s\n",
            "10160:\tlearn: 0.0165023\ttest: 0.0167184\tbest: 0.0167184 (10160)\ttotal: 10m 43s\tremaining: 5m 6s\n",
            "10170:\tlearn: 0.0165018\ttest: 0.0167181\tbest: 0.0167181 (10170)\ttotal: 10m 44s\tremaining: 5m 5s\n",
            "10180:\tlearn: 0.0165015\ttest: 0.0167179\tbest: 0.0167179 (10180)\ttotal: 10m 44s\tremaining: 5m 5s\n",
            "10190:\tlearn: 0.0165011\ttest: 0.0167177\tbest: 0.0167177 (10190)\ttotal: 10m 45s\tremaining: 5m 4s\n",
            "10200:\tlearn: 0.0165008\ttest: 0.0167174\tbest: 0.0167174 (10200)\ttotal: 10m 46s\tremaining: 5m 4s\n",
            "10210:\tlearn: 0.0165004\ttest: 0.0167171\tbest: 0.0167171 (10210)\ttotal: 10m 47s\tremaining: 5m 3s\n",
            "10220:\tlearn: 0.0165000\ttest: 0.0167168\tbest: 0.0167168 (10220)\ttotal: 10m 47s\tremaining: 5m 2s\n",
            "10230:\tlearn: 0.0164996\ttest: 0.0167165\tbest: 0.0167165 (10230)\ttotal: 10m 48s\tremaining: 5m 2s\n",
            "10240:\tlearn: 0.0164992\ttest: 0.0167162\tbest: 0.0167162 (10240)\ttotal: 10m 49s\tremaining: 5m 1s\n",
            "10250:\tlearn: 0.0164988\ttest: 0.0167159\tbest: 0.0167159 (10250)\ttotal: 10m 49s\tremaining: 5m 1s\n",
            "10260:\tlearn: 0.0164984\ttest: 0.0167156\tbest: 0.0167156 (10260)\ttotal: 10m 50s\tremaining: 5m\n",
            "10270:\tlearn: 0.0164981\ttest: 0.0167154\tbest: 0.0167154 (10270)\ttotal: 10m 51s\tremaining: 4m 59s\n",
            "10280:\tlearn: 0.0164977\ttest: 0.0167151\tbest: 0.0167151 (10280)\ttotal: 10m 52s\tremaining: 4m 59s\n",
            "10290:\tlearn: 0.0164973\ttest: 0.0167148\tbest: 0.0167148 (10290)\ttotal: 10m 52s\tremaining: 4m 58s\n",
            "10300:\tlearn: 0.0164968\ttest: 0.0167145\tbest: 0.0167145 (10300)\ttotal: 10m 53s\tremaining: 4m 58s\n",
            "10310:\tlearn: 0.0164965\ttest: 0.0167142\tbest: 0.0167142 (10310)\ttotal: 10m 54s\tremaining: 4m 57s\n",
            "10320:\tlearn: 0.0164961\ttest: 0.0167139\tbest: 0.0167139 (10320)\ttotal: 10m 55s\tremaining: 4m 56s\n",
            "10330:\tlearn: 0.0164957\ttest: 0.0167136\tbest: 0.0167136 (10330)\ttotal: 10m 55s\tremaining: 4m 56s\n",
            "10340:\tlearn: 0.0164953\ttest: 0.0167133\tbest: 0.0167133 (10340)\ttotal: 10m 56s\tremaining: 4m 55s\n",
            "10350:\tlearn: 0.0164950\ttest: 0.0167131\tbest: 0.0167131 (10350)\ttotal: 10m 57s\tremaining: 4m 55s\n",
            "10360:\tlearn: 0.0164946\ttest: 0.0167128\tbest: 0.0167128 (10360)\ttotal: 10m 58s\tremaining: 4m 54s\n",
            "10370:\tlearn: 0.0164942\ttest: 0.0167125\tbest: 0.0167125 (10370)\ttotal: 10m 58s\tremaining: 4m 54s\n",
            "10380:\tlearn: 0.0164939\ttest: 0.0167123\tbest: 0.0167123 (10380)\ttotal: 10m 59s\tremaining: 4m 53s\n",
            "10390:\tlearn: 0.0164935\ttest: 0.0167121\tbest: 0.0167121 (10390)\ttotal: 11m\tremaining: 4m 52s\n",
            "10400:\tlearn: 0.0164931\ttest: 0.0167118\tbest: 0.0167118 (10400)\ttotal: 11m\tremaining: 4m 52s\n",
            "10410:\tlearn: 0.0164928\ttest: 0.0167115\tbest: 0.0167115 (10410)\ttotal: 11m 1s\tremaining: 4m 51s\n",
            "10420:\tlearn: 0.0164924\ttest: 0.0167113\tbest: 0.0167113 (10420)\ttotal: 11m 2s\tremaining: 4m 51s\n",
            "10430:\tlearn: 0.0164921\ttest: 0.0167110\tbest: 0.0167110 (10430)\ttotal: 11m 3s\tremaining: 4m 50s\n",
            "10440:\tlearn: 0.0164917\ttest: 0.0167108\tbest: 0.0167108 (10440)\ttotal: 11m 3s\tremaining: 4m 49s\n",
            "10450:\tlearn: 0.0164914\ttest: 0.0167106\tbest: 0.0167106 (10450)\ttotal: 11m 4s\tremaining: 4m 49s\n",
            "10460:\tlearn: 0.0164910\ttest: 0.0167103\tbest: 0.0167103 (10460)\ttotal: 11m 5s\tremaining: 4m 48s\n",
            "10470:\tlearn: 0.0164907\ttest: 0.0167100\tbest: 0.0167100 (10470)\ttotal: 11m 5s\tremaining: 4m 48s\n",
            "10480:\tlearn: 0.0164903\ttest: 0.0167097\tbest: 0.0167097 (10480)\ttotal: 11m 6s\tremaining: 4m 47s\n",
            "10490:\tlearn: 0.0164899\ttest: 0.0167095\tbest: 0.0167095 (10490)\ttotal: 11m 7s\tremaining: 4m 46s\n",
            "10500:\tlearn: 0.0164895\ttest: 0.0167092\tbest: 0.0167092 (10500)\ttotal: 11m 8s\tremaining: 4m 46s\n",
            "10510:\tlearn: 0.0164892\ttest: 0.0167090\tbest: 0.0167090 (10510)\ttotal: 11m 8s\tremaining: 4m 45s\n",
            "10520:\tlearn: 0.0164888\ttest: 0.0167087\tbest: 0.0167087 (10520)\ttotal: 11m 9s\tremaining: 4m 45s\n",
            "10530:\tlearn: 0.0164885\ttest: 0.0167084\tbest: 0.0167084 (10530)\ttotal: 11m 10s\tremaining: 4m 44s\n",
            "10540:\tlearn: 0.0164881\ttest: 0.0167082\tbest: 0.0167082 (10540)\ttotal: 11m 11s\tremaining: 4m 43s\n",
            "10550:\tlearn: 0.0164877\ttest: 0.0167079\tbest: 0.0167079 (10550)\ttotal: 11m 11s\tremaining: 4m 43s\n",
            "10560:\tlearn: 0.0164873\ttest: 0.0167077\tbest: 0.0167077 (10560)\ttotal: 11m 12s\tremaining: 4m 42s\n",
            "10570:\tlearn: 0.0164870\ttest: 0.0167074\tbest: 0.0167074 (10570)\ttotal: 11m 13s\tremaining: 4m 42s\n",
            "10580:\tlearn: 0.0164866\ttest: 0.0167071\tbest: 0.0167071 (10580)\ttotal: 11m 13s\tremaining: 4m 41s\n",
            "10590:\tlearn: 0.0164863\ttest: 0.0167068\tbest: 0.0167068 (10590)\ttotal: 11m 14s\tremaining: 4m 40s\n",
            "10600:\tlearn: 0.0164859\ttest: 0.0167066\tbest: 0.0167066 (10600)\ttotal: 11m 15s\tremaining: 4m 40s\n",
            "10610:\tlearn: 0.0164855\ttest: 0.0167063\tbest: 0.0167063 (10610)\ttotal: 11m 16s\tremaining: 4m 39s\n",
            "10620:\tlearn: 0.0164852\ttest: 0.0167061\tbest: 0.0167061 (10620)\ttotal: 11m 16s\tremaining: 4m 39s\n",
            "10630:\tlearn: 0.0164849\ttest: 0.0167059\tbest: 0.0167059 (10630)\ttotal: 11m 17s\tremaining: 4m 38s\n",
            "10640:\tlearn: 0.0164846\ttest: 0.0167057\tbest: 0.0167057 (10640)\ttotal: 11m 18s\tremaining: 4m 37s\n",
            "10650:\tlearn: 0.0164843\ttest: 0.0167054\tbest: 0.0167054 (10650)\ttotal: 11m 18s\tremaining: 4m 37s\n",
            "10660:\tlearn: 0.0164839\ttest: 0.0167052\tbest: 0.0167052 (10660)\ttotal: 11m 19s\tremaining: 4m 36s\n",
            "10670:\tlearn: 0.0164836\ttest: 0.0167049\tbest: 0.0167049 (10670)\ttotal: 11m 20s\tremaining: 4m 35s\n",
            "10680:\tlearn: 0.0164833\ttest: 0.0167047\tbest: 0.0167047 (10680)\ttotal: 11m 20s\tremaining: 4m 35s\n",
            "10690:\tlearn: 0.0164829\ttest: 0.0167045\tbest: 0.0167045 (10690)\ttotal: 11m 21s\tremaining: 4m 34s\n",
            "10700:\tlearn: 0.0164826\ttest: 0.0167042\tbest: 0.0167042 (10700)\ttotal: 11m 22s\tremaining: 4m 34s\n",
            "10710:\tlearn: 0.0164823\ttest: 0.0167040\tbest: 0.0167040 (10710)\ttotal: 11m 23s\tremaining: 4m 33s\n",
            "10720:\tlearn: 0.0164819\ttest: 0.0167038\tbest: 0.0167038 (10720)\ttotal: 11m 23s\tremaining: 4m 32s\n",
            "10730:\tlearn: 0.0164815\ttest: 0.0167035\tbest: 0.0167035 (10730)\ttotal: 11m 24s\tremaining: 4m 32s\n",
            "10740:\tlearn: 0.0164812\ttest: 0.0167033\tbest: 0.0167033 (10740)\ttotal: 11m 25s\tremaining: 4m 31s\n",
            "10750:\tlearn: 0.0164809\ttest: 0.0167031\tbest: 0.0167031 (10750)\ttotal: 11m 25s\tremaining: 4m 31s\n",
            "10760:\tlearn: 0.0164806\ttest: 0.0167028\tbest: 0.0167028 (10760)\ttotal: 11m 26s\tremaining: 4m 30s\n",
            "10770:\tlearn: 0.0164803\ttest: 0.0167026\tbest: 0.0167026 (10770)\ttotal: 11m 27s\tremaining: 4m 29s\n",
            "10780:\tlearn: 0.0164800\ttest: 0.0167024\tbest: 0.0167024 (10780)\ttotal: 11m 27s\tremaining: 4m 29s\n",
            "10790:\tlearn: 0.0164797\ttest: 0.0167022\tbest: 0.0167022 (10790)\ttotal: 11m 28s\tremaining: 4m 28s\n",
            "10800:\tlearn: 0.0164793\ttest: 0.0167019\tbest: 0.0167019 (10800)\ttotal: 11m 29s\tremaining: 4m 27s\n",
            "10810:\tlearn: 0.0164790\ttest: 0.0167017\tbest: 0.0167017 (10810)\ttotal: 11m 29s\tremaining: 4m 27s\n",
            "10820:\tlearn: 0.0164786\ttest: 0.0167015\tbest: 0.0167015 (10820)\ttotal: 11m 30s\tremaining: 4m 26s\n",
            "10830:\tlearn: 0.0164783\ttest: 0.0167012\tbest: 0.0167012 (10830)\ttotal: 11m 31s\tremaining: 4m 26s\n",
            "10840:\tlearn: 0.0164779\ttest: 0.0167010\tbest: 0.0167010 (10840)\ttotal: 11m 32s\tremaining: 4m 25s\n",
            "10850:\tlearn: 0.0164776\ttest: 0.0167008\tbest: 0.0167008 (10850)\ttotal: 11m 32s\tremaining: 4m 24s\n",
            "10860:\tlearn: 0.0164773\ttest: 0.0167005\tbest: 0.0167005 (10860)\ttotal: 11m 33s\tremaining: 4m 24s\n",
            "10870:\tlearn: 0.0164769\ttest: 0.0167003\tbest: 0.0167003 (10870)\ttotal: 11m 34s\tremaining: 4m 23s\n",
            "10880:\tlearn: 0.0164766\ttest: 0.0167001\tbest: 0.0167001 (10880)\ttotal: 11m 34s\tremaining: 4m 23s\n",
            "10890:\tlearn: 0.0164763\ttest: 0.0166999\tbest: 0.0166999 (10890)\ttotal: 11m 35s\tremaining: 4m 22s\n",
            "10900:\tlearn: 0.0164760\ttest: 0.0166996\tbest: 0.0166996 (10900)\ttotal: 11m 36s\tremaining: 4m 21s\n",
            "10910:\tlearn: 0.0164756\ttest: 0.0166994\tbest: 0.0166994 (10910)\ttotal: 11m 37s\tremaining: 4m 21s\n",
            "10920:\tlearn: 0.0164752\ttest: 0.0166991\tbest: 0.0166991 (10920)\ttotal: 11m 37s\tremaining: 4m 20s\n",
            "10930:\tlearn: 0.0164749\ttest: 0.0166989\tbest: 0.0166989 (10930)\ttotal: 11m 38s\tremaining: 4m 20s\n",
            "10940:\tlearn: 0.0164746\ttest: 0.0166987\tbest: 0.0166987 (10940)\ttotal: 11m 39s\tremaining: 4m 19s\n",
            "10950:\tlearn: 0.0164743\ttest: 0.0166985\tbest: 0.0166985 (10950)\ttotal: 11m 39s\tremaining: 4m 18s\n",
            "10960:\tlearn: 0.0164739\ttest: 0.0166982\tbest: 0.0166982 (10960)\ttotal: 11m 40s\tremaining: 4m 18s\n",
            "10970:\tlearn: 0.0164736\ttest: 0.0166980\tbest: 0.0166980 (10970)\ttotal: 11m 41s\tremaining: 4m 17s\n",
            "10980:\tlearn: 0.0164733\ttest: 0.0166978\tbest: 0.0166978 (10980)\ttotal: 11m 41s\tremaining: 4m 16s\n",
            "10990:\tlearn: 0.0164730\ttest: 0.0166976\tbest: 0.0166976 (10990)\ttotal: 11m 42s\tremaining: 4m 16s\n",
            "11000:\tlearn: 0.0164727\ttest: 0.0166974\tbest: 0.0166974 (11000)\ttotal: 11m 43s\tremaining: 4m 15s\n",
            "11010:\tlearn: 0.0164724\ttest: 0.0166972\tbest: 0.0166972 (11010)\ttotal: 11m 43s\tremaining: 4m 15s\n",
            "11020:\tlearn: 0.0164721\ttest: 0.0166969\tbest: 0.0166969 (11020)\ttotal: 11m 44s\tremaining: 4m 14s\n",
            "11030:\tlearn: 0.0164717\ttest: 0.0166967\tbest: 0.0166967 (11030)\ttotal: 11m 45s\tremaining: 4m 13s\n",
            "11040:\tlearn: 0.0164714\ttest: 0.0166965\tbest: 0.0166965 (11040)\ttotal: 11m 46s\tremaining: 4m 13s\n",
            "11050:\tlearn: 0.0164711\ttest: 0.0166962\tbest: 0.0166962 (11050)\ttotal: 11m 46s\tremaining: 4m 12s\n",
            "11060:\tlearn: 0.0164708\ttest: 0.0166960\tbest: 0.0166960 (11060)\ttotal: 11m 47s\tremaining: 4m 11s\n",
            "11070:\tlearn: 0.0164705\ttest: 0.0166958\tbest: 0.0166958 (11070)\ttotal: 11m 48s\tremaining: 4m 11s\n",
            "11080:\tlearn: 0.0164702\ttest: 0.0166956\tbest: 0.0166956 (11080)\ttotal: 11m 48s\tremaining: 4m 10s\n",
            "11090:\tlearn: 0.0164698\ttest: 0.0166953\tbest: 0.0166953 (11090)\ttotal: 11m 49s\tremaining: 4m 10s\n",
            "11100:\tlearn: 0.0164695\ttest: 0.0166951\tbest: 0.0166951 (11100)\ttotal: 11m 50s\tremaining: 4m 9s\n",
            "11110:\tlearn: 0.0164692\ttest: 0.0166949\tbest: 0.0166949 (11110)\ttotal: 11m 51s\tremaining: 4m 8s\n",
            "11120:\tlearn: 0.0164689\ttest: 0.0166946\tbest: 0.0166946 (11120)\ttotal: 11m 51s\tremaining: 4m 8s\n",
            "11130:\tlearn: 0.0164685\ttest: 0.0166944\tbest: 0.0166944 (11130)\ttotal: 11m 52s\tremaining: 4m 7s\n",
            "11140:\tlearn: 0.0164682\ttest: 0.0166942\tbest: 0.0166942 (11140)\ttotal: 11m 53s\tremaining: 4m 7s\n",
            "11150:\tlearn: 0.0164679\ttest: 0.0166940\tbest: 0.0166940 (11150)\ttotal: 11m 53s\tremaining: 4m 6s\n",
            "11160:\tlearn: 0.0164676\ttest: 0.0166938\tbest: 0.0166938 (11160)\ttotal: 11m 54s\tremaining: 4m 5s\n",
            "11170:\tlearn: 0.0164673\ttest: 0.0166936\tbest: 0.0166936 (11170)\ttotal: 11m 55s\tremaining: 4m 5s\n",
            "11180:\tlearn: 0.0164670\ttest: 0.0166934\tbest: 0.0166934 (11180)\ttotal: 11m 55s\tremaining: 4m 4s\n",
            "11190:\tlearn: 0.0164666\ttest: 0.0166931\tbest: 0.0166931 (11190)\ttotal: 11m 56s\tremaining: 4m 3s\n",
            "11200:\tlearn: 0.0164664\ttest: 0.0166930\tbest: 0.0166930 (11200)\ttotal: 11m 57s\tremaining: 4m 3s\n",
            "11210:\tlearn: 0.0164661\ttest: 0.0166928\tbest: 0.0166928 (11210)\ttotal: 11m 57s\tremaining: 4m 2s\n",
            "11220:\tlearn: 0.0164658\ttest: 0.0166926\tbest: 0.0166926 (11220)\ttotal: 11m 58s\tremaining: 4m 2s\n",
            "11230:\tlearn: 0.0164655\ttest: 0.0166924\tbest: 0.0166924 (11230)\ttotal: 11m 59s\tremaining: 4m 1s\n",
            "11240:\tlearn: 0.0164652\ttest: 0.0166921\tbest: 0.0166921 (11240)\ttotal: 12m\tremaining: 4m\n",
            "11250:\tlearn: 0.0164649\ttest: 0.0166919\tbest: 0.0166919 (11250)\ttotal: 12m\tremaining: 4m\n",
            "11260:\tlearn: 0.0164646\ttest: 0.0166917\tbest: 0.0166917 (11260)\ttotal: 12m 1s\tremaining: 3m 59s\n",
            "11270:\tlearn: 0.0164642\ttest: 0.0166914\tbest: 0.0166914 (11270)\ttotal: 12m 2s\tremaining: 3m 58s\n",
            "11280:\tlearn: 0.0164639\ttest: 0.0166912\tbest: 0.0166912 (11280)\ttotal: 12m 3s\tremaining: 3m 58s\n",
            "11290:\tlearn: 0.0164636\ttest: 0.0166910\tbest: 0.0166910 (11290)\ttotal: 12m 3s\tremaining: 3m 57s\n",
            "11300:\tlearn: 0.0164634\ttest: 0.0166909\tbest: 0.0166909 (11300)\ttotal: 12m 4s\tremaining: 3m 57s\n",
            "11310:\tlearn: 0.0164631\ttest: 0.0166906\tbest: 0.0166906 (11310)\ttotal: 12m 4s\tremaining: 3m 56s\n",
            "11320:\tlearn: 0.0164627\ttest: 0.0166904\tbest: 0.0166904 (11320)\ttotal: 12m 5s\tremaining: 3m 55s\n",
            "11330:\tlearn: 0.0164624\ttest: 0.0166902\tbest: 0.0166902 (11330)\ttotal: 12m 6s\tremaining: 3m 55s\n",
            "11340:\tlearn: 0.0164621\ttest: 0.0166900\tbest: 0.0166900 (11340)\ttotal: 12m 7s\tremaining: 3m 54s\n",
            "11350:\tlearn: 0.0164618\ttest: 0.0166897\tbest: 0.0166897 (11350)\ttotal: 12m 7s\tremaining: 3m 53s\n",
            "11360:\tlearn: 0.0164615\ttest: 0.0166895\tbest: 0.0166895 (11360)\ttotal: 12m 8s\tremaining: 3m 53s\n",
            "11370:\tlearn: 0.0164611\ttest: 0.0166893\tbest: 0.0166893 (11370)\ttotal: 12m 9s\tremaining: 3m 52s\n",
            "11380:\tlearn: 0.0164609\ttest: 0.0166891\tbest: 0.0166891 (11380)\ttotal: 12m 9s\tremaining: 3m 52s\n",
            "11390:\tlearn: 0.0164606\ttest: 0.0166889\tbest: 0.0166889 (11390)\ttotal: 12m 10s\tremaining: 3m 51s\n",
            "11400:\tlearn: 0.0164602\ttest: 0.0166887\tbest: 0.0166887 (11400)\ttotal: 12m 11s\tremaining: 3m 50s\n",
            "11410:\tlearn: 0.0164600\ttest: 0.0166885\tbest: 0.0166885 (11410)\ttotal: 12m 12s\tremaining: 3m 50s\n",
            "11420:\tlearn: 0.0164596\ttest: 0.0166883\tbest: 0.0166883 (11420)\ttotal: 12m 12s\tremaining: 3m 49s\n",
            "11430:\tlearn: 0.0164593\ttest: 0.0166881\tbest: 0.0166881 (11430)\ttotal: 12m 13s\tremaining: 3m 49s\n",
            "11440:\tlearn: 0.0164591\ttest: 0.0166879\tbest: 0.0166879 (11440)\ttotal: 12m 14s\tremaining: 3m 48s\n",
            "11450:\tlearn: 0.0164587\ttest: 0.0166877\tbest: 0.0166877 (11450)\ttotal: 12m 14s\tremaining: 3m 47s\n",
            "11460:\tlearn: 0.0164584\ttest: 0.0166875\tbest: 0.0166875 (11460)\ttotal: 12m 15s\tremaining: 3m 47s\n",
            "11470:\tlearn: 0.0164581\ttest: 0.0166874\tbest: 0.0166874 (11470)\ttotal: 12m 16s\tremaining: 3m 46s\n",
            "11480:\tlearn: 0.0164579\ttest: 0.0166872\tbest: 0.0166872 (11480)\ttotal: 12m 17s\tremaining: 3m 45s\n",
            "11490:\tlearn: 0.0164576\ttest: 0.0166870\tbest: 0.0166870 (11490)\ttotal: 12m 17s\tremaining: 3m 45s\n",
            "11500:\tlearn: 0.0164573\ttest: 0.0166868\tbest: 0.0166868 (11500)\ttotal: 12m 18s\tremaining: 3m 44s\n",
            "11510:\tlearn: 0.0164570\ttest: 0.0166867\tbest: 0.0166867 (11510)\ttotal: 12m 19s\tremaining: 3m 44s\n",
            "11520:\tlearn: 0.0164567\ttest: 0.0166864\tbest: 0.0166864 (11520)\ttotal: 12m 19s\tremaining: 3m 43s\n",
            "11530:\tlearn: 0.0164564\ttest: 0.0166862\tbest: 0.0166862 (11530)\ttotal: 12m 20s\tremaining: 3m 42s\n",
            "11540:\tlearn: 0.0164561\ttest: 0.0166860\tbest: 0.0166860 (11540)\ttotal: 12m 21s\tremaining: 3m 42s\n",
            "11550:\tlearn: 0.0164558\ttest: 0.0166858\tbest: 0.0166858 (11550)\ttotal: 12m 21s\tremaining: 3m 41s\n",
            "11560:\tlearn: 0.0164555\ttest: 0.0166856\tbest: 0.0166856 (11560)\ttotal: 12m 22s\tremaining: 3m 40s\n",
            "11570:\tlearn: 0.0164552\ttest: 0.0166854\tbest: 0.0166854 (11570)\ttotal: 12m 23s\tremaining: 3m 40s\n",
            "11580:\tlearn: 0.0164549\ttest: 0.0166852\tbest: 0.0166852 (11580)\ttotal: 12m 24s\tremaining: 3m 39s\n",
            "11590:\tlearn: 0.0164546\ttest: 0.0166850\tbest: 0.0166850 (11590)\ttotal: 12m 24s\tremaining: 3m 39s\n",
            "11600:\tlearn: 0.0164543\ttest: 0.0166848\tbest: 0.0166848 (11600)\ttotal: 12m 25s\tremaining: 3m 38s\n",
            "11610:\tlearn: 0.0164540\ttest: 0.0166846\tbest: 0.0166846 (11610)\ttotal: 12m 26s\tremaining: 3m 37s\n",
            "11620:\tlearn: 0.0164537\ttest: 0.0166844\tbest: 0.0166844 (11620)\ttotal: 12m 27s\tremaining: 3m 37s\n",
            "11630:\tlearn: 0.0164534\ttest: 0.0166842\tbest: 0.0166842 (11630)\ttotal: 12m 27s\tremaining: 3m 36s\n",
            "11640:\tlearn: 0.0164531\ttest: 0.0166840\tbest: 0.0166840 (11640)\ttotal: 12m 28s\tremaining: 3m 35s\n",
            "11650:\tlearn: 0.0164529\ttest: 0.0166838\tbest: 0.0166838 (11650)\ttotal: 12m 29s\tremaining: 3m 35s\n",
            "11660:\tlearn: 0.0164526\ttest: 0.0166837\tbest: 0.0166837 (11660)\ttotal: 12m 29s\tremaining: 3m 34s\n",
            "11670:\tlearn: 0.0164523\ttest: 0.0166835\tbest: 0.0166835 (11670)\ttotal: 12m 30s\tremaining: 3m 34s\n",
            "11680:\tlearn: 0.0164520\ttest: 0.0166833\tbest: 0.0166833 (11680)\ttotal: 12m 31s\tremaining: 3m 33s\n",
            "11690:\tlearn: 0.0164517\ttest: 0.0166831\tbest: 0.0166831 (11690)\ttotal: 12m 31s\tremaining: 3m 32s\n",
            "11700:\tlearn: 0.0164514\ttest: 0.0166829\tbest: 0.0166829 (11700)\ttotal: 12m 32s\tremaining: 3m 32s\n",
            "11710:\tlearn: 0.0164511\ttest: 0.0166827\tbest: 0.0166827 (11710)\ttotal: 12m 33s\tremaining: 3m 31s\n",
            "11720:\tlearn: 0.0164509\ttest: 0.0166825\tbest: 0.0166825 (11720)\ttotal: 12m 34s\tremaining: 3m 30s\n",
            "11730:\tlearn: 0.0164505\ttest: 0.0166823\tbest: 0.0166823 (11730)\ttotal: 12m 34s\tremaining: 3m 30s\n",
            "11740:\tlearn: 0.0164502\ttest: 0.0166821\tbest: 0.0166821 (11740)\ttotal: 12m 35s\tremaining: 3m 29s\n",
            "11750:\tlearn: 0.0164499\ttest: 0.0166819\tbest: 0.0166819 (11750)\ttotal: 12m 36s\tremaining: 3m 29s\n",
            "11760:\tlearn: 0.0164496\ttest: 0.0166817\tbest: 0.0166817 (11760)\ttotal: 12m 37s\tremaining: 3m 28s\n",
            "11770:\tlearn: 0.0164493\ttest: 0.0166815\tbest: 0.0166815 (11770)\ttotal: 12m 37s\tremaining: 3m 27s\n",
            "11780:\tlearn: 0.0164490\ttest: 0.0166814\tbest: 0.0166814 (11780)\ttotal: 12m 38s\tremaining: 3m 27s\n",
            "11790:\tlearn: 0.0164487\ttest: 0.0166812\tbest: 0.0166812 (11790)\ttotal: 12m 39s\tremaining: 3m 26s\n",
            "11800:\tlearn: 0.0164485\ttest: 0.0166810\tbest: 0.0166810 (11800)\ttotal: 12m 39s\tremaining: 3m 26s\n",
            "11810:\tlearn: 0.0164482\ttest: 0.0166808\tbest: 0.0166808 (11810)\ttotal: 12m 40s\tremaining: 3m 25s\n",
            "11820:\tlearn: 0.0164479\ttest: 0.0166807\tbest: 0.0166807 (11820)\ttotal: 12m 41s\tremaining: 3m 24s\n",
            "11830:\tlearn: 0.0164476\ttest: 0.0166805\tbest: 0.0166805 (11830)\ttotal: 12m 42s\tremaining: 3m 24s\n",
            "11840:\tlearn: 0.0164473\ttest: 0.0166803\tbest: 0.0166803 (11840)\ttotal: 12m 42s\tremaining: 3m 23s\n",
            "11850:\tlearn: 0.0164470\ttest: 0.0166801\tbest: 0.0166801 (11850)\ttotal: 12m 43s\tremaining: 3m 22s\n",
            "11860:\tlearn: 0.0164467\ttest: 0.0166799\tbest: 0.0166799 (11860)\ttotal: 12m 44s\tremaining: 3m 22s\n",
            "11870:\tlearn: 0.0164465\ttest: 0.0166797\tbest: 0.0166797 (11870)\ttotal: 12m 45s\tremaining: 3m 21s\n",
            "11880:\tlearn: 0.0164462\ttest: 0.0166795\tbest: 0.0166795 (11880)\ttotal: 12m 45s\tremaining: 3m 21s\n",
            "11890:\tlearn: 0.0164459\ttest: 0.0166794\tbest: 0.0166794 (11890)\ttotal: 12m 46s\tremaining: 3m 20s\n",
            "11900:\tlearn: 0.0164456\ttest: 0.0166791\tbest: 0.0166791 (11900)\ttotal: 12m 47s\tremaining: 3m 19s\n",
            "11910:\tlearn: 0.0164453\ttest: 0.0166790\tbest: 0.0166790 (11910)\ttotal: 12m 47s\tremaining: 3m 19s\n",
            "11920:\tlearn: 0.0164450\ttest: 0.0166788\tbest: 0.0166788 (11920)\ttotal: 12m 48s\tremaining: 3m 18s\n",
            "11930:\tlearn: 0.0164448\ttest: 0.0166786\tbest: 0.0166786 (11930)\ttotal: 12m 49s\tremaining: 3m 17s\n",
            "11940:\tlearn: 0.0164445\ttest: 0.0166784\tbest: 0.0166784 (11940)\ttotal: 12m 49s\tremaining: 3m 17s\n",
            "11950:\tlearn: 0.0164442\ttest: 0.0166783\tbest: 0.0166783 (11950)\ttotal: 12m 50s\tremaining: 3m 16s\n",
            "11960:\tlearn: 0.0164439\ttest: 0.0166781\tbest: 0.0166781 (11960)\ttotal: 12m 51s\tremaining: 3m 16s\n",
            "11970:\tlearn: 0.0164436\ttest: 0.0166779\tbest: 0.0166779 (11970)\ttotal: 12m 52s\tremaining: 3m 15s\n",
            "11980:\tlearn: 0.0164433\ttest: 0.0166777\tbest: 0.0166777 (11980)\ttotal: 12m 52s\tremaining: 3m 14s\n",
            "11990:\tlearn: 0.0164430\ttest: 0.0166775\tbest: 0.0166775 (11990)\ttotal: 12m 53s\tremaining: 3m 14s\n",
            "12000:\tlearn: 0.0164427\ttest: 0.0166773\tbest: 0.0166773 (12000)\ttotal: 12m 54s\tremaining: 3m 13s\n",
            "12010:\tlearn: 0.0164425\ttest: 0.0166771\tbest: 0.0166771 (12010)\ttotal: 12m 55s\tremaining: 3m 12s\n",
            "12020:\tlearn: 0.0164421\ttest: 0.0166769\tbest: 0.0166769 (12020)\ttotal: 12m 55s\tremaining: 3m 12s\n",
            "12030:\tlearn: 0.0164418\ttest: 0.0166768\tbest: 0.0166768 (12030)\ttotal: 12m 56s\tremaining: 3m 11s\n",
            "12040:\tlearn: 0.0164416\ttest: 0.0166766\tbest: 0.0166766 (12040)\ttotal: 12m 57s\tremaining: 3m 11s\n",
            "12050:\tlearn: 0.0164413\ttest: 0.0166764\tbest: 0.0166764 (12050)\ttotal: 12m 57s\tremaining: 3m 10s\n",
            "12060:\tlearn: 0.0164410\ttest: 0.0166762\tbest: 0.0166762 (12060)\ttotal: 12m 58s\tremaining: 3m 9s\n",
            "12070:\tlearn: 0.0164408\ttest: 0.0166761\tbest: 0.0166761 (12070)\ttotal: 12m 59s\tremaining: 3m 9s\n",
            "12080:\tlearn: 0.0164405\ttest: 0.0166759\tbest: 0.0166759 (12080)\ttotal: 12m 59s\tremaining: 3m 8s\n",
            "12090:\tlearn: 0.0164402\ttest: 0.0166757\tbest: 0.0166757 (12090)\ttotal: 13m\tremaining: 3m 7s\n",
            "12100:\tlearn: 0.0164399\ttest: 0.0166755\tbest: 0.0166755 (12100)\ttotal: 13m 1s\tremaining: 3m 7s\n",
            "12110:\tlearn: 0.0164397\ttest: 0.0166754\tbest: 0.0166754 (12110)\ttotal: 13m 2s\tremaining: 3m 6s\n",
            "12120:\tlearn: 0.0164394\ttest: 0.0166752\tbest: 0.0166752 (12120)\ttotal: 13m 2s\tremaining: 3m 5s\n",
            "12130:\tlearn: 0.0164391\ttest: 0.0166750\tbest: 0.0166750 (12130)\ttotal: 13m 3s\tremaining: 3m 5s\n",
            "12140:\tlearn: 0.0164389\ttest: 0.0166749\tbest: 0.0166749 (12140)\ttotal: 13m 4s\tremaining: 3m 4s\n",
            "12150:\tlearn: 0.0164386\ttest: 0.0166747\tbest: 0.0166747 (12150)\ttotal: 13m 4s\tremaining: 3m 4s\n",
            "12160:\tlearn: 0.0164384\ttest: 0.0166746\tbest: 0.0166746 (12160)\ttotal: 13m 5s\tremaining: 3m 3s\n",
            "12170:\tlearn: 0.0164381\ttest: 0.0166744\tbest: 0.0166744 (12170)\ttotal: 13m 6s\tremaining: 3m 2s\n",
            "12180:\tlearn: 0.0164378\ttest: 0.0166742\tbest: 0.0166742 (12180)\ttotal: 13m 6s\tremaining: 3m 2s\n",
            "12190:\tlearn: 0.0164375\ttest: 0.0166740\tbest: 0.0166740 (12190)\ttotal: 13m 7s\tremaining: 3m 1s\n",
            "12200:\tlearn: 0.0164373\ttest: 0.0166738\tbest: 0.0166738 (12200)\ttotal: 13m 8s\tremaining: 3m\n",
            "12210:\tlearn: 0.0164370\ttest: 0.0166737\tbest: 0.0166737 (12210)\ttotal: 13m 9s\tremaining: 3m\n",
            "12220:\tlearn: 0.0164368\ttest: 0.0166735\tbest: 0.0166735 (12220)\ttotal: 13m 9s\tremaining: 2m 59s\n",
            "12230:\tlearn: 0.0164365\ttest: 0.0166733\tbest: 0.0166733 (12230)\ttotal: 13m 10s\tremaining: 2m 59s\n",
            "12240:\tlearn: 0.0164362\ttest: 0.0166732\tbest: 0.0166732 (12240)\ttotal: 13m 11s\tremaining: 2m 58s\n",
            "12250:\tlearn: 0.0164360\ttest: 0.0166730\tbest: 0.0166730 (12250)\ttotal: 13m 12s\tremaining: 2m 57s\n",
            "12260:\tlearn: 0.0164356\ttest: 0.0166728\tbest: 0.0166728 (12260)\ttotal: 13m 12s\tremaining: 2m 57s\n",
            "12270:\tlearn: 0.0164354\ttest: 0.0166726\tbest: 0.0166726 (12270)\ttotal: 13m 13s\tremaining: 2m 56s\n",
            "12280:\tlearn: 0.0164351\ttest: 0.0166724\tbest: 0.0166724 (12280)\ttotal: 13m 14s\tremaining: 2m 55s\n",
            "12290:\tlearn: 0.0164348\ttest: 0.0166722\tbest: 0.0166722 (12290)\ttotal: 13m 15s\tremaining: 2m 55s\n",
            "12300:\tlearn: 0.0164346\ttest: 0.0166721\tbest: 0.0166721 (12300)\ttotal: 13m 15s\tremaining: 2m 54s\n",
            "12310:\tlearn: 0.0164343\ttest: 0.0166719\tbest: 0.0166719 (12310)\ttotal: 13m 16s\tremaining: 2m 53s\n",
            "12320:\tlearn: 0.0164340\ttest: 0.0166717\tbest: 0.0166717 (12320)\ttotal: 13m 17s\tremaining: 2m 53s\n",
            "12330:\tlearn: 0.0164338\ttest: 0.0166716\tbest: 0.0166716 (12330)\ttotal: 13m 17s\tremaining: 2m 52s\n",
            "12340:\tlearn: 0.0164335\ttest: 0.0166714\tbest: 0.0166714 (12340)\ttotal: 13m 18s\tremaining: 2m 52s\n",
            "12350:\tlearn: 0.0164332\ttest: 0.0166713\tbest: 0.0166713 (12350)\ttotal: 13m 19s\tremaining: 2m 51s\n",
            "12360:\tlearn: 0.0164330\ttest: 0.0166711\tbest: 0.0166711 (12360)\ttotal: 13m 20s\tremaining: 2m 50s\n",
            "12370:\tlearn: 0.0164327\ttest: 0.0166709\tbest: 0.0166709 (12370)\ttotal: 13m 20s\tremaining: 2m 50s\n",
            "12380:\tlearn: 0.0164324\ttest: 0.0166707\tbest: 0.0166707 (12380)\ttotal: 13m 21s\tremaining: 2m 49s\n",
            "12390:\tlearn: 0.0164321\ttest: 0.0166706\tbest: 0.0166706 (12390)\ttotal: 13m 22s\tremaining: 2m 48s\n",
            "12400:\tlearn: 0.0164319\ttest: 0.0166704\tbest: 0.0166704 (12400)\ttotal: 13m 22s\tremaining: 2m 48s\n",
            "12410:\tlearn: 0.0164316\ttest: 0.0166702\tbest: 0.0166702 (12410)\ttotal: 13m 23s\tremaining: 2m 47s\n",
            "12420:\tlearn: 0.0164313\ttest: 0.0166700\tbest: 0.0166700 (12420)\ttotal: 13m 24s\tremaining: 2m 47s\n",
            "12430:\tlearn: 0.0164310\ttest: 0.0166699\tbest: 0.0166699 (12430)\ttotal: 13m 25s\tremaining: 2m 46s\n",
            "12440:\tlearn: 0.0164308\ttest: 0.0166697\tbest: 0.0166697 (12440)\ttotal: 13m 25s\tremaining: 2m 45s\n",
            "12450:\tlearn: 0.0164305\ttest: 0.0166695\tbest: 0.0166695 (12450)\ttotal: 13m 26s\tremaining: 2m 45s\n",
            "12460:\tlearn: 0.0164302\ttest: 0.0166694\tbest: 0.0166694 (12460)\ttotal: 13m 27s\tremaining: 2m 44s\n",
            "12470:\tlearn: 0.0164300\ttest: 0.0166692\tbest: 0.0166692 (12470)\ttotal: 13m 28s\tremaining: 2m 43s\n",
            "12480:\tlearn: 0.0164297\ttest: 0.0166691\tbest: 0.0166691 (12480)\ttotal: 13m 28s\tremaining: 2m 43s\n",
            "12490:\tlearn: 0.0164295\ttest: 0.0166689\tbest: 0.0166689 (12490)\ttotal: 13m 29s\tremaining: 2m 42s\n",
            "12500:\tlearn: 0.0164292\ttest: 0.0166688\tbest: 0.0166688 (12500)\ttotal: 13m 30s\tremaining: 2m 41s\n",
            "12510:\tlearn: 0.0164290\ttest: 0.0166686\tbest: 0.0166686 (12510)\ttotal: 13m 30s\tremaining: 2m 41s\n",
            "12520:\tlearn: 0.0164287\ttest: 0.0166685\tbest: 0.0166685 (12520)\ttotal: 13m 31s\tremaining: 2m 40s\n",
            "12530:\tlearn: 0.0164284\ttest: 0.0166683\tbest: 0.0166683 (12530)\ttotal: 13m 32s\tremaining: 2m 40s\n",
            "12540:\tlearn: 0.0164282\ttest: 0.0166681\tbest: 0.0166681 (12540)\ttotal: 13m 32s\tremaining: 2m 39s\n",
            "12550:\tlearn: 0.0164279\ttest: 0.0166680\tbest: 0.0166680 (12550)\ttotal: 13m 33s\tremaining: 2m 38s\n",
            "12560:\tlearn: 0.0164276\ttest: 0.0166678\tbest: 0.0166678 (12560)\ttotal: 13m 34s\tremaining: 2m 38s\n",
            "12570:\tlearn: 0.0164273\ttest: 0.0166676\tbest: 0.0166676 (12570)\ttotal: 13m 35s\tremaining: 2m 37s\n",
            "12580:\tlearn: 0.0164271\ttest: 0.0166674\tbest: 0.0166674 (12580)\ttotal: 13m 36s\tremaining: 2m 36s\n",
            "12590:\tlearn: 0.0164268\ttest: 0.0166673\tbest: 0.0166673 (12590)\ttotal: 13m 36s\tremaining: 2m 36s\n",
            "12600:\tlearn: 0.0164266\ttest: 0.0166671\tbest: 0.0166671 (12600)\ttotal: 13m 37s\tremaining: 2m 35s\n",
            "12610:\tlearn: 0.0164263\ttest: 0.0166670\tbest: 0.0166670 (12610)\ttotal: 13m 38s\tremaining: 2m 34s\n",
            "12620:\tlearn: 0.0164260\ttest: 0.0166668\tbest: 0.0166668 (12620)\ttotal: 13m 38s\tremaining: 2m 34s\n",
            "12630:\tlearn: 0.0164258\ttest: 0.0166666\tbest: 0.0166666 (12630)\ttotal: 13m 39s\tremaining: 2m 33s\n",
            "12640:\tlearn: 0.0164255\ttest: 0.0166665\tbest: 0.0166665 (12640)\ttotal: 13m 40s\tremaining: 2m 33s\n",
            "12650:\tlearn: 0.0164253\ttest: 0.0166663\tbest: 0.0166663 (12650)\ttotal: 13m 40s\tremaining: 2m 32s\n",
            "12660:\tlearn: 0.0164250\ttest: 0.0166662\tbest: 0.0166662 (12660)\ttotal: 13m 41s\tremaining: 2m 31s\n",
            "12670:\tlearn: 0.0164247\ttest: 0.0166660\tbest: 0.0166660 (12670)\ttotal: 13m 42s\tremaining: 2m 31s\n",
            "12680:\tlearn: 0.0164245\ttest: 0.0166659\tbest: 0.0166659 (12680)\ttotal: 13m 43s\tremaining: 2m 30s\n",
            "12690:\tlearn: 0.0164243\ttest: 0.0166657\tbest: 0.0166657 (12690)\ttotal: 13m 43s\tremaining: 2m 29s\n",
            "12700:\tlearn: 0.0164240\ttest: 0.0166656\tbest: 0.0166656 (12700)\ttotal: 13m 44s\tremaining: 2m 29s\n",
            "12710:\tlearn: 0.0164237\ttest: 0.0166654\tbest: 0.0166654 (12710)\ttotal: 13m 45s\tremaining: 2m 28s\n",
            "12720:\tlearn: 0.0164235\ttest: 0.0166653\tbest: 0.0166653 (12720)\ttotal: 13m 45s\tremaining: 2m 27s\n",
            "12730:\tlearn: 0.0164233\ttest: 0.0166651\tbest: 0.0166651 (12730)\ttotal: 13m 46s\tremaining: 2m 27s\n",
            "12740:\tlearn: 0.0164230\ttest: 0.0166649\tbest: 0.0166649 (12740)\ttotal: 13m 47s\tremaining: 2m 26s\n",
            "12750:\tlearn: 0.0164227\ttest: 0.0166648\tbest: 0.0166648 (12750)\ttotal: 13m 48s\tremaining: 2m 26s\n",
            "12760:\tlearn: 0.0164224\ttest: 0.0166646\tbest: 0.0166646 (12760)\ttotal: 13m 48s\tremaining: 2m 25s\n",
            "12770:\tlearn: 0.0164221\ttest: 0.0166644\tbest: 0.0166644 (12770)\ttotal: 13m 49s\tremaining: 2m 24s\n",
            "12780:\tlearn: 0.0164219\ttest: 0.0166643\tbest: 0.0166643 (12780)\ttotal: 13m 50s\tremaining: 2m 24s\n",
            "12790:\tlearn: 0.0164216\ttest: 0.0166641\tbest: 0.0166641 (12790)\ttotal: 13m 51s\tremaining: 2m 23s\n",
            "12800:\tlearn: 0.0164214\ttest: 0.0166640\tbest: 0.0166640 (12800)\ttotal: 13m 51s\tremaining: 2m 22s\n",
            "12810:\tlearn: 0.0164212\ttest: 0.0166639\tbest: 0.0166639 (12810)\ttotal: 13m 52s\tremaining: 2m 22s\n",
            "12820:\tlearn: 0.0164209\ttest: 0.0166637\tbest: 0.0166637 (12820)\ttotal: 13m 53s\tremaining: 2m 21s\n",
            "12830:\tlearn: 0.0164207\ttest: 0.0166636\tbest: 0.0166636 (12830)\ttotal: 13m 53s\tremaining: 2m 20s\n",
            "12840:\tlearn: 0.0164205\ttest: 0.0166634\tbest: 0.0166634 (12840)\ttotal: 13m 54s\tremaining: 2m 20s\n",
            "12850:\tlearn: 0.0164202\ttest: 0.0166632\tbest: 0.0166632 (12850)\ttotal: 13m 55s\tremaining: 2m 19s\n",
            "12860:\tlearn: 0.0164199\ttest: 0.0166631\tbest: 0.0166631 (12860)\ttotal: 13m 55s\tremaining: 2m 19s\n",
            "12870:\tlearn: 0.0164197\ttest: 0.0166629\tbest: 0.0166629 (12870)\ttotal: 13m 56s\tremaining: 2m 18s\n",
            "12880:\tlearn: 0.0164194\ttest: 0.0166627\tbest: 0.0166627 (12880)\ttotal: 13m 57s\tremaining: 2m 17s\n",
            "12890:\tlearn: 0.0164192\ttest: 0.0166626\tbest: 0.0166626 (12890)\ttotal: 13m 58s\tremaining: 2m 17s\n",
            "12900:\tlearn: 0.0164189\ttest: 0.0166625\tbest: 0.0166625 (12900)\ttotal: 13m 58s\tremaining: 2m 16s\n",
            "12910:\tlearn: 0.0164187\ttest: 0.0166623\tbest: 0.0166623 (12910)\ttotal: 13m 59s\tremaining: 2m 15s\n",
            "12920:\tlearn: 0.0164184\ttest: 0.0166622\tbest: 0.0166622 (12920)\ttotal: 14m\tremaining: 2m 15s\n",
            "12930:\tlearn: 0.0164182\ttest: 0.0166620\tbest: 0.0166620 (12930)\ttotal: 14m\tremaining: 2m 14s\n",
            "12940:\tlearn: 0.0164180\ttest: 0.0166619\tbest: 0.0166619 (12940)\ttotal: 14m 1s\tremaining: 2m 13s\n",
            "12950:\tlearn: 0.0164177\ttest: 0.0166617\tbest: 0.0166617 (12950)\ttotal: 14m 2s\tremaining: 2m 13s\n",
            "12960:\tlearn: 0.0164174\ttest: 0.0166615\tbest: 0.0166615 (12960)\ttotal: 14m 3s\tremaining: 2m 12s\n",
            "12970:\tlearn: 0.0164172\ttest: 0.0166614\tbest: 0.0166614 (12970)\ttotal: 14m 3s\tremaining: 2m 11s\n",
            "12980:\tlearn: 0.0164170\ttest: 0.0166613\tbest: 0.0166613 (12980)\ttotal: 14m 4s\tremaining: 2m 11s\n",
            "12990:\tlearn: 0.0164167\ttest: 0.0166611\tbest: 0.0166611 (12990)\ttotal: 14m 5s\tremaining: 2m 10s\n",
            "13000:\tlearn: 0.0164165\ttest: 0.0166609\tbest: 0.0166609 (13000)\ttotal: 14m 5s\tremaining: 2m 10s\n",
            "13010:\tlearn: 0.0164162\ttest: 0.0166608\tbest: 0.0166608 (13010)\ttotal: 14m 6s\tremaining: 2m 9s\n",
            "13020:\tlearn: 0.0164160\ttest: 0.0166606\tbest: 0.0166606 (13020)\ttotal: 14m 7s\tremaining: 2m 8s\n",
            "13030:\tlearn: 0.0164157\ttest: 0.0166605\tbest: 0.0166605 (13030)\ttotal: 14m 8s\tremaining: 2m 8s\n",
            "13040:\tlearn: 0.0164155\ttest: 0.0166603\tbest: 0.0166603 (13040)\ttotal: 14m 8s\tremaining: 2m 7s\n",
            "13050:\tlearn: 0.0164152\ttest: 0.0166602\tbest: 0.0166602 (13050)\ttotal: 14m 9s\tremaining: 2m 6s\n",
            "13060:\tlearn: 0.0164150\ttest: 0.0166600\tbest: 0.0166600 (13060)\ttotal: 14m 10s\tremaining: 2m 6s\n",
            "13070:\tlearn: 0.0164148\ttest: 0.0166599\tbest: 0.0166599 (13070)\ttotal: 14m 10s\tremaining: 2m 5s\n",
            "13080:\tlearn: 0.0164145\ttest: 0.0166598\tbest: 0.0166598 (13080)\ttotal: 14m 11s\tremaining: 2m 4s\n",
            "13090:\tlearn: 0.0164143\ttest: 0.0166596\tbest: 0.0166596 (13090)\ttotal: 14m 12s\tremaining: 2m 4s\n",
            "13100:\tlearn: 0.0164141\ttest: 0.0166595\tbest: 0.0166595 (13100)\ttotal: 14m 12s\tremaining: 2m 3s\n",
            "13110:\tlearn: 0.0164138\ttest: 0.0166593\tbest: 0.0166593 (13110)\ttotal: 14m 13s\tremaining: 2m 2s\n",
            "13120:\tlearn: 0.0164136\ttest: 0.0166592\tbest: 0.0166592 (13120)\ttotal: 14m 14s\tremaining: 2m 2s\n",
            "13130:\tlearn: 0.0164133\ttest: 0.0166590\tbest: 0.0166590 (13130)\ttotal: 14m 15s\tremaining: 2m 1s\n",
            "13140:\tlearn: 0.0164131\ttest: 0.0166589\tbest: 0.0166589 (13140)\ttotal: 14m 15s\tremaining: 2m 1s\n",
            "13150:\tlearn: 0.0164128\ttest: 0.0166587\tbest: 0.0166587 (13150)\ttotal: 14m 16s\tremaining: 2m\n",
            "13160:\tlearn: 0.0164126\ttest: 0.0166586\tbest: 0.0166586 (13160)\ttotal: 14m 17s\tremaining: 1m 59s\n",
            "13170:\tlearn: 0.0164124\ttest: 0.0166584\tbest: 0.0166584 (13170)\ttotal: 14m 17s\tremaining: 1m 59s\n",
            "13180:\tlearn: 0.0164121\ttest: 0.0166583\tbest: 0.0166583 (13180)\ttotal: 14m 18s\tremaining: 1m 58s\n",
            "13190:\tlearn: 0.0164119\ttest: 0.0166582\tbest: 0.0166582 (13190)\ttotal: 14m 19s\tremaining: 1m 57s\n",
            "13200:\tlearn: 0.0164116\ttest: 0.0166580\tbest: 0.0166580 (13200)\ttotal: 14m 20s\tremaining: 1m 57s\n",
            "13210:\tlearn: 0.0164114\ttest: 0.0166579\tbest: 0.0166579 (13210)\ttotal: 14m 20s\tremaining: 1m 56s\n",
            "13220:\tlearn: 0.0164112\ttest: 0.0166578\tbest: 0.0166578 (13220)\ttotal: 14m 21s\tremaining: 1m 55s\n",
            "13230:\tlearn: 0.0164109\ttest: 0.0166576\tbest: 0.0166576 (13230)\ttotal: 14m 22s\tremaining: 1m 55s\n",
            "13240:\tlearn: 0.0164107\ttest: 0.0166575\tbest: 0.0166575 (13240)\ttotal: 14m 22s\tremaining: 1m 54s\n",
            "13250:\tlearn: 0.0164105\ttest: 0.0166573\tbest: 0.0166573 (13250)\ttotal: 14m 23s\tremaining: 1m 53s\n",
            "13260:\tlearn: 0.0164102\ttest: 0.0166572\tbest: 0.0166572 (13260)\ttotal: 14m 24s\tremaining: 1m 53s\n",
            "13270:\tlearn: 0.0164100\ttest: 0.0166571\tbest: 0.0166571 (13270)\ttotal: 14m 24s\tremaining: 1m 52s\n",
            "13280:\tlearn: 0.0164098\ttest: 0.0166570\tbest: 0.0166570 (13280)\ttotal: 14m 25s\tremaining: 1m 52s\n",
            "13290:\tlearn: 0.0164095\ttest: 0.0166568\tbest: 0.0166568 (13290)\ttotal: 14m 26s\tremaining: 1m 51s\n",
            "13300:\tlearn: 0.0164093\ttest: 0.0166567\tbest: 0.0166567 (13300)\ttotal: 14m 27s\tremaining: 1m 50s\n",
            "13310:\tlearn: 0.0164090\ttest: 0.0166565\tbest: 0.0166565 (13310)\ttotal: 14m 27s\tremaining: 1m 50s\n",
            "13320:\tlearn: 0.0164088\ttest: 0.0166564\tbest: 0.0166564 (13320)\ttotal: 14m 28s\tremaining: 1m 49s\n",
            "13330:\tlearn: 0.0164086\ttest: 0.0166563\tbest: 0.0166563 (13330)\ttotal: 14m 29s\tremaining: 1m 48s\n",
            "13340:\tlearn: 0.0164083\ttest: 0.0166561\tbest: 0.0166561 (13340)\ttotal: 14m 30s\tremaining: 1m 48s\n",
            "13350:\tlearn: 0.0164081\ttest: 0.0166560\tbest: 0.0166560 (13350)\ttotal: 14m 30s\tremaining: 1m 47s\n",
            "13360:\tlearn: 0.0164079\ttest: 0.0166558\tbest: 0.0166558 (13360)\ttotal: 14m 31s\tremaining: 1m 46s\n",
            "13370:\tlearn: 0.0164076\ttest: 0.0166557\tbest: 0.0166557 (13370)\ttotal: 14m 32s\tremaining: 1m 46s\n",
            "13380:\tlearn: 0.0164074\ttest: 0.0166555\tbest: 0.0166555 (13380)\ttotal: 14m 32s\tremaining: 1m 45s\n",
            "13390:\tlearn: 0.0164071\ttest: 0.0166554\tbest: 0.0166554 (13390)\ttotal: 14m 33s\tremaining: 1m 44s\n",
            "13400:\tlearn: 0.0164070\ttest: 0.0166553\tbest: 0.0166553 (13400)\ttotal: 14m 34s\tremaining: 1m 44s\n",
            "13410:\tlearn: 0.0164067\ttest: 0.0166552\tbest: 0.0166552 (13410)\ttotal: 14m 34s\tremaining: 1m 43s\n",
            "13420:\tlearn: 0.0164065\ttest: 0.0166550\tbest: 0.0166550 (13420)\ttotal: 14m 35s\tremaining: 1m 43s\n",
            "13430:\tlearn: 0.0164062\ttest: 0.0166549\tbest: 0.0166549 (13430)\ttotal: 14m 36s\tremaining: 1m 42s\n",
            "13440:\tlearn: 0.0164060\ttest: 0.0166547\tbest: 0.0166547 (13440)\ttotal: 14m 37s\tremaining: 1m 41s\n",
            "13450:\tlearn: 0.0164058\ttest: 0.0166546\tbest: 0.0166546 (13450)\ttotal: 14m 37s\tremaining: 1m 41s\n",
            "13460:\tlearn: 0.0164055\ttest: 0.0166545\tbest: 0.0166545 (13460)\ttotal: 14m 38s\tremaining: 1m 40s\n",
            "13470:\tlearn: 0.0164054\ttest: 0.0166543\tbest: 0.0166543 (13470)\ttotal: 14m 39s\tremaining: 1m 39s\n",
            "13480:\tlearn: 0.0164051\ttest: 0.0166542\tbest: 0.0166542 (13480)\ttotal: 14m 39s\tremaining: 1m 39s\n",
            "13490:\tlearn: 0.0164049\ttest: 0.0166541\tbest: 0.0166541 (13490)\ttotal: 14m 40s\tremaining: 1m 38s\n",
            "13500:\tlearn: 0.0164047\ttest: 0.0166539\tbest: 0.0166539 (13500)\ttotal: 14m 41s\tremaining: 1m 37s\n",
            "13510:\tlearn: 0.0164044\ttest: 0.0166538\tbest: 0.0166538 (13510)\ttotal: 14m 41s\tremaining: 1m 37s\n",
            "13520:\tlearn: 0.0164042\ttest: 0.0166536\tbest: 0.0166536 (13520)\ttotal: 14m 42s\tremaining: 1m 36s\n",
            "13530:\tlearn: 0.0164039\ttest: 0.0166534\tbest: 0.0166534 (13530)\ttotal: 14m 43s\tremaining: 1m 35s\n",
            "13540:\tlearn: 0.0164037\ttest: 0.0166533\tbest: 0.0166533 (13540)\ttotal: 14m 44s\tremaining: 1m 35s\n",
            "13550:\tlearn: 0.0164034\ttest: 0.0166532\tbest: 0.0166532 (13550)\ttotal: 14m 44s\tremaining: 1m 34s\n",
            "13560:\tlearn: 0.0164032\ttest: 0.0166530\tbest: 0.0166530 (13560)\ttotal: 14m 45s\tremaining: 1m 33s\n",
            "13570:\tlearn: 0.0164030\ttest: 0.0166529\tbest: 0.0166529 (13570)\ttotal: 14m 46s\tremaining: 1m 33s\n",
            "13580:\tlearn: 0.0164027\ttest: 0.0166527\tbest: 0.0166527 (13580)\ttotal: 14m 46s\tremaining: 1m 32s\n",
            "13590:\tlearn: 0.0164025\ttest: 0.0166526\tbest: 0.0166526 (13590)\ttotal: 14m 47s\tremaining: 1m 32s\n",
            "13600:\tlearn: 0.0164022\ttest: 0.0166525\tbest: 0.0166525 (13600)\ttotal: 14m 48s\tremaining: 1m 31s\n",
            "13610:\tlearn: 0.0164020\ttest: 0.0166523\tbest: 0.0166523 (13610)\ttotal: 14m 49s\tremaining: 1m 30s\n",
            "13620:\tlearn: 0.0164018\ttest: 0.0166522\tbest: 0.0166522 (13620)\ttotal: 14m 49s\tremaining: 1m 30s\n",
            "13630:\tlearn: 0.0164015\ttest: 0.0166520\tbest: 0.0166520 (13630)\ttotal: 14m 50s\tremaining: 1m 29s\n",
            "13640:\tlearn: 0.0164013\ttest: 0.0166519\tbest: 0.0166519 (13640)\ttotal: 14m 51s\tremaining: 1m 28s\n",
            "13650:\tlearn: 0.0164011\ttest: 0.0166518\tbest: 0.0166518 (13650)\ttotal: 14m 51s\tremaining: 1m 28s\n",
            "13660:\tlearn: 0.0164009\ttest: 0.0166516\tbest: 0.0166516 (13660)\ttotal: 14m 52s\tremaining: 1m 27s\n",
            "13670:\tlearn: 0.0164007\ttest: 0.0166515\tbest: 0.0166515 (13670)\ttotal: 14m 53s\tremaining: 1m 26s\n",
            "13680:\tlearn: 0.0164005\ttest: 0.0166514\tbest: 0.0166514 (13680)\ttotal: 14m 53s\tremaining: 1m 26s\n",
            "13690:\tlearn: 0.0164002\ttest: 0.0166513\tbest: 0.0166513 (13690)\ttotal: 14m 54s\tremaining: 1m 25s\n",
            "13700:\tlearn: 0.0164000\ttest: 0.0166511\tbest: 0.0166511 (13700)\ttotal: 14m 55s\tremaining: 1m 24s\n",
            "13710:\tlearn: 0.0163998\ttest: 0.0166510\tbest: 0.0166510 (13710)\ttotal: 14m 56s\tremaining: 1m 24s\n",
            "13720:\tlearn: 0.0163995\ttest: 0.0166509\tbest: 0.0166509 (13720)\ttotal: 14m 56s\tremaining: 1m 23s\n",
            "13730:\tlearn: 0.0163993\ttest: 0.0166507\tbest: 0.0166507 (13730)\ttotal: 14m 57s\tremaining: 1m 22s\n",
            "13740:\tlearn: 0.0163991\ttest: 0.0166506\tbest: 0.0166506 (13740)\ttotal: 14m 58s\tremaining: 1m 22s\n",
            "13750:\tlearn: 0.0163989\ttest: 0.0166505\tbest: 0.0166505 (13750)\ttotal: 14m 58s\tremaining: 1m 21s\n",
            "13760:\tlearn: 0.0163987\ttest: 0.0166504\tbest: 0.0166504 (13760)\ttotal: 14m 59s\tremaining: 1m 20s\n",
            "13770:\tlearn: 0.0163985\ttest: 0.0166503\tbest: 0.0166503 (13770)\ttotal: 15m\tremaining: 1m 20s\n",
            "13780:\tlearn: 0.0163983\ttest: 0.0166502\tbest: 0.0166502 (13780)\ttotal: 15m\tremaining: 1m 19s\n",
            "13790:\tlearn: 0.0163981\ttest: 0.0166500\tbest: 0.0166500 (13790)\ttotal: 15m 1s\tremaining: 1m 19s\n",
            "13800:\tlearn: 0.0163978\ttest: 0.0166499\tbest: 0.0166499 (13800)\ttotal: 15m 2s\tremaining: 1m 18s\n",
            "13810:\tlearn: 0.0163976\ttest: 0.0166497\tbest: 0.0166497 (13810)\ttotal: 15m 3s\tremaining: 1m 17s\n",
            "13820:\tlearn: 0.0163974\ttest: 0.0166495\tbest: 0.0166495 (13820)\ttotal: 15m 3s\tremaining: 1m 17s\n",
            "13830:\tlearn: 0.0163971\ttest: 0.0166494\tbest: 0.0166494 (13830)\ttotal: 15m 4s\tremaining: 1m 16s\n",
            "13840:\tlearn: 0.0163969\ttest: 0.0166493\tbest: 0.0166493 (13840)\ttotal: 15m 5s\tremaining: 1m 15s\n",
            "13850:\tlearn: 0.0163967\ttest: 0.0166492\tbest: 0.0166492 (13850)\ttotal: 15m 5s\tremaining: 1m 15s\n",
            "13860:\tlearn: 0.0163965\ttest: 0.0166491\tbest: 0.0166491 (13860)\ttotal: 15m 6s\tremaining: 1m 14s\n",
            "13870:\tlearn: 0.0163963\ttest: 0.0166489\tbest: 0.0166489 (13870)\ttotal: 15m 7s\tremaining: 1m 13s\n",
            "13880:\tlearn: 0.0163960\ttest: 0.0166488\tbest: 0.0166488 (13880)\ttotal: 15m 8s\tremaining: 1m 13s\n",
            "13890:\tlearn: 0.0163958\ttest: 0.0166486\tbest: 0.0166486 (13890)\ttotal: 15m 8s\tremaining: 1m 12s\n",
            "13900:\tlearn: 0.0163956\ttest: 0.0166485\tbest: 0.0166485 (13900)\ttotal: 15m 9s\tremaining: 1m 11s\n",
            "13910:\tlearn: 0.0163954\ttest: 0.0166484\tbest: 0.0166484 (13910)\ttotal: 15m 10s\tremaining: 1m 11s\n",
            "13920:\tlearn: 0.0163952\ttest: 0.0166483\tbest: 0.0166483 (13920)\ttotal: 15m 10s\tremaining: 1m 10s\n",
            "13930:\tlearn: 0.0163949\ttest: 0.0166481\tbest: 0.0166481 (13930)\ttotal: 15m 11s\tremaining: 1m 9s\n",
            "13940:\tlearn: 0.0163947\ttest: 0.0166480\tbest: 0.0166480 (13940)\ttotal: 15m 12s\tremaining: 1m 9s\n",
            "13950:\tlearn: 0.0163945\ttest: 0.0166479\tbest: 0.0166479 (13950)\ttotal: 15m 13s\tremaining: 1m 8s\n",
            "13960:\tlearn: 0.0163943\ttest: 0.0166477\tbest: 0.0166477 (13960)\ttotal: 15m 13s\tremaining: 1m 8s\n",
            "13970:\tlearn: 0.0163941\ttest: 0.0166476\tbest: 0.0166476 (13970)\ttotal: 15m 14s\tremaining: 1m 7s\n",
            "13980:\tlearn: 0.0163939\ttest: 0.0166475\tbest: 0.0166475 (13980)\ttotal: 15m 15s\tremaining: 1m 6s\n",
            "13990:\tlearn: 0.0163937\ttest: 0.0166474\tbest: 0.0166474 (13990)\ttotal: 15m 15s\tremaining: 1m 6s\n",
            "14000:\tlearn: 0.0163934\ttest: 0.0166472\tbest: 0.0166472 (14000)\ttotal: 15m 16s\tremaining: 1m 5s\n",
            "14010:\tlearn: 0.0163932\ttest: 0.0166471\tbest: 0.0166471 (14010)\ttotal: 15m 17s\tremaining: 1m 4s\n",
            "14020:\tlearn: 0.0163931\ttest: 0.0166470\tbest: 0.0166470 (14020)\ttotal: 15m 18s\tremaining: 1m 4s\n",
            "14030:\tlearn: 0.0163928\ttest: 0.0166469\tbest: 0.0166469 (14030)\ttotal: 15m 18s\tremaining: 1m 3s\n",
            "14040:\tlearn: 0.0163926\ttest: 0.0166468\tbest: 0.0166468 (14040)\ttotal: 15m 19s\tremaining: 1m 2s\n",
            "14050:\tlearn: 0.0163924\ttest: 0.0166467\tbest: 0.0166467 (14050)\ttotal: 15m 20s\tremaining: 1m 2s\n",
            "14060:\tlearn: 0.0163922\ttest: 0.0166465\tbest: 0.0166465 (14060)\ttotal: 15m 20s\tremaining: 1m 1s\n",
            "14070:\tlearn: 0.0163920\ttest: 0.0166464\tbest: 0.0166464 (14070)\ttotal: 15m 21s\tremaining: 1m\n",
            "14080:\tlearn: 0.0163917\ttest: 0.0166463\tbest: 0.0166463 (14080)\ttotal: 15m 22s\tremaining: 1m\n",
            "14090:\tlearn: 0.0163915\ttest: 0.0166461\tbest: 0.0166461 (14090)\ttotal: 15m 22s\tremaining: 59.5s\n",
            "14100:\tlearn: 0.0163913\ttest: 0.0166460\tbest: 0.0166460 (14100)\ttotal: 15m 23s\tremaining: 58.9s\n",
            "14110:\tlearn: 0.0163911\ttest: 0.0166459\tbest: 0.0166459 (14110)\ttotal: 15m 24s\tremaining: 58.2s\n",
            "14120:\tlearn: 0.0163909\ttest: 0.0166458\tbest: 0.0166458 (14120)\ttotal: 15m 24s\tremaining: 57.6s\n",
            "14130:\tlearn: 0.0163906\ttest: 0.0166456\tbest: 0.0166456 (14130)\ttotal: 15m 25s\tremaining: 56.9s\n",
            "14140:\tlearn: 0.0163904\ttest: 0.0166455\tbest: 0.0166455 (14140)\ttotal: 15m 26s\tremaining: 56.3s\n",
            "14150:\tlearn: 0.0163902\ttest: 0.0166454\tbest: 0.0166454 (14150)\ttotal: 15m 26s\tremaining: 55.6s\n",
            "14160:\tlearn: 0.0163900\ttest: 0.0166453\tbest: 0.0166453 (14160)\ttotal: 15m 27s\tremaining: 55s\n",
            "14170:\tlearn: 0.0163898\ttest: 0.0166451\tbest: 0.0166451 (14170)\ttotal: 15m 28s\tremaining: 54.3s\n",
            "14180:\tlearn: 0.0163896\ttest: 0.0166450\tbest: 0.0166450 (14180)\ttotal: 15m 29s\tremaining: 53.7s\n",
            "14190:\tlearn: 0.0163894\ttest: 0.0166449\tbest: 0.0166449 (14190)\ttotal: 15m 29s\tremaining: 53s\n",
            "14200:\tlearn: 0.0163892\ttest: 0.0166448\tbest: 0.0166448 (14200)\ttotal: 15m 30s\tremaining: 52.3s\n",
            "14210:\tlearn: 0.0163890\ttest: 0.0166447\tbest: 0.0166447 (14210)\ttotal: 15m 31s\tremaining: 51.7s\n",
            "14220:\tlearn: 0.0163887\ttest: 0.0166446\tbest: 0.0166446 (14220)\ttotal: 15m 31s\tremaining: 51s\n",
            "14230:\tlearn: 0.0163886\ttest: 0.0166445\tbest: 0.0166445 (14230)\ttotal: 15m 32s\tremaining: 50.4s\n",
            "14240:\tlearn: 0.0163883\ttest: 0.0166443\tbest: 0.0166443 (14240)\ttotal: 15m 33s\tremaining: 49.7s\n",
            "14250:\tlearn: 0.0163881\ttest: 0.0166442\tbest: 0.0166442 (14250)\ttotal: 15m 33s\tremaining: 49.1s\n",
            "14260:\tlearn: 0.0163879\ttest: 0.0166441\tbest: 0.0166441 (14260)\ttotal: 15m 34s\tremaining: 48.4s\n",
            "14270:\tlearn: 0.0163876\ttest: 0.0166439\tbest: 0.0166439 (14270)\ttotal: 15m 35s\tremaining: 47.8s\n",
            "14280:\tlearn: 0.0163874\ttest: 0.0166438\tbest: 0.0166438 (14280)\ttotal: 15m 36s\tremaining: 47.1s\n",
            "14290:\tlearn: 0.0163872\ttest: 0.0166437\tbest: 0.0166437 (14290)\ttotal: 15m 36s\tremaining: 46.5s\n",
            "14300:\tlearn: 0.0163870\ttest: 0.0166436\tbest: 0.0166436 (14300)\ttotal: 15m 37s\tremaining: 45.8s\n",
            "14310:\tlearn: 0.0163868\ttest: 0.0166435\tbest: 0.0166435 (14310)\ttotal: 15m 38s\tremaining: 45.2s\n",
            "14320:\tlearn: 0.0163866\ttest: 0.0166433\tbest: 0.0166433 (14320)\ttotal: 15m 38s\tremaining: 44.5s\n",
            "14330:\tlearn: 0.0163864\ttest: 0.0166432\tbest: 0.0166432 (14330)\ttotal: 15m 39s\tremaining: 43.9s\n",
            "14340:\tlearn: 0.0163861\ttest: 0.0166431\tbest: 0.0166431 (14340)\ttotal: 15m 40s\tremaining: 43.2s\n",
            "14350:\tlearn: 0.0163859\ttest: 0.0166430\tbest: 0.0166430 (14350)\ttotal: 15m 41s\tremaining: 42.6s\n",
            "14360:\tlearn: 0.0163857\ttest: 0.0166428\tbest: 0.0166428 (14360)\ttotal: 15m 41s\tremaining: 41.9s\n",
            "14370:\tlearn: 0.0163855\ttest: 0.0166427\tbest: 0.0166427 (14370)\ttotal: 15m 42s\tremaining: 41.2s\n",
            "14380:\tlearn: 0.0163853\ttest: 0.0166426\tbest: 0.0166426 (14380)\ttotal: 15m 43s\tremaining: 40.6s\n",
            "14390:\tlearn: 0.0163851\ttest: 0.0166424\tbest: 0.0166424 (14390)\ttotal: 15m 43s\tremaining: 39.9s\n",
            "14400:\tlearn: 0.0163848\ttest: 0.0166423\tbest: 0.0166423 (14400)\ttotal: 15m 44s\tremaining: 39.3s\n",
            "14410:\tlearn: 0.0163847\ttest: 0.0166422\tbest: 0.0166422 (14410)\ttotal: 15m 45s\tremaining: 38.6s\n",
            "14420:\tlearn: 0.0163845\ttest: 0.0166421\tbest: 0.0166421 (14420)\ttotal: 15m 45s\tremaining: 38s\n",
            "14430:\tlearn: 0.0163843\ttest: 0.0166420\tbest: 0.0166420 (14430)\ttotal: 15m 46s\tremaining: 37.3s\n",
            "14440:\tlearn: 0.0163841\ttest: 0.0166419\tbest: 0.0166419 (14440)\ttotal: 15m 47s\tremaining: 36.7s\n",
            "14450:\tlearn: 0.0163838\ttest: 0.0166418\tbest: 0.0166418 (14450)\ttotal: 15m 48s\tremaining: 36s\n",
            "14460:\tlearn: 0.0163836\ttest: 0.0166416\tbest: 0.0166416 (14460)\ttotal: 15m 48s\tremaining: 35.4s\n",
            "14470:\tlearn: 0.0163834\ttest: 0.0166415\tbest: 0.0166415 (14470)\ttotal: 15m 49s\tremaining: 34.7s\n",
            "14480:\tlearn: 0.0163832\ttest: 0.0166414\tbest: 0.0166414 (14480)\ttotal: 15m 50s\tremaining: 34.1s\n",
            "14490:\tlearn: 0.0163831\ttest: 0.0166413\tbest: 0.0166413 (14490)\ttotal: 15m 50s\tremaining: 33.4s\n",
            "14500:\tlearn: 0.0163829\ttest: 0.0166412\tbest: 0.0166412 (14500)\ttotal: 15m 51s\tremaining: 32.7s\n",
            "14510:\tlearn: 0.0163827\ttest: 0.0166411\tbest: 0.0166411 (14510)\ttotal: 15m 52s\tremaining: 32.1s\n",
            "14520:\tlearn: 0.0163825\ttest: 0.0166410\tbest: 0.0166410 (14520)\ttotal: 15m 52s\tremaining: 31.4s\n",
            "14530:\tlearn: 0.0163823\ttest: 0.0166409\tbest: 0.0166409 (14530)\ttotal: 15m 53s\tremaining: 30.8s\n",
            "14540:\tlearn: 0.0163821\ttest: 0.0166408\tbest: 0.0166408 (14540)\ttotal: 15m 54s\tremaining: 30.1s\n",
            "14550:\tlearn: 0.0163819\ttest: 0.0166406\tbest: 0.0166406 (14550)\ttotal: 15m 54s\tremaining: 29.5s\n",
            "14560:\tlearn: 0.0163817\ttest: 0.0166405\tbest: 0.0166405 (14560)\ttotal: 15m 55s\tremaining: 28.8s\n",
            "14570:\tlearn: 0.0163814\ttest: 0.0166404\tbest: 0.0166404 (14570)\ttotal: 15m 56s\tremaining: 28.2s\n",
            "14580:\tlearn: 0.0163812\ttest: 0.0166403\tbest: 0.0166403 (14580)\ttotal: 15m 57s\tremaining: 27.5s\n",
            "14590:\tlearn: 0.0163811\ttest: 0.0166402\tbest: 0.0166402 (14590)\ttotal: 15m 57s\tremaining: 26.8s\n",
            "14600:\tlearn: 0.0163809\ttest: 0.0166401\tbest: 0.0166401 (14600)\ttotal: 15m 58s\tremaining: 26.2s\n",
            "14610:\tlearn: 0.0163806\ttest: 0.0166400\tbest: 0.0166400 (14610)\ttotal: 15m 59s\tremaining: 25.5s\n",
            "14620:\tlearn: 0.0163804\ttest: 0.0166398\tbest: 0.0166398 (14620)\ttotal: 15m 59s\tremaining: 24.9s\n",
            "14630:\tlearn: 0.0163802\ttest: 0.0166397\tbest: 0.0166397 (14630)\ttotal: 16m\tremaining: 24.2s\n",
            "14640:\tlearn: 0.0163800\ttest: 0.0166396\tbest: 0.0166396 (14640)\ttotal: 16m 1s\tremaining: 23.6s\n",
            "14650:\tlearn: 0.0163798\ttest: 0.0166395\tbest: 0.0166395 (14650)\ttotal: 16m 1s\tremaining: 22.9s\n",
            "14660:\tlearn: 0.0163796\ttest: 0.0166393\tbest: 0.0166393 (14660)\ttotal: 16m 2s\tremaining: 22.3s\n",
            "14670:\tlearn: 0.0163794\ttest: 0.0166393\tbest: 0.0166393 (14670)\ttotal: 16m 3s\tremaining: 21.6s\n",
            "14680:\tlearn: 0.0163792\ttest: 0.0166391\tbest: 0.0166391 (14680)\ttotal: 16m 3s\tremaining: 20.9s\n",
            "14690:\tlearn: 0.0163790\ttest: 0.0166390\tbest: 0.0166390 (14690)\ttotal: 16m 4s\tremaining: 20.3s\n",
            "14700:\tlearn: 0.0163788\ttest: 0.0166389\tbest: 0.0166389 (14700)\ttotal: 16m 5s\tremaining: 19.6s\n",
            "14710:\tlearn: 0.0163787\ttest: 0.0166388\tbest: 0.0166388 (14710)\ttotal: 16m 5s\tremaining: 19s\n",
            "14720:\tlearn: 0.0163785\ttest: 0.0166387\tbest: 0.0166387 (14720)\ttotal: 16m 6s\tremaining: 18.3s\n",
            "14730:\tlearn: 0.0163783\ttest: 0.0166386\tbest: 0.0166386 (14730)\ttotal: 16m 7s\tremaining: 17.7s\n",
            "14740:\tlearn: 0.0163780\ttest: 0.0166384\tbest: 0.0166384 (14740)\ttotal: 16m 7s\tremaining: 17s\n",
            "14750:\tlearn: 0.0163778\ttest: 0.0166383\tbest: 0.0166383 (14750)\ttotal: 16m 8s\tremaining: 16.4s\n",
            "14760:\tlearn: 0.0163776\ttest: 0.0166382\tbest: 0.0166382 (14760)\ttotal: 16m 9s\tremaining: 15.7s\n",
            "14770:\tlearn: 0.0163774\ttest: 0.0166381\tbest: 0.0166381 (14770)\ttotal: 16m 10s\tremaining: 15s\n",
            "14780:\tlearn: 0.0163773\ttest: 0.0166380\tbest: 0.0166380 (14780)\ttotal: 16m 10s\tremaining: 14.4s\n",
            "14790:\tlearn: 0.0163770\ttest: 0.0166379\tbest: 0.0166379 (14790)\ttotal: 16m 11s\tremaining: 13.7s\n",
            "14800:\tlearn: 0.0163769\ttest: 0.0166378\tbest: 0.0166378 (14800)\ttotal: 16m 12s\tremaining: 13.1s\n",
            "14810:\tlearn: 0.0163767\ttest: 0.0166377\tbest: 0.0166377 (14810)\ttotal: 16m 12s\tremaining: 12.4s\n",
            "14820:\tlearn: 0.0163765\ttest: 0.0166376\tbest: 0.0166376 (14820)\ttotal: 16m 13s\tremaining: 11.8s\n",
            "14830:\tlearn: 0.0163762\ttest: 0.0166375\tbest: 0.0166375 (14830)\ttotal: 16m 14s\tremaining: 11.1s\n",
            "14840:\tlearn: 0.0163761\ttest: 0.0166373\tbest: 0.0166373 (14840)\ttotal: 16m 14s\tremaining: 10.4s\n",
            "14850:\tlearn: 0.0163759\ttest: 0.0166372\tbest: 0.0166372 (14850)\ttotal: 16m 15s\tremaining: 9.79s\n",
            "14860:\tlearn: 0.0163756\ttest: 0.0166371\tbest: 0.0166371 (14860)\ttotal: 16m 16s\tremaining: 9.13s\n",
            "14870:\tlearn: 0.0163754\ttest: 0.0166370\tbest: 0.0166370 (14870)\ttotal: 16m 17s\tremaining: 8.48s\n",
            "14880:\tlearn: 0.0163753\ttest: 0.0166369\tbest: 0.0166369 (14880)\ttotal: 16m 17s\tremaining: 7.82s\n",
            "14890:\tlearn: 0.0163751\ttest: 0.0166368\tbest: 0.0166368 (14890)\ttotal: 16m 18s\tremaining: 7.16s\n",
            "14900:\tlearn: 0.0163749\ttest: 0.0166367\tbest: 0.0166367 (14900)\ttotal: 16m 19s\tremaining: 6.5s\n",
            "14910:\tlearn: 0.0163747\ttest: 0.0166366\tbest: 0.0166366 (14910)\ttotal: 16m 19s\tremaining: 5.85s\n",
            "14920:\tlearn: 0.0163745\ttest: 0.0166365\tbest: 0.0166365 (14920)\ttotal: 16m 20s\tremaining: 5.19s\n",
            "14930:\tlearn: 0.0163743\ttest: 0.0166364\tbest: 0.0166364 (14930)\ttotal: 16m 21s\tremaining: 4.53s\n",
            "14940:\tlearn: 0.0163741\ttest: 0.0166363\tbest: 0.0166363 (14940)\ttotal: 16m 21s\tremaining: 3.88s\n",
            "14950:\tlearn: 0.0163739\ttest: 0.0166362\tbest: 0.0166362 (14950)\ttotal: 16m 22s\tremaining: 3.22s\n",
            "14960:\tlearn: 0.0163737\ttest: 0.0166361\tbest: 0.0166361 (14960)\ttotal: 16m 23s\tremaining: 2.56s\n",
            "14970:\tlearn: 0.0163735\ttest: 0.0166360\tbest: 0.0166360 (14970)\ttotal: 16m 24s\tremaining: 1.91s\n",
            "14980:\tlearn: 0.0163733\ttest: 0.0166359\tbest: 0.0166359 (14980)\ttotal: 16m 24s\tremaining: 1.25s\n",
            "14990:\tlearn: 0.0163731\ttest: 0.0166358\tbest: 0.0166358 (14990)\ttotal: 16m 25s\tremaining: 592ms\n",
            "14999:\tlearn: 0.0163729\ttest: 0.0166357\tbest: 0.0166357 (14999)\ttotal: 16m 26s\tremaining: 0us\n",
            "bestTest = 0.01663565919\n",
            "bestIteration = 14999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7f5d680517f0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat_model = CatBoostRegressor(\n",
        "    iterations=15000,\n",
        "    learning_rate=0.0001,\n",
        "    task_type='GPU',\n",
        "    loss_function='MAE'\n",
        ")\n",
        "  \n",
        "cat_model.fit(\n",
        "      x_train, y_train,\n",
        "      eval_set=(x_val, y_val),\n",
        "      verbose=10\n",
        ")     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XATWr0JNGmQg"
      },
      "outputs": [],
      "source": [
        "y_val_pred = cat_model.predict(x_val)\n",
        "y_train_pred = cat_model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "474P63PoGpxo",
        "outputId": "7c1280a8-16a1-4d35-fa6f-61b4c2fe6601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.0120398  0.01626687 0.01496185 0.01808313 0.01828506 0.01505594\n",
            " 0.01252063 0.00731855], shape=(8,), dtype=float32)\n",
            "tf.Tensor([8.168375], shape=(1,), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.00929639 0.0155615  0.01484375 0.01794397 0.01796895 0.01476417\n",
            " 0.01171368 0.00656596], shape=(8,), dtype=float32)\n",
            "tf.Tensor([8.181248], shape=(1,), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(AAR_metric(y_val, np.around(y_val_pred, 2)))\n",
        "print(AAR_metric(y_train, np.around(y_train_pred, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0qvZAAMdWfP"
      },
      "outputs": [],
      "source": [
        "cat_model.save_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/regressor')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLHzjn23igzC"
      },
      "source": [
        "## Finetuning base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ul4gJe9EFk",
        "outputId": "d3c87bc4-0093-4654-ddb8-a1b088ec6821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_3_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_3_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_5_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_5_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_7_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_7_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_9_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_9_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_9_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_11_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_11_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_11_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_13_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_13_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_13_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_15_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_15_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_15_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_2_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_4_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_4_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_6_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_6_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_8_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_8_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_8_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_10_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_10_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_10_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_12_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_12_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_12_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_14_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_14_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_14_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14377/14377 [==============================] - 93s 6ms/step - loss: 0.0114 - mae: 0.0167 - AAR_metric: 7.7226 - val_loss: 0.0090 - val_mae: 0.0168 - val_AAR_metric: 8.1931\n",
            "Epoch 2/100\n",
            "14377/14377 [==============================] - 86s 6ms/step - loss: 0.0114 - mae: 0.0166 - AAR_metric: 7.7278 - val_loss: 0.0090 - val_mae: 0.0168 - val_AAR_metric: 8.1947\n",
            "Epoch 3/100\n",
            "14377/14377 [==============================] - 86s 6ms/step - loss: 0.0114 - mae: 0.0166 - AAR_metric: 7.7341 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2003\n",
            "Epoch 4/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0113 - mae: 0.0166 - AAR_metric: 7.7411 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2030\n",
            "Epoch 5/100\n",
            "14377/14377 [==============================] - 88s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7417 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2031\n",
            "Epoch 6/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7522 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2058\n",
            "Epoch 7/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0114 - mae: 0.0165 - AAR_metric: 7.7340 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2048\n",
            "Epoch 8/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7476 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2051\n",
            "Epoch 9/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7400 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2075\n",
            "Epoch 10/100\n",
            "14377/14377 [==============================] - 90s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7570 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2066\n",
            "Epoch 11/100\n",
            "14377/14377 [==============================] - 89s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7487 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2080\n",
            "Epoch 12/100\n",
            "14377/14377 [==============================] - 89s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7439 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2088\n",
            "Epoch 13/100\n",
            "14377/14377 [==============================] - 88s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7443 - val_loss: 0.0089 - val_mae: 0.0166 - val_AAR_metric: 8.2104\n",
            "Epoch 14/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7421 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2088\n",
            "Epoch 15/100\n",
            "14377/14377 [==============================] - 88s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7416 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2065\n",
            "Epoch 16/100\n",
            "14377/14377 [==============================] - 87s 6ms/step - loss: 0.0113 - mae: 0.0165 - AAR_metric: 7.7466 - val_loss: 0.0090 - val_mae: 0.0167 - val_AAR_metric: 8.2074\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1f8c2cbaf0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_final.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00001, clipvalue=1.), loss=AAR_loss, metrics=[\"mae\", AAR_metric])\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "model_final.fit(\n",
        "    x_train, y_train,\n",
        "    workers=25,\n",
        "    batch_size=32,\n",
        "    #steps_per_epoch=(n_train_samples) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    #validation_steps=n_val_samples // batch_size,\n",
        "    callbacks=[ModelCheckpoint('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/' + 'xception_double_finetuning', monitor='val_loss', save_best_only=True),\n",
        "               EarlyStopping(monitor=\"val_loss\", patience=3)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model"
      ],
      "metadata": {
        "id": "DSkb9PPLjbT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = keras.models.load_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/xception_double_finetuning', compile=False)\n",
        "final_model.trainable = True\n",
        "final_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCkEYg3PjaWq",
        "outputId": "0d55350d-e80f-401c-ed8d-92237034a4fc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 2048)]            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 262,401\n",
            "Trainable params: 262,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = final_model.predict(x_val)\n",
        "y_train_pred = final_model.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLVqOlIgjsjT",
        "outputId": "92f20a2c-eee8-4c57-9d4a-63a2aff399f3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115015/115015 [==============================] - 241s 2ms/step\n",
            "14377/14377 [==============================] - 28s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(AAR_metric(y_val, y_val_pred))\n",
        "print(AAR_metric(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWjg-wT2jv9B",
        "outputId": "2bbcbbe5-3f85-4900-ce0f-3f6826e15f9c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.016637322, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.00677763 0.01421369 0.01567372 0.01848217 0.01840018 0.01523813\n",
            " 0.01224497 0.00631236], shape=(8,), dtype=float32)\n",
            "tf.Tensor(0.013417855, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0054587373, shape=(), dtype=float32)\n",
            "tf.Tensor([8.112341], shape=(1,), dtype=float32)\n",
            "tf.Tensor(0.01646004, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.00465861 0.01367717 0.01557727 0.01846188 0.01815128 0.01504813\n",
            " 0.0116579  0.00630401], shape=(8,), dtype=float32)\n",
            "tf.Tensor(0.012942031, shape=(), dtype=float32)\n",
            "tf.Tensor(0.0059462604, shape=(), dtype=float32)\n",
            "tf.Tensor([8.111171], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qLFKf2R3NUC"
      },
      "source": [
        "## Last model 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7GTqR_k3RDz"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(2048, 1))\n",
        "x = Dense(1024, activation=\"relu\")(inputs)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=x, name=\"sample_model\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.), loss=AAR_loss, metrics=[\"mae\", AAR_metric])\n",
        "\n",
        "epochs = 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERaxP73PQ6O3",
        "outputId": "c3901cf1-e755-4bf2-f9d8-de02501671f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0263 - mae: 0.0349 - AAR_metric: 4.9284 - val_loss: 0.0179 - val_mae: 0.0333 - val_AAR_metric: 6.5809\n",
            "Epoch 2/100\n",
            "14377/14377 [==============================] - 356s 25ms/step - loss: 0.0251 - mae: 0.0334 - AAR_metric: 5.1402 - val_loss: 0.0172 - val_mae: 0.0319 - val_AAR_metric: 6.6699\n",
            "Epoch 3/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0248 - mae: 0.0329 - AAR_metric: 5.2206 - val_loss: 0.0170 - val_mae: 0.0316 - val_AAR_metric: 6.6982\n",
            "Epoch 4/100\n",
            "14377/14377 [==============================] - 356s 25ms/step - loss: 0.0244 - mae: 0.0325 - AAR_metric: 5.2786 - val_loss: 0.0170 - val_mae: 0.0317 - val_AAR_metric: 6.6714\n",
            "Epoch 5/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0242 - mae: 0.0324 - AAR_metric: 5.3016 - val_loss: 0.0166 - val_mae: 0.0308 - val_AAR_metric: 6.7870\n",
            "Epoch 6/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0239 - mae: 0.0320 - AAR_metric: 5.3617 - val_loss: 0.0170 - val_mae: 0.0316 - val_AAR_metric: 6.7016\n",
            "Epoch 7/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0239 - mae: 0.0321 - AAR_metric: 5.3559 - val_loss: 0.0166 - val_mae: 0.0310 - val_AAR_metric: 6.7644\n",
            "Epoch 8/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0238 - mae: 0.0319 - AAR_metric: 5.3690 - val_loss: 0.0168 - val_mae: 0.0313 - val_AAR_metric: 6.7557\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1a66c16c40>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    workers=25,\n",
        "    batch_size=32,\n",
        "    #steps_per_epoch=(n_train_samples) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    #validation_steps=n_val_samples // batch_size,\n",
        "    callbacks=[ModelCheckpoint('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/' + 'final2_anto', monitor='val_loss', save_best_only=True),\n",
        "               EarlyStopping(monitor=\"val_loss\", patience=3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU0fKArdcwFY",
        "outputId": "886af36b-dc7f-4a5d-a7e9-2f3eb6daecfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sample_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 2048, 1)]         0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048, 1024)        2048      \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 1024)             0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/final2_anto', compile=False)\n",
        "model.trainable = True\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioPxIYVMdCM2",
        "outputId": "45fe5183-feb2-4eb4-b4bc-f41cd276a27c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_3_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_3_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_5_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_5_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_7_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_7_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_9_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_9_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_9_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_11_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_11_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_11_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_13_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_13_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_13_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_15_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_15_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_15_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_2_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_4_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_4_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_6_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_6_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_8_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_8_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_8_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_10_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_10_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_10_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_12_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_12_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_12_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_14_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_14_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_14_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14377/14377 [==============================] - 367s 25ms/step - loss: 0.0232 - mae: 0.0307 - AAR_metric: 5.4999 - val_loss: 0.0165 - val_mae: 0.0307 - val_AAR_metric: 6.8049 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "14377/14377 [==============================] - 359s 25ms/step - loss: 0.0231 - mae: 0.0307 - AAR_metric: 5.5183 - val_loss: 0.0166 - val_mae: 0.0309 - val_AAR_metric: 6.7548 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "14377/14377 [==============================] - 359s 25ms/step - loss: 0.0232 - mae: 0.0306 - AAR_metric: 5.5065 - val_loss: 0.0165 - val_mae: 0.0306 - val_AAR_metric: 6.8106 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "14377/14377 [==============================] - 358s 25ms/step - loss: 0.0230 - mae: 0.0305 - AAR_metric: 5.5416 - val_loss: 0.0164 - val_mae: 0.0304 - val_AAR_metric: 6.8171 - lr: 1.0000e-05\n",
            "Epoch 5/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0230 - mae: 0.0304 - AAR_metric: 5.5451 - val_loss: 0.0164 - val_mae: 0.0305 - val_AAR_metric: 6.8077 - lr: 1.0000e-05\n",
            "Epoch 6/100\n",
            "14377/14377 [==============================] - 357s 25ms/step - loss: 0.0229 - mae: 0.0304 - AAR_metric: 5.5501 - val_loss: 0.0164 - val_mae: 0.0304 - val_AAR_metric: 6.8180 - lr: 1.0000e-05\n",
            "Epoch 7/100\n",
            "14377/14377 [==============================] - 359s 25ms/step - loss: 0.0229 - mae: 0.0304 - AAR_metric: 5.5587 - val_loss: 0.0164 - val_mae: 0.0305 - val_AAR_metric: 6.8144 - lr: 1.0000e-06\n",
            "Epoch 8/100\n",
            "14377/14377 [==============================] - 358s 25ms/step - loss: 0.0229 - mae: 0.0304 - AAR_metric: 5.5449 - val_loss: 0.0164 - val_mae: 0.0304 - val_AAR_metric: 6.8166 - lr: 1.0000e-06\n",
            "Epoch 9/100\n",
            "14377/14377 [==============================] - 358s 25ms/step - loss: 0.0230 - mae: 0.0304 - AAR_metric: 5.5301 - val_loss: 0.0164 - val_mae: 0.0305 - val_AAR_metric: 6.8144 - lr: 1.0000e-07\n",
            "Epoch 10/100\n",
            "14377/14377 [==============================] - 358s 25ms/step - loss: 0.0229 - mae: 0.0304 - AAR_metric: 5.5348 - val_loss: 0.0164 - val_mae: 0.0305 - val_AAR_metric: 6.8126 - lr: 1.0000e-07\n",
            "Epoch 11/100\n",
            "14377/14377 [==============================] - 358s 25ms/step - loss: 0.0229 - mae: 0.0304 - AAR_metric: 5.5458 - val_loss: 0.0164 - val_mae: 0.0305 - val_AAR_metric: 6.8127 - lr: 1.0000e-08\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f565ab221f0>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, clipvalue=1.), loss=AAR_loss, metrics=[\"mae\", AAR_metric])\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "lr_manager = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=2,\n",
        "    verbose=0,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0,\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    workers=25,\n",
        "    batch_size=32,\n",
        "    #steps_per_epoch=(n_train_samples) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    #validation_steps=n_val_samples // batch_size,\n",
        "    callbacks=[ModelCheckpoint('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/' + 'final2_anto_second', monitor='val_loss', save_best_only=True),\n",
        "               EarlyStopping(monitor=\"val_loss\", patience=5), lr_manager])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model 1"
      ],
      "metadata": {
        "id": "_xg83pCi5wzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = keras.models.load_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/final2_anto_second', compile=False)\n",
        "final_model.trainable = True\n",
        "final_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99475002-e5b0-46fd-c059-78096a0ad934",
        "id": "J1m0ziTA5wzL"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sample_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 2048, 1)]         0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048, 1024)        2048      \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 1024)             0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,073\n",
            "Trainable params: 3,073\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = final_model.predict(x_val)\n",
        "y_train_pred = final_model.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c7ecd05-c37a-46c5-ae41-a738751e1167",
        "id": "P2Qf67ZV5wzL"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3595/3595 [==============================] - 30s 8ms/step\n",
            "14377/14377 [==============================] - 122s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(AAR_metric(y_val, y_val_pred))\n",
        "print(AAR_metric(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce05035-652c-4adc-91cb-921b58920cde",
        "id": "rXxECT825wzM"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.030430987, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.10126048 0.06557602 0.03343995 0.03237204 0.02296661 0.02218156\n",
            " 0.02007069 0.0694296 ], shape=(8,), dtype=float32)\n",
            "tf.Tensor([2.2431898], shape=(1,), dtype=float32)\n",
            "tf.Tensor(0.03039617, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.10140812 0.06455352 0.0335843  0.03236026 0.02305938 0.02215545\n",
            " 0.01937902 0.06902578], shape=(8,), dtype=float32)\n",
            "tf.Tensor([2.2768013], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtSFqa3P6vyr"
      },
      "source": [
        "## Last model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "283317f3-293f-455e-c352-e88fd4df79f8",
        "id": "dfoii4N-6vyx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sample_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2048, 1)]         0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048, 1024)        2048      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048, 1024)        0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2048, 128)         131200    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048, 128)         0         \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ef92cfb451d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1356\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[1;32m   1359\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1399\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1152\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m                **kwargs):\n\u001b[1;32m    235\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    238\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_single_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_single_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1037\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1492\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m   \"\"\"\n\u001b[0;32m-> 1494\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1495\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1501\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \"\"\"\n\u001b[0;32m--> 267\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(2048, 1))\n",
        "x = Dense(1024, activation=\"relu\")(inputs)\n",
        "x = Dropout(.2)(x)\n",
        "x = Dense(128, activation=\"relu\")(x)\n",
        "x = Dropout(.2)(x)\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "x = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=x, name=\"sample_model\")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001, clipvalue=1.), loss=AAR_loss, metrics=[\"mae\", AAR_metric])\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    workers=25,\n",
        "    batch_size=32,\n",
        "    #steps_per_epoch=(n_train_samples) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    #validation_steps=n_val_samples // batch_size,\n",
        "    callbacks=[ModelCheckpoint('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/' + 'final_anto', monitor='val_loss', save_best_only=True),\n",
        "               EarlyStopping(monitor=\"val_loss\", patience=3)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iXX7zKTdmIgs",
        "outputId": "802ad9c9-fe05-424f-c805-1f5cd9b3b241"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sample_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 2048, 1)]         0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 2048, 1024)        2048      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 2048, 1024)        0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 2048, 128)         131200    \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 2048, 128)         0         \n",
            "                                                                 \n",
            " global_average_pooling1d_6   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/final_anto', compile=False)\n",
        "model.trainable = True\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "outputId": "d46497fd-e37a-4457-929a-2c0468a6ea05",
        "id": "PDzp9osr6vyx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_1_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_1_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_1_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_3_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_3_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_3_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_5_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_5_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_5_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_7_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_7_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_7_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_9_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_9_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_9_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_11_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_11_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_11_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_13_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_13_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_13_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_15_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_15_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_15_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_2_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_2_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_4_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_4_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_4_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_6_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_6_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_6_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_8_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_8_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_8_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_10_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_10_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_10_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_12_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_12_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_12_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/GatherV2_14_grad/Reshape_1:0\", shape=(None,), dtype=int64), values=Tensor(\"gradients/GatherV2_14_grad/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradients/GatherV2_14_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14377/14377 [==============================] - 707s 49ms/step - loss: 0.0238 - mae: 0.0318 - AAR_metric: 5.3902 - val_loss: 0.0162 - val_mae: 0.0302 - val_AAR_metric: 6.8320 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "14377/14377 [==============================] - 700s 49ms/step - loss: 0.0236 - mae: 0.0316 - AAR_metric: 5.4117 - val_loss: 0.0162 - val_mae: 0.0300 - val_AAR_metric: 6.8552 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "14377/14377 [==============================] - 700s 49ms/step - loss: 0.0235 - mae: 0.0316 - AAR_metric: 5.4205 - val_loss: 0.0163 - val_mae: 0.0304 - val_AAR_metric: 6.8131 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "14377/14377 [==============================] - 700s 49ms/step - loss: 0.0235 - mae: 0.0316 - AAR_metric: 5.4392 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8641 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "14377/14377 [==============================] - 701s 49ms/step - loss: 0.0235 - mae: 0.0315 - AAR_metric: 5.4306 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8773 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "14377/14377 [==============================] - 701s 49ms/step - loss: 0.0234 - mae: 0.0315 - AAR_metric: 5.4370 - val_loss: 0.0168 - val_mae: 0.0312 - val_AAR_metric: 6.7470 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "14377/14377 [==============================] - 699s 49ms/step - loss: 0.0235 - mae: 0.0315 - AAR_metric: 5.4261 - val_loss: 0.0163 - val_mae: 0.0302 - val_AAR_metric: 6.8461 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "14377/14377 [==============================] - 699s 49ms/step - loss: 0.0235 - mae: 0.0315 - AAR_metric: 5.4234 - val_loss: 0.0161 - val_mae: 0.0300 - val_AAR_metric: 6.8740 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "14377/14377 [==============================] - 699s 49ms/step - loss: 0.0235 - mae: 0.0312 - AAR_metric: 5.4428 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8645 - lr: 1.0000e-05\n",
            "Epoch 10/100\n",
            "14377/14377 [==============================] - 699s 49ms/step - loss: 0.0233 - mae: 0.0313 - AAR_metric: 5.4695 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8685 - lr: 1.0000e-05\n",
            "Epoch 11/100\n",
            "14377/14377 [==============================] - 702s 49ms/step - loss: 0.0233 - mae: 0.0313 - AAR_metric: 5.4778 - val_loss: 0.0161 - val_mae: 0.0300 - val_AAR_metric: 6.8503 - lr: 1.0000e-05\n",
            "Epoch 12/100\n",
            "14377/14377 [==============================] - 699s 49ms/step - loss: 0.0235 - mae: 0.0313 - AAR_metric: 5.4471 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8719 - lr: 1.0000e-05\n",
            "Epoch 13/100\n",
            "14377/14377 [==============================] - 702s 49ms/step - loss: 0.0235 - mae: 0.0312 - AAR_metric: 5.4537 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8609 - lr: 1.0000e-06\n",
            "Epoch 14/100\n",
            "14377/14377 [==============================] - 702s 49ms/step - loss: 0.0234 - mae: 0.0313 - AAR_metric: 5.4531 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8647 - lr: 1.0000e-06\n",
            "Epoch 15/100\n",
            "14377/14377 [==============================] - 703s 49ms/step - loss: 0.0234 - mae: 0.0312 - AAR_metric: 5.4519 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8608 - lr: 1.0000e-06\n",
            "Epoch 16/100\n",
            "14377/14377 [==============================] - 703s 49ms/step - loss: 0.0232 - mae: 0.0312 - AAR_metric: 5.4720 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8659 - lr: 1.0000e-06\n",
            "Epoch 17/100\n",
            "14377/14377 [==============================] - 702s 49ms/step - loss: 0.0233 - mae: 0.0312 - AAR_metric: 5.4752 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8625 - lr: 1.0000e-07\n",
            "Epoch 18/100\n",
            "14377/14377 [==============================] - 703s 49ms/step - loss: 0.0232 - mae: 0.0313 - AAR_metric: 5.4761 - val_loss: 0.0161 - val_mae: 0.0299 - val_AAR_metric: 6.8628 - lr: 1.0000e-07\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd2264d8e0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, clipvalue=1.), loss=AAR_loss, metrics=[\"mae\", AAR_metric])\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "lr_manager = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=4,\n",
        "    verbose=0,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0,\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train,\n",
        "    workers=25,\n",
        "    batch_size=32,\n",
        "    #steps_per_epoch=(n_train_samples) // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_val, y_val),\n",
        "    #validation_steps=n_val_samples // batch_size,\n",
        "    callbacks=[ModelCheckpoint('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/' + 'final_anto_second', monitor='val_loss', save_best_only=True),\n",
        "               EarlyStopping(monitor=\"val_loss\", patience=6), lr_manager])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate model 2"
      ],
      "metadata": {
        "id": "Z6pJA2uH7ddm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = keras.models.load_model('/content/drive/MyDrive/finalProject_AV/GTA_CAIP_Contest_Code/final_anto_second', compile=False)\n",
        "final_model.trainable = True\n",
        "final_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "693061d8-2a83-40ca-e04e-9ac0ec17aa7b",
        "id": "5Ie4shcI7ddn"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sample_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 2048, 1)]         0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 2048, 1024)        2048      \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 2048, 1024)        0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 2048, 128)         131200    \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 2048, 128)         0         \n",
            "                                                                 \n",
            " global_average_pooling1d_6   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = final_model.predict(x_val)\n",
        "y_train_pred = final_model.predict(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f081963-c940-426e-e29b-a52914e2aa3f",
        "id": "niX8meE87ddn"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3595/3595 [==============================] - 40s 11ms/step\n",
            "14377/14377 [==============================] - 153s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(AAR_metric(y_val, y_val_pred))\n",
        "print(AAR_metric(y_train, y_train_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f123ac6-2341-4d16-96b2-54de5094e794",
        "id": "B95AcSS97ddn"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.029880682, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.09392432 0.06622002 0.03210472 0.0321246  0.02430819 0.02023486\n",
            " 0.01823771 0.05539346], shape=(8,), dtype=float32)\n",
            "tf.Tensor([2.9024203], shape=(1,), dtype=float32)\n",
            "tf.Tensor(0.029834671, shape=(), dtype=float32)\n",
            "MAE's of all age groups:  tf.Tensor(\n",
            "[0.09373035 0.0651166  0.03225201 0.03205658 0.0244158  0.02022067\n",
            " 0.01756665 0.0554096 ], shape=(8,), dtype=float32)\n",
            "tf.Tensor([2.9420433], shape=(1,), dtype=float32)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "4eZbMa0BUGik",
        "DEHhKOgMGs4v",
        "QtE9ecpST1ah",
        "eTzVvUcST6ff",
        "FmKUApXZZcVQ",
        "z-mUoOZFGBKC",
        "J3kciXyd7TKA",
        "Q2MDnG-S8c-1",
        "CWvhMhQgF2wE",
        "pLHzjn23igzC",
        "DSkb9PPLjbT8",
        "1qLFKf2R3NUC",
        "_xg83pCi5wzG",
        "NtSFqa3P6vyr",
        "Z6pJA2uH7ddm"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}